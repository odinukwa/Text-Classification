It is important to understand that there is a spectrum from deep to shallow. You model the parts of your language deeply that should somehow participate in some inductive argument about the construction of it, the remainder is better left in the shallow see of direct semantics of the substrate of the logic. For example, when you want to reason about Hoare Logic, you can model the expression language in a shallow manner, but the outline of the assign-if-while language should be a concrete datatype. You don't need to enter the structure of x + y or a < b, but you need to work with etc. In the other answers there were allusions to dependent types. This reminds of the ancient problem to represent languages with binders in a sane way, such that they are as shallow as possible, but still admit some inductive arguments. My impression is that the jury is still out judging about all the different approaches and papers that have emerged in the past 10-20 years on that subject. The "POPLmark challenge" for the different proof assistant communities was also about that to some extent. Oddly, in classic HOL without dependent types, the HOL-Nominal approach by C. Urban worked quite well for shallow binding, although it did not catch up with the cultural shifts in these communities of programming-language formalization. 

(Sorry, this is a bit biased towards papers I have co-authored, mostly due to my familiarity with those.) 

(There are others -- see e.g. the surveys referenced by Ronitt Rubinfeld here for property testing in general, and some discussion of distribution testing.) Some slides: $URL$ 

Tutorials on the Foundations of Cryptography (edited by Yehuda Lindell) Dedicated to Oded Goldreich From the Springer page: 

I realize the problem itself would need a more thorough and precise formulation to be tackled, as in the above we deal with full real numbers (so "hiding" information in a single real number, say the weight of a node in the middle layer, would give a very easy way out). But with this dealt with appropriately, hopefully there are non-trivial statements to be made with regard to what compression can be achieved, with respect to some distribution over the inputs? Has this type of question been looked at from a theoretical viewpoint, in our community or another? 

Using the relation between total variation and $L_1$/$\ell_1$ distance of the probability/distribution/mass functions, we have $$\begin{align} d_{\rm TV}(D_1, D_2) &= \frac{1}{2}\lVert D_1-D_2\rVert_1 = \frac{1}{2}\lVert \beta D_2 +(1-\beta)D_3 - D_2\rVert_1\\ &= \frac{1-\beta}{2}\lVert D_3 - D_2\rVert_1 = (1-\beta)d_{\rm TV}(D_2, D_3). \end{align}$$ 

The classic Markowitz model is a quadratic programming problem. I'm not sure at all about the state of current research, but one paper that might constitute a starting point is here: $URL$ By the way, there's a paper that's been making the rounds on related issues: "Computational Complexity and Information Asymmetry in Financial Products" by Sanjeev Arora, Boaz Barak, Markus Brunnermeiery, and Rong Ge. The latter has posted it along with some additional comments here: $URL$ I tend to think the results are of theoretical interest but don't explain anything that actually happened. My suspicion is that complexity is not the main barrier in most models (generally, anything complicated gets turned into a monte-carlo eventually anyway, and generally things get complicated fast -- so yes this opens the way to certain malicious attacks, but maliciousness in the financial world can much more easily be much more crude, general, and straightforward) so much as many other, generally well known critiques of these models (sometimes from an information theory standpoint) that aren't really appropriate for this forum. 

Don’t Stop the BIBOP: Flexible and Efficient Storage Management for Dynamically Typed Languages, by R. Kent Dybvig, David Eby, and Carl Bruggeman I am not a Number—I am a Free Variable, by Conor McBride and James McKinna Initial Algebra Semantics is Enough!, by Neil Ghani and Patricia Johann 

Edit: As pointed out in the comments by Denis Pankratov, the first variant admits a trivial $O(\log n)$ upper bound (sending $\lvert x\rvert$ to Bob is enough). 

On Universal Learning Algorithms, Oded Goldreich and Dana Ron (1997), Information Processing Letters, Volume 63, Issue 3, pp. 131-136. (see also the updated version) Adapting Levin's argument for the existence of an optimal algorithm for NP, the authors show that there exists a universal learning algorithm (in several learning settings, including PAC): "if a concept class is learnable, this algorithm will learn it, optimally." Beyond the result itself, and perhaps more strikingly, this is also (as pointed out and discussed in the paper) a great illustration of the dangers of abusing $O(\cdot)$ notations and asymptotics. 

There is a second proof, somewhat more fun, given in that short note (credit to John Wright for pointing it out, and emphasizing it's the "fun" one). Here it is: Proof. Again, we will analyze the behavior of the empirical distribution $\tilde{p}$ over $m$ i.i.d. samples from the unknown $p$. Recalling the definition of total variation distance, note that $d_{\rm TV}({p,\tilde{p}}) > \varepsilon$ literally means there exists a subset $S\subseteq [n]$ such that $\tilde{p}(S) > p(S) + \varepsilon$. There are $2^n$ such subsets, so we can do a union bound. Fix any $S\subseteq[n]$. We have $$ \tilde{p}(S) = \tilde{p}(i) = \frac{1}{m} \sum_{i\in S} \sum_{j=1}^m \mathbb{1}_{\{s_j=i\}} $$ and so, letting $X_j \stackrel{\rm def}{=} \sum_{i\in S}\mathbb{1}_{\{s_j=i\}}$ for $j\in [m]$, we have $ \tilde{p}(S) = \frac{1}{m}\sum_{j=1}^m X_j $ where the $X_j$'s are i.i.d. Bernoulli random variable with parameter $p(S)$. Then, by a Chernoff bound (actually, Hoeffding): $$ \mathbb{P}\left\{ \tilde{p}(S) > p(S) + \varepsilon \right\} = \mathbb{P}\left\{ \frac{1}{m}\sum_{j=1}^m X_j > \mathbb{E}\left[\frac{1}{m}\sum_{j=1}^m X_j\right] + \varepsilon \right\} \leq e^{-2\varepsilon^2 m} $$ and therefore $\mathbb{P}\left\{ \tilde{p}(S) > p(S) + \varepsilon \right\} \leq \frac{\delta}{2^n}$ for any $m\geq \frac{n\ln 2+\log(1/\delta)}{2\varepsilon^2}$. A union bound over these $2^n$ possible sets $S$ concludes the proof: $$ \mathbb{P}\left\{ \exists S\subseteq [n] \text{ s.t. }\tilde{p}(S) > p(S) + \varepsilon \right\} \leq 2^n\cdot \frac{\delta}{2^n} = \delta $$ and we are done. $\square$ 

Riffing on jbapple's excellent answer regarding , but using (which is built on) instead, I came up with the following: 

This isn't a direct answer at all, but are some potentially useful connections to draw/research programmes to be conducted along the lines of Stay and Baez' work on algorithmic thermodynamics: $URL$ Do take note, however, that this work does not draw out actual physical consequences -- rather it illustrates a connection that is, thus far, purely mathematical. 

The collection is the union of the three individual elements, which is to say . Also, wikipedia: $URL$ 

My sense is that SPJ was referring to purely functional languages -- i.e. languages which are referentially transparent. This includes, e.g., Haskell, Miranda, Clean, but not ML. Once you have a purely functional language, in general, you can give it a fairly clean and well defined denotational semantics. This semantics will, in general, look like one for the lambda calculus, with some tweaks here and there. Generally, you will have a type system which desugars to something resembling a variant of System F -- perhaps more powerful in some regards, more restricted in others. This is why code extraction to/compilation to Haskell, O'Caml, etc. is relatively straightforward from sophisticated dependently-typed proof assistants such as Agda. Within that framework, there's lots of room for play. Certainly, there is still a difference between a non-strict and a strict language. However, in the absence of side-effects, the only difference is that a non-strict language contains more expressions which do not denote bottom -- insofar as the two evaluation strategies both do not yield bottom, they agree. Simon's statement also fits in a very important historical context. At the time of the birth of Haskell (1987), there were a panoply of non-strict functional languages -- not only Miranda, but Lazy ML, Orwell, Clean, and many others. Aside from certain syntactic variations, they all were very much the same language. Which was precisely the motivation for the Haskell Committee to form. For more on this, see "A History of Haskell: being lazy with class": $URL$ 

Coq and Matita are still pretty close to this LCF principle. Isabelle is different here: as early as 1989, Larry Paulson reformed the notions of goal and tactic to make them closer to the logic, which is the "Pure" logical framework of Isabelle here. Isabelle/Pure provides minimal higher-order logic with implication ==> and quantifier !! which indicate both the structure of natural deduction rules and goal states. For example, ⊢ A ==> B ==> A ∧ B is the conjunction introduction rule (of the object logic) as theorem of the logical framework. Goal states are just theorems as well, starting with ⊢ C ==> C for your initial claim C, which is refined to ⊢ X ==> Y ==> Z ==> C in intermediate states, where X, Y, Z are the current subgoals, and the process ends with ⊢ C (no subgoals). Now back to tactics, which are more uniform for all these provers: given some notion of goal state (e.g. the Isabelle one above), a tactic is a function that maps a goal state to (0, 1, or more) follow-up goal states. Moreover, a tactical is a combinator of such tactic functions, e.g. to express sequential composition, choice, repeat etc. In fact, the language of tactics and tacticals is related to the "list of successes" approach of parser combinators. Tactics allow to describe certain strategies of goal refinements systematically. They turned out quite successful since their invention in LCF in the 1970/80-ies, but they produce notoriously unreadable proof scripts. A recent overview of some aspects of tactic languages is given in the paper by A. Asperti et al, PLMMS 2009, see workshop proceedings page 22. Mizar and Isabelle/Isar have been mentioned as alternative approaches to human-readable structured reasoning, and they are not based on tactics in that sense. Mizar is unrelated to the LCF family, so it does not know that tactic terminology. Isabelle/Isar incorporates the tactical tradition to some extent, but its notion of proof method is a bit more structured (with explicit Isar proof context, explicit indication of chained facts, and avoidance of internal goal-hacking in the course of reasoning). Many more reforms and reconsiderations of tactic languages have happened in the past decades. For example, a recent branch of the Coq community favours SSReflect (by G. Gonthier) instead of the traditional Ltac. 

Columnar stores. There are some great papers on the topic from the c-store project: $URL$ The most interesting thing about columnar stores is that many operations can be performed directly on compressed data. 

(in a slightly more efficient version) is already defined and used internally in for constructing finger trees that are results of sorts. In general, the intuition for is simple. is built on top of the applicativeTree function. takes a piece of a tree of a size , and produces a well-balanced tree containing copies of this. The cases for up to 8 (a single finger) are hard coded. Anything above this, and it invokes itself recursively. The "applicative" element is simply that it interleaves the construction of the tree with threading effects through, such as, in the case of the above code, state. The function, which is replicated, is simply an action which gets the current state, pops an element off the top, and replaces the remainder. On each invocation, it thus steps further down the list provided as input. Some more concrete notes 

The concept is simpler than you think. Assuming 8 bit words and a bitvector of only one word length, 

On some simple tests, this yielded an interesting performance tradeoff. The main function above ran almost 1/3 lower with myFromList than with . On the other hand, used a constant heap of 2MB, while the standard used up to 926MB. That 926MB arises from needing to hold the entire list in memory at once. Meanwhile, the solution with is able to consume the structure in a lazy streaming fashion. The issue with speed results from the fact that must perform roughly twice as many allocations (as a result of the pair construction/destruction of the state monad) as . We can eliminate those allocations by moving to a CPS-transformed state monad, but that results in holding on to far more memory at any given time, because the loss of laziness requires traversing the list in a non-streaming manner. On the other hand, if rather than forcing the entire sequence with a show, I move to just extracting the head or last element, immediately presents a bigger win -- extracting the head element is nearly instant, and extracting the last element is 0.8s. Meanwhile, with the standard , extracting either the head or last element costs ~2.3 seconds. This is all details, and is a consequence of purity and laziness. In a situation with mutation and random access, I would imagine the solution is strictly better. However, it does raise the question of whether there is a way to rewrite such that is strictly more efficient. The issue is, I think, that the applicative actions are executed in a different order than the tree is naturally traversed, but I haven't fully worked through how this works, or if there is a way to resolve this. 

[1] Erik Waingarten and Amit Levi. Lower Bounds for Tolerant Junta and Unateness Testing via Rejection Sampling of Graphs, 2018. arXiv:1805.01074 [2] Eric Blais. Improved Bounds for Testing Juntas. APPROX-RANDOM, 2008. [3] Roksana Baleshzar, Deeparnab Chakrabarty, Ramesh Krishnan S. Pallavoor, Sofya Raskhodnikova, C. Seshadhri. Optimal Unateness Testers for Real-Valued Functions: Adaptivity Helps. ICALP, 2017. [4] Xi Chen, Erik Waingarten, Jinyu Xie. Boolean Unateness Testing with $\tilde{O}(n^{3/4})$ Adaptive Queries. FOCS, 2017. 

A FOCS'15 paper by Lee, Sidford, and Wong [LSW15] can be leveraged to obtain such minimization guarantees -- cf. Section 5 (specifically, Corollary 5.4) in our recent paper ([BCELR16]). 

For a Boolean function $f\colon\{-1,1\}^n \to \{-1,1\}$, the influence of the $i$th variable is defined as $$ \operatorname{Inf}_i[f] \stackrel{\rm def}{=} \Pr_{x\sim\{-1,1\}^n}[ f(x) \neq f(x^{\oplus i})] $$ where $x^{\oplus i}$ is the string obtained by flipping the $i$th bit of $x$. The minimum influence of $f$ is then $$\operatorname{MinInf}[f] \stackrel{\rm def}{=} \min_{i\in[n]}\operatorname{Inf}_i[f].$$ Given a parameter $p\in[0,1]$, we choose a $p$-random function $f$ by choosing its value on each of the $2^n$ inputs independently at random to be $1$ with probability $p$, and $-1$ with probability $1-p$. Then, it is easy to see that, for every $i\in[n]$ $$ \mathbb{E}_{f}[\operatorname{Inf}_i[f]] = 2p(1-p) $$ and a fortiori $$ I_n(p) \stackrel{\rm def}{=}\mathbb{E}_{f}[\operatorname{MinInf}[f]] \leq 2p(1-p). $$ My question is: 

Place all the queries in conjunctive normal form. Decompose the set of CNF queries into a tree (with the head simply being True), where each terminating node is labeled with the query that path represents. We now only needs to walk further down those branches of the tree for which the head is satisfied. This creates a new question -- by which criteria can we judge which trees are better than others? I tend to think a greedy algorithm will give a good approximation for minimum nodes (if the remainder of clauses of a given query are unique, they can of course be packed into a single node), but more interesting would be something which took into account the expected distribution of inputs. That's for the general case of boolean formulas, of course. For any specific type of query, such as just substrings, I imagine there would be various things that can be done. Edit: In fact, for queries (or portions of queries) which can be represented as regular expressions, one can use the techniques presented in A Play on Regular Expressions and take the union of these regular expressions over a semiring which counts matches to each original query.