Browser connects from a random high (i.e. > 1024) port on your computer to a remote server's port 80. Therefore there's no port conflict on your machine. If you use many tabs to connect to the same remote server (or there are many users connecting to the server) they all go to the same port and are serviced by the same process (i.e. the web server of the site). 

All layers of the storage stack have to support trim. After all only file system layer knows, which blocks are safe to be wiped. This post on the ext4 developers list with patch for elements of trim functionality in ext3 strongly suggest that such work is being done already. 

To the best of my knowledge TCP/IP stack will short-circuit any communication between any local interfaces. Therefore no package will ever be sent or received over the link. 

This thread may give you some insight into ext4 file placement algorithm. has a function, which seems to give the data you want. You should be able to give it consecutive blocks of a file and get the physical block numbers. 

This Symantec kb article may have solution to your problem. Alternatively, depending on your license, see this community thread. Googling for your error message gives a lot of articles with possible causes and solutions. 

This isn't a situation I'd like, and the answer depends on your definition of "coexist". There cannot be hosts with the same address, i.e. if host A has address 192.168.3.5/16 and host B has 192.168.3.5/24 and they will try to live on the same Ethernet segment, they'll cause IP address conflicts. When you send a packet over IP network, you do not specify a subnet, only the IP address. Subnets are a tool for routing, so if A and B live on different Ethernet segments, only B will receive packets, because routers will choose the one with the longest mask. Actually, about the only situation, where I would expect definition of both 192.168.0.0/16 and 192.168.x.0/24 to appear would be a routing table. I could imagine, that hosts on the /24 subnet are in separate place, and need special definition of routing. In that case it is a normal, acceptable thing. About any other is something weird, or at least I cannot think of a rational justification of such a config right now. 

Definitely large RAM, speed be damned. Access to random data for RAM technology from XX century '90 is below 100 ns. That's using practically ancient chips that won't even physically fit into anything borderline contemporary. Access to random data for cutting edge 15k rpm hard drives is in measured in miliseconds. 100 ns is 10 000 times shorter (nano -> micro -> milli) than 1 ms. Current RAM is faster, and HDD needs several milliseconds to access data. I couldn't care less if my RAM was 50 000 faster or only 30 000 times faster than HDD, if I could get more. 

Therefore, it looks that you have just client installed. You can get a list of files in the package with . If you run you will get list of files in bin/sbin directories, which will be binaries. Chances are your client is not named mysql. To install the server from command line run . 

Performance characteristics I'm going to assume RAID 10, because in my opinion it has all advantages and no downsides in your scenario. You are going to be limited by a performance equivalent of a pair of HDDs. In other words you are going to be able to serve/write data at about 2x what a single HDD can do. For streaming you should be able to saturate 1Gbps link with no effort (reading or writing). For bursty data you are stuck with ~150 IOps (assuming 7.2krpm SATA drives). RAID 10 will guarantee that the load is spread among all drives for all I/O (unless you are unlucky enough to have application access data with a stride matching your RAID chunk size), and RAID 10 "far" layout should give you similar performance no matter which region of filesystem you are accessing. Lost drive means marginal loss in read access time (you loose the "far" layout benefit for the affected mirror pair). If you expand the storage with another pair of mirrored drives will not be able to reshape the data to re-stripe it over the new space. Effectively you have a RAID10 + RAID1 setup, unless you backup, re-create the array and restore. 

The only method is to destroy and re-create the array with new parameters. Neil Brown have written in his recently published road map for md: 

I do not think it would be a bug in the ext3 code, because it's been around for a while, but do you use any exotic mount options? Do you have 4K block on the storage? Anything exotic? Did the server ever work OK? If so, can you name the change, that caused it to start failing? If you are going to troubleshoot it yourself, then your best bet would be to make a minimal set of options that makes the system fail. More practical approach could be to re-organise your storage so that you use only one vendor's storage at any given server. This could save you a ping-pong between vendors. Your best bet, however, would be to contact your OS vendor and make them drive the case, I think. 

My guess is, that the uplink from THE client so bad, that the data POST never completes. Because the data was never sent, the application never got it. I sometimes have problems sending data when hooked up via a mobile (GSM) modem. The same sites work perfectly when I'm connected to a decent uplink. 

Add a cron job writing a time stamp into the log every n (possibly n == 1) minutes? Will not help figure the reason, but it could help figure out if shutdown time is correlated with the time you leave your machine or it always turns off at the same time. Another idea: move /sbin/shutdown to /sbin/shutdown.bin and create a shell script /sbin/shutdown which tells you what called shutdown, (find parent process id from $PPID, run ps auxwww to find out who's messing with the system, save pstree output and generally call the cavalry). This way you should be able to catch the offender red handed. 

If the time to restore data isn't prohibitive, then re-installing from scratch will be faster and less error prone. I'm not sure what is your planned final setup, but if you intend to use all 3 disks, you could do 3-disk RAID 1 for /boot partition, and have the rest of the disks set up in RAID 5, if it's acceptable performance-wise for you. 

A knee-jerk reaction: check (with telnet) if your ISP doesn't block outgoing mail ports (25 and 465). Make sure your firewall allows outgoing connections to TCP ports 25 and 465. 

RAM. In and of itself 4x the amount of RAM is a winner for any DB use. More cores. I don't think, that your major bottleneck is going to be CPU performance. More cores means that you can have more threads doing their work. 

If you decide to go via route 3, you again have several options :). Just note, that DNS servers are a crucial piece of infrastructure -- if they fail then people will be unable to reach anything within your domain. Also note, that to have your own DNS server, you have to own a domain. This means, that if you want to have a server in domainone.com you have to own the whole domain. If your host is alpha.domainone.com, but someone else owns beta.domainone.com, then you have to have the same server. There are several ways to get your DNS servers point where you need: