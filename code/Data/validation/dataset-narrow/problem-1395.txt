UPDATE2: Finally, by trial and error, I managed to get this thing working. The problem was that the cubemap texture is mirrored, so I had to scale the regular projection matrix by (1, -1, 1) in order to un-flip it. Also, the right vector to read cubemap is . Now everything seems to be working nice! 

Let's say, that I have 3 programs, and in each of those programs there is a view matrix uniform, which should be the same in all those programs. Right now, when my camera moves, I need to re-upload the modified matrix to every program separately. Is it possible to create some kind of global uniforms which are constant for all programs linked to it, so I could just upload the matrix once? I tried creating a globalUniforms object which looked kinda like this: 

We go through all of your example pictures with my parent/child system. Picture 1 - 1 Entity Keeps falling till Picture 2 - 3 Entities Green Entity and yellow Entity fall red entity is . Let's assume green entity has a higher velocity then the yellow one and hits yellow before any of both get's grounded. Green Entity detects a collision with yellow. We decide (because mass doesn't care for you) that green as first entity get's the new parent. So we set for yellow the parent as green and for green the child to yellow. Next they keep falling. Yellow is no longer moved or done collision detection because it has a parent. We move green and ask if has children and use both data for collision detection and movement. We detect a collision of 1 child, yellow collided with the floor. So we set it to be grounded, remove it from the parent and set it has no parent. Next we do this for green, it collides with yellow, has no children anylonger so just set it as grounded. Done. Picture 3 - 2 Entities We detect a collision between green and red. We take green as the first entity of our list and set the children as red and on red the parent as green. Next we do collsion and movement only for green, because red has a parent and so will not be used in collision detection and movement. Green hits the ground and will be marked grounded. Green has children so we remove the children and set their parents to be null. Next we check red and detect a collision with green. we set green as parent of red and it is no longer part of the collision detection. But it is not grounded. As soon as green get's removed from the board, we free red and red will eventually start falling again till also grounded. Picture 4 - 3 Entities Red/Green is the same as on Picture 3. Green detects a collision with it's children against yellow. Yellow is grounded and has there for the "master" right. So we set Green with it's children as a child of yellow. They are no longer used for collision detection, as long as yellow exists. If yellow get's removed of the board, remove the children of yellow and set their parents to null, and they start falling again. Picture 5 - 3 Entites If we assume yellow falls faster or red or both have same velocity doesn't care. The algorithm is allways the same. We assume red falls faster. We detect a collison between yellow and red. yellow will the get the parent because first in the entity list. Next we detect a collision of yellow's child with green. We set green as the parent of yellow because green is grounded and so the master. We free all children of yellow because yellow is connected of a master/grounded entity. We also free yellow of green because it is no longer colliding with green. So yellow starts falling again and detects a collision between yellow and red. But red is connected to a master/grounded entity so we set yellow as a child of red and red as a child of green and set on all Picture 6 - 3 Entites Same as picture 5. 

Finally, by trial and error, I managed to get this thing working. The problem was that the cubemap texture is mirrored, so I had to scale the regular projection matrix by (1, -1, 1) in order to un-flip it. Also, the right vector to read the cubemap is . Now everything seems to be working nice! 

First of all I must say, that I have read a lot of posts describing an usage of cubemaps, but I'm still confused about how to use them. My goal is to achieve a simple omni-directional (point) light type shading in my WebGL application. I know that there is a lot more techniques (like using Two-Hemispheres or Camera Space Shadow Mapping) which are way more efficient, but for an educational purpose cubemaps are my primary goal. Till now, I have adapted a simple shadow mapping which works with spotlights (with one exception: I don't know how to cut off the glitchy part beyond the reach of a single shadow map texture): >>>glitchy shadow mapping<<< So for now, this is how I understand the usage of cubemaps in shadow mapping: 

For this to be handled correctly you need to design your network protocol to do something called "continuous transitions". Client send's all time packages to the server with a order. This way the server has always the last state of the client, regardless of lag or lost packages. Next step is you need to analyze the packages arrived. Back to your jump example. The user presses the jump button, and the client sends the following packages: NKP = No Key Pressed JKP = Jump Key Pressed [NKP] -> [JKP] -> [JKP] -> [JKP] -> [JKP] -> [JKP] -> [NKP] ... Each package has a order. So the server receives JKP and start's to update physics. Now the server doesn't receive packages of the client for any time. Now u have 2 possibilities 

In a second pass, calculate the projection a a current vertex using light's projection and view matrix. Now I don't know If should I calculate 6 of them, because of 6 faces of a cubemap. ScaleMatrix pushes the projected vertex into the 0.0 - 1.0 region. 

In my fragment shader I have passed an uniform int variable, which indicates what type of light is in usage right now. The problem is that if-else branching does not work correctly - the fragment shader performs instructions in every statement block. 

You're calculating the up vector (and also the rest of them) from a matrix unrelated to the matrix, in which you have stored the new rotation. Usually, what I do is multiply an old rotation matrix by the new rotation matrix, and then calculate the up vector from the outcome matrix. Hope this helps. 

In the first case, what is happening, is exactly what people hate, when a lagging person enters any shooter game, that uses this prediction behavior. They start teleporting short distances. In the other case, what is happening, is exactly what people see, when they cry for lagging server, because their characters start to flicker or teleport back. You need to find the best prediction timings for your game design. 

Actually that is not that hard. As I don't know your complete design, I will just talk a bit more general. I assume, each block construct as an independent enitity. So in picture 2 as an example, you would have 3 entities. I also assume, that your design includes mass for each entity. If all this is correct then next will help you. As soon as 2 entities collide, determine the one with the bigger mass. This entitiy transforms into the parent entity of all other entities colliding. So now they all move no more independent, they are driven by the parent. The velocity break if 2 objects collide is a physics based calculation. After the collision just move the parent with it's break down velocity. When another collision is detected to the calculation again, but update the mass of the parent object to have the mass of all children too. 

Also, when I manually create an int variable (which is not an uniform) like this: and replace with it in the if-else branch, everything works fine, so I guess it have something to do with the fact that is the uniform. 

Could you give me some hints or examples (preferably in WebGL code) how I should build it? UPDATE: I figured out that view matrices are superfluous in the case of program rendering the scene with shadows. One can read the adequate texel from the shadow cubemap by using one of those vectors: or (right now I don't know which is the correct one, because both gives a not complete shadowing result - the first one mirrors the shadow and doesn't display anything from the -Y light cubemap face while the second one displays the bottom face correctly, but it does right only that: >>>img here<<<) 

To be honest, I can't even imagine a single scenario, where with well implemented client interpolation an input lag would be perceivable. Just to counter check - Client Interpolation summarized 2 Concepts meet up 1) The Interpolation itself - let the client live in the past (ae 100ms) 2) The client sends every data with a timestamp, and the server has to keep the data of all entities for some time (ae 500ms). Now for actions, that depend on other entities, like shooting, the server now can verify the position of the other entities via the timeline and the send timestamp of the client. With these 2 concepts merged together, you have a working, well implemented client interpolation. So first of, if your current implementation doesn't meet the mentioned requirements then change it. If you have both methods working fine, I will need more information to assist you in locating the problem. 

I have read that in order to optimize WebGL application, one should reduce an amount of draw calls. But does it mean that computing a one big mesh from all single meshes on CPU by modifying vertices position (which I heard is much slower than GPU while talking about matrix multiplications) and calling the draw call once would be faster than drawing every single mesh using model matrix inside GPU, calling the draw call for each one of them? 

While coding my WebGL app I've encountered an interesting phenomena: On my first PC (with GPU Radeon HD 5850), BrowserLeaks (link) tells me that in my browser - Google Chrome Version 36.0.1985.143m the Max Vertex Uniform Vectors value equals 1024 - which is true, when I try to create inside the shader an attribute array bigger than 1024, the browser throws an error: , which f.e. in my case let's me draw about 85 simple cubes in a single draw call. Meanwhile on my other PC (with GPU Intel X3100) with Opera-Next Version 12.15 installed, where BrowserLeaks shows a value 4096 next to the Max Vertex Uniform Vectors field, I can init an array of size 250 000 and even bigger, I can draw 20 000 cubes in a single draw call and everything works fine (except a very low framerate). So now my question is: Why those numbers varies so much, why in the second case the upper limit value does not seem to be valid? How would I find the true upper limit value (and read it inside my WebGL app at the runtime)? EDIT: Ok, I've found out how to get this parameter inside a WebGL app: , but the question now is how would I adapt it to shaders... 

Check if entity collides with another entity Check if the colliding entity is a "grounded" one If not grounded determine one as parent and set the rest as children If grounded free all children and do collision again for all If grounded and not children, set as children of grounded. If colliding with ground - free all children and set grounded 

It seems like you are missing to move the transformation of the player high enough. like on the picture I think the problem is, that you set a jump height according to the animation and not to the player without animation. So jump height looks fine when in crouch position, but when u turn of the animation, you will see, that the player model jumps way to less high. I think this is your problem. So just fix the jump height and all will be fine. As a side node, an animation should allways be applied only, when the actual movement is ok. So in your example, only when the player model jumps correctly to its complete transformation, then apply an animation for the whole duration of the jump.