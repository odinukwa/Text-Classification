... and that's what the config guide suggest. I suspect the problem is on the netflow analyzer side. Please verify that PRTG actually supports netflow lite. My current understanding from what I can find at paessler.com is that netflow lite is not directly supported, and that eventually, you might need to convert netflow lite to classic netflow with some kind of itermediate service (such as $URL$ Using one of the tools at $URL$ might help with the analysis. One more thing: Instead of naming at least three related config items "toPRTG", I suggest using a config style as outlined below. It helps to track what is what, and to keep track of all the needed config bits. In short, it helps to understand the config concept. We use similar config styles in larger multi-tenant QoS configurations (that we maintain manually), so we can keep track of the per-tenant class-maps and policy maps, the ACLs to go with it etc. In general, we put a Prefix in there describing what kind of config item it is, the customer's name and the name itself. This then might look like this: PM_QUE_CUST01_WANPOLICY01 or CM_QOS_CUST04_REALTIME-TRAFFIC. So here's what I suggest for a netflow config: 

That is a must-have when running PPPoE, each IP packet on interface FastEthernet4 will get an additional PPPoE header of 8 bytes, so you want to reduce MTU for interface dialer 0. 

NVI NAT's already been brought up by Aaron D. Here's a the relevant config bits of a working example. It's been done on a CISCO881 with IOS 15.4(3)M6a 

To rephrase ar_'s answer - please give the credits to him, if you are going to award them. Copy the configuration section with the "interface vlan XXX" statements into a text file. That will look somewhat like this 

8. other clever bits to have There's some clever config bits here and there, and I'll comment them here 

Hint: If anyhow possible, stay away from the "1" numbers for dialer pools and dialer lists, even more so when access list numbers come into play ("access list 1 permit ...") on top of that. It makes the configuration confusing to read, especially to the novice. I have no clue why Cisco's examples and documentation stick to that numbering style. By all means, do prefer named items (e.g. in ACLs) or pick "random" numbers that can easily be matched by a human reader, even when they're dozens or hundreds of lines away from each other in a config file. 

proxy-arp is a networking black witch I will personally burn at the stake whenever I come across her. Her magic is only needed in dark corner cases - leave it disabled, unless you really, really, need it. However, ip unreachables are a blessing when it comes to reduced-MTU links as in your case. They make sure that the router can inform a host to send smaller packets - especially for UDP applications; TCP is taken care of by ip tcp adjust-mss. Unfortunately, not all hosts will respect or understand these "packet too big" messages, but that's their problem. ip verify unicast reverse-path is good best practice, it prevents ip source address spoofing, by allowing only those source address ranges (incoming) on an interface for which a route exits in the reverse direction through that same interface. That makes it harder for your internal systems to be part of a bot army working with spoofed source adresses. 

Caution: NVI NAT can be VERY taxing on the CPU of low-end routers like the 800 series. Where my old 881 used to be able to deliver 50-60Mbit/s with classic NAT, switching over to NVI caused the throughput to drop to 20-30Mbit/s and would have the CPU glowing red when under load. That was also the case when the to-be-hairpinned translation was not actually in use, just with traffic matching the normal "interface ... overload" outbound NAT rule. 

You could consider "inside source NAT"-ing this particular incoming traffic into two seperate source NAT address or (better) address pools of private addresses, each implemented by firewall cluster 1, resp. 2. So not only would this traffic be destination NATted when coming in (making the server's private address reachable via a public address), but also source NATted. Then, from the core switch, route source address pool1 to firewall cluster 1 and source address pool 2 to firewall cluster 2 (possibly with static routes, but eventually, that's up to your internal routing setup). While technically feasible, there are several important caveats that come with this proposal: 

To me, this looks perfectly normal. I don't think that these captures are identical. Looking at the TCP headers of the the first frame (TCP SYN), you can see that - although all other properties are identical - the sequence numbers are different. EDIT: Oh.. there is also MSS clamping going on - ASA rewrites the MSS field from 1460 to 1380, on both the SYN segment from the initiator and the SYN-ACK segment from the responder. I think this is ASA's TCP sequence number randomization at work. EDIT: And the ASA performs some TCP MSS manipulation, too. Other than that, I would sincerely hope that all other properties of the frame/packet are unchanged when it is incoming through one of the port channel's subifs and exiting through the other (give or take NAT rewriting things a bit here and there, but NAT is quite obviously not in use here). 

You're (192.168.0.164 ) directly connected to the switch (10.168.0.106) you're SSH'in into and you get dup ACK and retransmit... There is something not right , seems that the Network Gremlins are hungry. What does the switches error counters say? Also note that some devices puts traffic to/from the control plane at a lower priority than the data plane. SSH directly to the switch might not reveal the problem you think it's revealing. What about connecting to something else on the switch, do you see the same symptoms? 

Simply addressing the connectivity of Ethernet cable, for short one as long as you use the same pairs at the same position it's OK. For longer ones, you might have some crosstalk issue if you do it "however you want as long as it's the same pairs at both ends" TIA/EIA-568A & B are only conventions to help everyone work together with less headache, there are no UTP-Police that will check your setup. Sure, they're supposed to be optimized (alternating signal/ground strands in the connector, centering Pair 1 to be able to use it for telephony if needs be, etc) but it's not like each pairs will refuse a signal if it's not at the right position in the connector. Also, if you follow the standard, it's quite easy to differentiate Straight/Roll-Over/Cross-Over cables. It's the same thing as the Jacket color (In UTP structured cabling. Fiber jacket color actually means something). Even if the cables are Blue, Red, White or Black, they're still an Ethernet Cable (barring rolled-over or crossed-over ones), meaning you can use whichever colors you like, but it's still a good idea to be able to see their function by using different colors (as long as you stick to it!) 

Quick test: Swap the SFPs with a known working ones on the switch (if possible) and see if the condition stays with the ports or follow the SFPs. If the other SFP works in the current "problematic SFP ports" there is less possibility of this being the switch's problem (I still could be, but just unlikely). You can try to plug it in the other switch's too... if it's problematic there, it's almost guaranteed to be the SFP, unless you got the One-In-A-Million chance of having two switches with exactly the same freaking bug - extremely unlikely If after all that JTAC still insist for RMA on both switches, just escalate the issue to get someone more reasonable at their end. Edit: I've just seen that it was a mislabeling issue, you might want to mark this question as answered. :) 

If you do not have any Layer 3 interface on the actual VLAN, you won't really be able to see any IPs going on. One way would be to do port miroring and sniff the packet to see what IP's going through, but it might not give you a complete picture either 

($URL$ ) Then you control the announcement by your ISRs to your L3 switch with IP SLA Monitor on the 2951 to track some public IPs and modify the announced route, so that if one cannot reach the Internet (router/link is UP but ISP has routing problems) you'll stop advertising internally the bad link. ($URL$ For your FTP, you can use Policy Based Routing on your L3 switch to bypass routing and force FTP traffic to use all outgoing FTP traffic on a single link ($URL$ If you're ever looking for a hardware solution that does pretty much all this, take a look at Radware's Linkproofs, at least id did a few years ago. 

I don't know Brocade's device specifically, but the config seems pretty straightfoward. Are you using Trunking (802.1Q) to have multiple VLANs between your switches? You seem to have more than one VLAN on the swich (150 + default) but only the default VLAN on your uplink port. If that's the case and the Brocade automagically puts phones on VLAN 150 (Voice VLAN), their DHCP request will never be able to reach the other switch unless you're using IP Helpers, in which case, you seem to be missing IP addresses on your vlan interfaces. So, if you're switching to the DHCP Server, there are VLANs issues (802.1q missing) while if routing to the DHCP server, there is no IP addresses on any interfaces, meaning it has no way to send/receive IP packets (no IP interfaces, no IP communication) 

QoS is of no use if the traffic is going on the Internet, simply because almost no ISP is acting on QoS markings (in fact, it's normally stripped automatically when entering their network) For QoS to be useful at all, all nodes in the path (routers, switches, etc) mustn't reset the marking and also must ACT on it (ie: if you have "DSCP EF" marking - normally used for Voice & Video, if the switch doesn't strip it but doesn't prioritize those packets, it doesn't help) That is why your Network team told you that they can't do anything - unless there are some network bottleneck on your own network, if you go out the Internet where QoS isn't used, everything is "Best Effort" and every stream is (supposedly) treated equally (your Sharepoint traffic isn't more important to your provider than your're co-worker web requests). Even if you had a special understanding with your provider, they're connected to others and so on and so forth, until you reach the Sharepoint servers. If any LINK used to reach those doesn't support QoS, then you have NONE. TL;DR: QoS is NOT supported on the Internet at large