Some SSD firmwares are optimized for the access patterns of NTFS and FAT, but I'm unsure if this is the case here. 

Sounds like you want a VPN connection/tunnel between servers 1 and 2. And then a reverse proxy (nginx/apache/haproxy/varnish/...) on server1 that forwards all requests over the tunnel to server2. 

I run OpenWRT at home and really like it. But I do get the occasional hangup. Maybe once in a week. Haven't had one in a while now though. 

Unix filesystems don't like being full. Try growing the slow filesystem. If that's not possible, try defragging it using xfs_fsr 

The problem is that everyone has a slightly different idea of what is the perfect setup. We use Puppet for configuring new nodes and there are some reusable puppet modules in puppet forge, but we usually end up customizing them. I've been meaning to write an article about setting up puppet, but real work prevents me from progressing. 

According to $URL$ it is important to align the virtual hard drives of virtual machines for performance. I'm running virtual machines in an environment built on Debian, KVM and LVM. What steps should be taken to get alignment right when installing a host node? How can the alignment be checked on an already installed node? Can the alignment be altered without re-installation? How? 

The IBM website has several articles about installing Linux in the "IBM System x3850 M2" model, specifically about installing RHEL 5 (Red Hat Enterprise Linux 5), RHEL 6, SLES 10 SP2 (Suse Linux Enterprise Server 10 Service Pack 2) and SLES 11. So, I guess that those Linux distributions, at least, are (or were) supported by IBM for that particular model. The articles are the following: IBM Installing Red Hat Enterprise Linux Version 5 - IBM System x3850 M2 (7141, 7144) $URL$ Installing Red Hat Enterprise Linux Version 6 - IBM System x3850 M2 and x3950 M2 (Type 7233, 7234) $URL$ Installing SUSE Linux Enterprise Server 10 SP 2 - IBM System x3850 M2 (7233) and System x3950 M2 (7233) $URL$ Installing SUSE Linux Enterprise Server 11 - IBM System x3850 M2 and x3950 M2 (7141, 7144) $URL$ Regarding the keybind combinations to start the installation, it seems you may find them in the section 4 of the articles above. Let me quote here the "4.0 Installing Red Hat Enterprise Linux Version 6" section from $URL$ 

There's at least chef, puppet, fabric, capistrano, cdist, bcfg2, cfengine and lots of other tools in this space. You can also just cook something together yourself using ssh, public key authentication and some creative scripting. 

Analyze the traffic of the other VPN software. Use tcpdump or wireshark or something similar. Don't guess, look. 

In most LDAP servers, the password is stored in the directory the server is hosting. I think it would be easiest to store the passwords in LDAP and authenticate RADIUS and everything else against LDAP. However, e.g. OpenLDAP supports SASL, so you can authenticate LDAP against something else, typically Kerberos. 

Yes. As long as you use TCP connections and not UNIX sockets. Make sure to encrypt the connections if there is any sensitive data. Or use a VPN. 

You might also want to check out Augeas, tool for programmatically modifying config files. It is very powerful in combination with Puppet (a configuration management system), but can also be used by itself. 

Hard-links can be very useful when you want to have the same contents (and same permissions!) in several files on the same filesystem. Take for example a package manager, that creates a /usr/share/doc/$packagename directory for each package that is installed and inside that directory a file called LICENSE with the license information of the package. Many packages on a typical Linux system are GPL licensed, so instead of having 200 copies of the GPL on the filesystem there could be only one copy and 199 links. Distributed version control systems copy the whole repository on clone, there is no checkout like in svn. If several clones of the same repository are on the same filesystem they can share part of the (immutable) files by using hard links (git does this, and darcs too IIRC). Many backup solutions also use hardlinks, like rsnapshot and backuppc. 

My question is the following: is there a way to see the RAID events history / log of the RAID internal controller (a "Smart Array P400")? I would like to be able to use "hpacucli" for that, but I can't find any related command in the Hpacucli Utility for Linux - All Commands Guide I may try to use other tools for this, if required (but not HP iLO - "Integrated Lights-Out" because I don't have that access), preferably avoiding any reboot. I have checked "/var/log/messages" but I haven't found any seemingly related entries there. 

To sign automatically all future git commits, you can define a global alias. For example, to create a global alias called "c", you would do this: 

Great. So this seems to be working in several cases (although I guess there may be more efficient solutions). So, how does this work? Here's the basic rundown for the "VAR_3" example... The first part - - returns the following output: 

Good. So it also works for single line cases! Does it work well if the string searched is NOT in the input? Let's try it for (that does NOT exist in the given example): 

The documentation states that the directories under SVNParentPath have to be repositories, so no looking through all subdirectories. You might be able to make script though, that would output several Location-blocks matching the parent folders of SVN repositories. 

Aptitude has easier to remember commands: vs. . It is still a good idea to install so that you will be given information about the changes in the updated packages and the option to cancel the upgrade. 

My previous answer, how to find out the answers: I'm looking at an Ubuntu 12.04 LTS system. udev handles device node creation. and only contain symlinks. matches several files. contains this line: 

readfds, writefds and exceptfds are all empty (NULL) timeout is 10 seconds. So it is simply waiting on nothing. 

Does rvm somehow link to the active ruby instance? That is, is there some sort of symlink called that points to whatever the active version happens to be? If so, then allow sudo for . Otherwise write a wrapper script (not in shell, but perl or python) that picks the right version and allow people to run that using sudo. 

The "" is for applying the sed command to the first line... And we want to NOT include that last line, so we pipe that output to the "head" command with the "" ("MINUS n") switch - specifically "" to exclude the last line: 

If I understand the question correctly, you want the "www" group to have 'read', 'write' and 'execute' privileges on the "/opt/apps" folder (directory) and subdirectories. In that case, use the command like this: 

(note that the commit switch to sign off is lowercase "-s" and NOT uppercase "-S", as you typed in your question). After having done this, you can start doing your commits using your newly created "c" alias. Here's an example of creating and commiting a file called "test.txt" that will be signed off by the committer: 

You can see that the commit has the "Signed-off-by:" line if you run the "git log" command with the option: 

So, to create a split zip archive, you could do the following (the "" is the "recursive" switch to include subdirectories of the directory): 

You probably want the sleepenh program, which allows for "accurate sleeping". There's also a blog post about how it was used to solve a problem which required no oversleeping 

Mac OS X has autofs, which, by default, is configured to do NFS automounts under . So you should be able to just . 

There's (8) which can be used to select the boot entry if you're using . If you're not using the default is which boots the first defined kernel. Usually the kernels are ordered from latest to oldest in order to boot into the latest kernel. 

According to wikipedia NFSv2 uses 32bit file size values, which limits it to 4GiB files, but apparently a common bug is to make the values signed, which limits it to 2GiB. NFSv3 also has async operations, and much optimised operations, so that less operations have to be done. This really has a big impact on performance, even on a LAN, since network latencies are something totally different from local machine latencies. NFSv2 should only be used if something doesn't support NFSv3. Try to find out why NFSv4 doesn't work. Maybe it's something you can fix. 

I have just checked a Windows Server 2003 computer with disks formatted in NTFS and indeed there is a "RECYCLER" hidden directory / folder in C:\ and, under that "RECYCLER" directory, there are several (also) hidden sub-directories with names started by "S-" I hope this helps. 

First of all, I knew about WMI - Windows Management Instrumentation - but I must admit I did NOT know about WMIC - WMI Command-Line :) I have found the following blog post that I think helps here: Rich's Blog - Get Process CPU Usage Using WMI $URL$ In that blog post, the author uses the Win32_PerfFormattedData_PerfProc_Process class to get the CPU usage of a process (in several ways). For instance, if the name of the running process is "iexplore" (Internet Explorer) then you would run: 

Raymond Chen, from Microsoft, has written the following "blog post": Why does the Recycle Bin have different file system names on FAT and NTFS? $URL$ From that blog post, let me quote the section that seems to be more relevant to this effect: 

Maybe you can do the following: have one open "Command Prompt" window where you run the "ftp command" and have another "Command Prompt" window where you run the query. I hope this helps. 

Check out what AnandTech has to say about SSDs. They seem to have understood their strengths and weaknesses right from the beginning. I'm still guessing that Intel X-25E is a safe bet, but maybe not the ultimate choice. 

Take a look at the Linux Terminal Server Project. With X11, you should be able to run an X11 server (the part of X11 that draws stuff on the screen) on your netbook and whatever X11 clients (firefox, libreoffice, almost anything, really, except software that needs direct access to hardware (OpenGL) or pushes a lot of stuff over from the client to server (video?)) you wish on your server, displaying their windows on your netbook. 

Try reading the logs on the server so that you can see the reason for rejecting your connection attempt. /var/log/auth.long on debian-based systems and /var/log/security on redhat-based. 

What file system are you running? Are journaling data or just metadata? It might be that the log file size (metadata) is extended and the change is journaled, but the log contents (data) isn't written yet. If the server then crashes or reboots the metadata is replayed from journal, but there is no data to recover so empty (zero) contents are shown. Do you use TRIM on your SSD? that would increase the likelihood of zero bytes (^@) 

So, that part basically matches everything between and the next ocurrence of . As we see, this part seems to be returning what we want... PLUS two things that we do NOT want: the "" in the first line -AND- the last line. So, we pipe this first output to another "sed" instruction that only applies to the first line, and we replace the string "" by nothing, effectively removing it: 

Here's a basic explanation of this awk command: : defines "|" (pipe symbol) as the field separator : only matches lines that start with "VAR_3" : prints the second field / column (that, in this case, contains the value that you want to print) UPDATE (Dec 3, 2015): So, the OP has added a clarifying comment, which leads to conclude that he wants the search to be multiline, considering the lines between two "tokens" as part of the value of the first token. Here's a revised version for the initial example, this time using the "sed" (2 times!) and "head" commands: 

Imagining your input is saved in a file called "test.txt", you can use "awk" with the following syntax: