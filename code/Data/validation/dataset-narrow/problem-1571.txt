In order to build those profiles, you need to map the "categories" and "keywords" that you have, which are too plentiful, into the features you think are relevant. Look into topic modeling or semantic similarity to do so. Once that map is built, it will state that all dollars spent on webs with keywords "gadget", "electronics", "programming", and X others, should all be aggregated into our first feature; and so on. Do not be afraid of "imposing" the features! You will need to refine them and maybe completely change them once you have clustered the users. Once you have user profiles, proceed to cluster them using k-means or whatever else you think is interesting. Whatever technique you use, you will be interested in getting the "representative" point for each cluster. This is usually the geometric "center" of the points in that cluster. Plot those "representative" points, and also plot how they compare to other clusters. Using a radar chart is very useful here. Wherever there is a salient feature (something in the representative that is very marked, and is also very prominent in its comparison to other clusters) is a good candidate to help you label the cluster with some catchy phrase ("nerds", "fashionistas", "aggressive moms" ...). Remember that a clustering problem is an open problem, so there is no "right" solution! And I think my answer is quite long already; check also about normalization of the profiles and filtering outliers. 

Or maybe you can create a new , similar to in the linked example, where some keys are kept for real-time results, and others for batch results. 

However, if you had some more features of each company, like the amount of money they received at each stage, or the profit they were making, then you could train a decision tree, e.g. with this implementation in sklearn, that told you, in simple words, "if a company arrived at round X with at least Y dollars raised and at least Z dollars of profit, then they are passing to the next round with 0.XX probability". Which is, I think, what you are aiming at. 

I think you will like the following two papers: Available from: $URL$ Nair A, Srinivasan P, Blackwell S, Alcicek C, Fearon R, De Maria A, et al. Massively Parallel Methods for Deep Reinforcement Learning. arXiv preprint arXiv:150704296 Available from: $URL$ Mnih V, Badia AP, Mirza M, Graves A, Lillicrap TP, Harley T, et al. Asynchronous Methods for Deep Reinforcement Learning. arXiv:160201783 

When explaining advantage function, it is usually claimed that using a baseline reduces the variance. I have not found any specific reference to justify this. Is this an application of control variates or something similar? Could anyone provide some reference or formal justification for the variance reduction? 

In Q-Learning, on every step you will use observations and rewards to update your Q-value function: $$ Q_{t+1}(s_t,a_t) = Q_t(s_t,a_t) + \alpha [R_{t+1}+ \gamma \underset{a'}{\max} Q_t(s_{t+1},a') - Q_t(s_t, a_t)] $$ You are correct in saying that the neural network is just a function approximation for the q-value function. In general, the approximation part is just a standard supervised learning problem. Your network uses (s,a) as input and the output is the q-value. As q-values are adjusted, you need to train these new samples to the network. Still, you will find some issues as you as using correlated samples and SGD will suffer. If you are looking at the DQN paper, things are slightly different. In that case, what they are doing is putting samples in a vector (experience replay). To teach the network, they sample tuples from the vector, bootstrap using this information to obtain a new q-value that is taught to the network. When I say teaching, I mean adjusting the network parameters using stochastic gradient descent or your favourite optimisation approach. By not teaching the samples in the order that are being collected by the policy the decorrelate them and that helps in the training. Lastly, in order to make a decision on state $ s $, you choose the action that provides the highest q-value: $$ a^*(s)= \underset{a}{argmax} \space Q(s,a) $$ If your Q-value function has been learnt completely and the environment is stationary, it is fine to be greedy at this point. However, while learning, you are expected to explore. There are several approaches being $\varepsilon$-greedy one of the easiest and most common ways. 

Both ways are valid and both are commonly used. Sometimes, a classifier that claims to be multilabel may just be separating the labels into multiple OneVsRest classifiers under-the-hood and conveniently joining the results together at the end. However, there are cases where the methods are fundamentally different. For instance, in training a neural net with multiple targets (labels), you can setup the structure of the network such that there is shared structure. The shared nodes will end up learning features that are useful for all the targets, which could be very useful. For example, if you're classes (labels) are "cat-pet", "cat-big", and "dog", you may want an algorithm that first learns to distinguish between any cat and any dog, and then in a later step learns to separate cats that are pets from cats that are big (like a lion!). This is called hierarchy, and if your classifier can exploit hierarchy you may gain better accuracy. If your classes are completely independent however, it may not make any difference. I suggest you start with the method that is easiest (i.e. OneVsRest), and see if the performance is suitable to your needs, then move to more complicated methods (multilabel, hierarchical methods, etc) only once you need better performance. 

I would like to know how to model and solve the problem of unmixing a composition into its underlying components, where the sum of the elements is normalized to 100% (e.g. $0.25m_1 + 0.75m_2$ has the same composition as $0.50m_1 + 1.50m_2$). Furthermore, my example is simplistic; in reality a composition can have more than just 2 minerals (up to 3000) and each mineral is made up of 118 elements, not just 3 (all the elements of periodic table - though many elements will be zero). The elemental composition of a mineral is assumed to be known (definition of $m_1$ and $m_2$ in the example). Also, the sensor reading is noisy - each element of the observed composition is assumed to have Gaussian noise. 

What you are asking about is, in my view, the main problem of implementing a lambda architecture. Here are some suggestions on how to solve it. The combination of Spark and Spark Streaming largely supersedes the original lambda architecture (which usually involved Hadoop and Storm). Read here an example of how to use a and a separate to produce different s, one for batch processed results and another for real-time results. Once you have replicated that in your system, you still have to think about how to query both kind of s. The trivial case would be to just both of them: 

Let me assume you intend to use Python libraries to analyze the data, since you are using Scrapy to gather the data. If this is true, then a factor to consider for storage would be compatibility with other Python libraries. Of course, plain text is compatible with anything. But e.g. Pandas has a host of IO tools that simplifies reading from certain formats. If you intend to use for modeling, then Pandas can still read the data in for you, if you then cast it from a DataFrame to a Numpy array as an intermediate step. These tools allow you to read CSV and JSON, but also HDF5 ... particularly, I would draw your attention to the experimental support for msgpack, which seems to be a binary version of JSON. Binary means here that the stored files will be smaller and therefore faster to read and write. A somewhat similar alternative is BSON, which has a Python implementation — no Pandas or Numpy involved. Considering these formats only makes sense if you intend to give at least some formatting to the stored text, e.g. storing the post title separately from the post content, or storing all posts in a thread in order, or storing the timestamp ... If you considered JSON at all, then I suppose this is what you intended. If you just intend to store the plain post contents, then use plain text. 

There is a problem in your definition of the problem. is the expected utility of taking action in state and following the optimal policy afterwards. The expected utility of a certain state (based on your definition) is different after taking 1, 2 or 9 steps. That means that the reward of being in state and taking action is different in step from what you get in step To adequate model the problem, you should reframe it and consider the state to be both the 'position'+'step'. You will now have 90 states (10pos*9steps). 

The slides and the book are consistent. Notice how in the slides there is a restriction in the summatory: i.e. $a \neq A_{t+1}$. For $G^{(2)}$, you need to "remove" from $V_{t+1}$ the term that should not be there, i.e. $A_{t+1}$. Now, why this term is removed? If you keep this term you will be adding $A_{t+1}$ twice. In 1-step backup, it is part of the expectation of step $S_{t+1}$. When you calculate 2-step backup you want to replace $(S_{t+1}, A_{t+1})$ in the 1-step expectation with the discounted expected value of $S_{t+2}$. So you substract the term and add the discounted expectation for $S_{t+2}$ 

You need to use some function approximation scheme. In addition, experience replay would be useful for two reasons: (1) you want to keep past memories (2) you need to decorrelate the way to teach your network. Have a look at Deepmind's DQN on ATARI games. What you are describing is basically what they have solved. The paper is in their website: $URL$ Mnih V, Kavukcuoglu K, Silver D, Rusu AA, Veness J, Bellemare MG, et al. Human-level control through deep reinforcement learning. Nature. 2015 Feb 25;518(7540):529–33. With respect to the network architecture, it will definitely require some experimentation. For an alternative, you can also have a look at HyperNEAT. They evolve the network topology: Hausknecht M, Khandelwal P, Miikkulainen R, Stone P. HyperNEAT-GGP: A HyperNEAT-based Atari general game player. In: Proceedings of the 14th annual conference on Genetic and evolutionary computation p. 217–24. Available from: $URL$ For more strategic games. Maybe you can have a look at "Giraffe: Using Deep Reinforcement Learning to Play Chess" $URL$ 

There is a worked out example in the Wikipedia page for "simple linear regression" Just for the sake of it, let me plug in your example into the formulas: The fitted model should be a straight line with parameters $\alpha$ (value at $x = 0$) and $\beta$ (the slope): $$f(x) = \alpha + \beta x$$ The values for these parameters that minimize the distance between line and data points are called $\hat{\alpha}$ and $\hat{\beta}$. They can be computed out of the data point values by using these formulae, derived here: $$\begin{align} \hat{\beta} & = \frac{ \overline{xy} - \bar{x}\bar{y} }{ \overline{x^2} - \bar{x}^2 } , \\ \\ \hat{\alpha} & = \bar{y} - \hat{\beta}\bar{x} \end{align} $$ where an expression with an overline $\overline{xy}$ means the sample average of that expression: $\overline{xy} = \tfrac{1}{n} \sum_{i=1}^n{x_iy_i}$. Here are the values I find for the datapoints you have listed in your question: $$ \begin{align} \overline{xy} &= \frac{1}{4} \sum{<(1 \times 4000), (2 \times 10000), (3 \times 22000), (4 \times 30000)>} \\ &= \frac{1}{4}(4000 + 20000 + 66000 + 120000) = 52500, \\ \overline{x} &= \frac{1}{4} \sum{<1, 2, 3, 4>} = 2.5 ,\\ \overline{y} &= \frac{1}{4} \sum{<4000, 10000, 22000, 30000>} = 16500 , \\ \overline{x^2} &= \frac{1}{4} \sum{<1^2, 2^2, 3^2, 4^2>} = 7.5 , \\ \overline{x}^2 &= 2.5^2 = 6.25 \end{align} $$ and the fitted line should be: $$ \begin{align}\ \hat{\beta} &= \frac{52500 - 2.5 \times 16500}{7.5 - 6.25} = \frac{41250}{1.25} = 33000 , \\ \hat{\alpha} &= 16500 - 33000 \times 2.5 = - 66000 , \\ \Rightarrow f(x) &= - 66000 + 33000 x \end{align} $$ Therefore, the model would predict, for a house with 10 rooms, a rent of: $$ f(x) = -66000 + 33000 \times 10 = 264000 $$ 

Treat the examples from the first as labels for training; you want to learn "what is an exception" and you need to have an expert answer that question for you. Treat the suggested features as new features for your classification. If you cannot get the experts to answer the questions you make, then try to infer them from their interaction with your reports: how many of those reports were downloaded, how many times are they mentioned, how are they ever used in decision-making ... Try to separate the important ones from the uninteresting ones, and there you have your labels. 

What is the best way to model compositional data problems? Compositional data is when each example or sample is a vector that sums to 1 (or 100%). In my case, I am interested in the composition of minerals in a rock and I have sensors that tell me the sum of the minerals but not the components that make up the sum. For example, lets say I have two minerals, $m_1$ and $m_2$, that are made up of 3 elements (like copper and other elements from the periodic table) which form a vector of length 3: 

Now I just need a way to export the coordinates of the points to CSV. I realize this is a simple program and I could write my own, but surely someone has already done this and created a tool to do so? It could be a website, an .exe, Python source, or any other application. 

If a rock has 25% of $m_1$ and 75% of $m_2$, the sensor reading produces the sum of the two minerals (shown in bottom-left subplot below): $$ \begin{align} &0.25*m_1 + 0.75*m_2 \\ =&0.25*[0.1, 0.3, 0.6] + 0.75*[0.6, 0.2, 0.2] \\ =&[0.475, 0.225, 0.3] \end{align} $$ 

Often when I am learning new machine learning methods or experimenting with a data analysis algorithm I need to generate a series of 2D points. Teachers also do this often when making a lesson or tutorial. In some cases I just create a function, add some noise, and plot it, but there are many times when I wish I could just click my mouse on a graph to generate points. For instance, when I want to generate a fairly complex relationship between x and y, it's a hassle to think of the right formulation to generate the points programmatically. Does there exist a tool that will allow me to generate data points using my mouse, with an option to export to CSV (or other simple format)? For example, I am currently learning how to use mutual information and entropy as a metric of dependence between variables. I'd like to see what happens when I have data that is clearly dependent but does not have a linear relationship, so I drew this image: