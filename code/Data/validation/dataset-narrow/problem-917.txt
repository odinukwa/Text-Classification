As you can see from the template, discovery runs only once an hour. So you need to wait a bit after you add a new host before this data becomes available. 

Hmm. I think you can get around this with ansible's raw module. Remember that while rbash is a restricted shell, it's entirely possible to start an unrestricted subshell; it's meant more to prevent accidents than to provide security. So this is what I would do. I've tested this and confirmed it successfully changes a restricted shell. Note that it has to prompt for a password, because prompts for a password and this isn't avoidable without root access. 

You don't need a window manager in this case at all! Just and start your app. The X server and its own window management runs locally on the user's desktop, not on the remote server. The Windows and Mac guys will have to start their X servers manually, but on Linux desktops it's already running of course. 

The simplest solution is to run two mail servers on premise. One handles only incoming mail, while the other handles only outgoing mail and knows nothing of the first server. 

If you're using NetworkManager, there is no reason to - and you should not - enable the legacy network service. Conversely, if you're using the legacy network service, you should not enable or start NetworkManager. You might have breakage if you have legacy scripts that expect to use the old network service and don't understand NetworkManager. These should be adapted as appropriate, if possible. Otherwise, you can always use the old network service. 

Wait several hours. Depending on the size of the hard disk and your available bandwidth, this may take a very long time. You will end up with a file . Mount this to a KVM virtual machine as a raw disk image and it, as there will be errors. 

You can use Group Policy to prevent the installation of new network devices. You'll find an option in Administrative Templates \ System \ Device Installation \ Device Installation Restrictions \ Prevent installation of devices using drivers that match these driver setup classes. From its description: 

The simplest solution is to use grub. Syslinux was designed primarily to boot from media other than hard drives, and while it technically can be made to boot a hard drive, it's not even the default bootloader (grub is), and probably has little or no support for GPT. 

This should get you about 99% of the way there, barring any last tweaks based on information not in your question. 

Distcache was removed from EL6, according to the package manifest. Apparently it was not important enough to warrant a note in the Migration Planning Guide, though from visiting their web site I would guess the most likely reason is that it's ancient and unmaintained and therefore unsupportable. Whatever you're trying to do, it's probably time to look at other options. 

You don't see this in a FastCGI setup because a new process is spawned for every page load. But in php-fpm a pool of processes is maintained indefinitely. To resolve the problem, ideally each customer should have their own php-fpm pool. Then the customer is responsible for any applications they run which don't properly set the locale when they start up. 

Your application only bound to 10.141.36.41. You cannot reach it on any other address. To resolve the problem, change the application's settings. 

You installed a mysql-community repository for EL7, but you have EL6. Remove it and install the correct repository. 

It appears that your hard drive has had a physical failure, and that it has affected a block containing the ext3 journal. You will need a second blank hard drive, at least as large as the failed drive partition, to perform any sort of recovery of this disk. You will also need a destination to copy recovered files to, so let's call it a third blank hard drive, network file share, etc. The general recovery process is going to be: 

The ssh key is never regenerated on the same host. You are seeing this message because you previously had your Elastic IP connected to a completely different instance. 

I just look for the AMI ID (it's in your list of instances) and Google it. It always returns a result in the Amazon marketplace. 

Remove the dotdeb.org repository from your apt sources. This repository was designed for Debian systems and is not intended for (and does not work with) Ubuntu. 

There are none yet. Google has not yet expanded into Finland. When they do, the new region will be listed on their web site. 

IPv6/IPv4 preference is determined by the initiator of a connection, i.e. the web browser. The address selection rules are defined in RFC 6724. While these can be overridden, it is only by the user reconfiguring their operating system. The only way you can force someone to use IPv4 is to not offer IPv6 at all. Obviously this is not a practical solution even in the medium term... So, let's go back to the original problem: Geolocation for IPv6 is "quite a bit spottier than with IPv4." In part this is very dependent on where you get your geolocation data. Maxmind for instance only gives my IPv6 address as "United States" with no city at all and an interesting set of coordinates, while Google at least correctly identifies the metropolitan area they are still about 50 miles off. Both Maxmind and Google allow for reporting corrections, and at least for Maxmind anyone can do this for any IP address. I would not expect this situation to last very long. As IPv6 usage continues to expand, users of such geolocation services will demand greater accuracy for IPv6 addresses, and they will have to deliver it eventually, at least for paying customers, lest those customers go elsewhere. In the meantime, you should be sure that your application has other ways to locate users. If they logged in, you could read their existing account for clues as to their location. You could ask the user to explicitly select a country. And so on... One other thing you can do is to provide an IPv4-only subdomain and an IPv6-only subdomain of your web site, each of which your pages attempt to load. You can then correlate them client side and report back to the server. Not coincidentally Maxmind is already doing this on their own web site. 

And note that you probably do not want to do this in the zone, but create a new zone. That zone has several things set up to be allowed by default (such as DHCP) which could cause you problems if you remove the interface and restrict the zone by source IP address. 

sshfs has a lot of overhead, and has been quite slow in my experience, compared with other transports like NFS or iSCSI. For this application, where you have several app servers reading and serving the same data from a central file share, NFS really is your best bet. If you're on Linode, you can always run your own NFS server on one of your VPSes, or go shopping for a completely different provider. Some do offer straight-up NFS file storage. (Though, note that we don't do product/service recommendations here, so don't ask here.) 

GraphicsMagick was compiled with X support, and links to some X libraries, so that its functions that require X will work. From the README: 

Based on the output, I would guess the appliance has a broken milter which is screwing up mail processing. Sendmail alone usually gets RFC compliance right. 

Security In general, timestamps are used in various authentication protocols to help prevent replay attacks, where an attacker can reuse an authentication token he was able to steal (e.g. by sniffing the network). Kerberos authentication does exactly this, for instance. In the version of Kerberos used in Windows, the default tolerance is 5 minutes. This is also used by various one-time password protocols used for two-factor authentication such as Google Authenticator, RSA SecurID, etc. In these cases the tolerance is usually around 30-60 seconds. Without the time being in sync between client and server, it would not be possible to complete authentication. (This restriction is removed in the newest versions of MIT Kerberos, by having the requester and KDC determine the offset between their clocks during authentication, but these changes occurred after Windows Server 2012 R2 and it will be a while before you see it in a Windows version. But some implementations of 2FA will probably always need synchronized clocks.) Administration Having clocks in sync makes it easier to work with disparate systems. For instance, correlating log entries from multiple servers is much easier if all systems have the same time. In these cases you can usually work with a tolerance of 1 second, which NTP will provide, but ideally you want the times to be as closely synchronized as you can afford. PTP, which provides much tighter tolerances, can be much more expensive to implement.