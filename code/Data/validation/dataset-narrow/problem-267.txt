Everything in the result set was correct, save monitor_server, it had the value of OddServer03! As many of you know, when configuring Log Shipping through the GUI, it is damn near impossible to "accidentally" configure this option. We never intended having a monitor server in the mix. We use Quest Spotlight to monitor the aforementioned servers which will yield alerts when jobs fail or when log shipping gets behind. One other perplexing matter, the job that is getting created is instead of . Why is the service account trying to authenticate to a server that isn't part of the configuration? 

I've set up alerting on all my database servers and every once in awhile I'll get the following error, sometimes it goes on and on and on, other times it'll be a few times here and there. 

1 Another way to express the same constraint would be to say that the following two queries should always produce identical outputs: 

My "non-solution" My "non-solution" to this problem is a hard-to-maintain hack. I post it here for three reasons: 

I'm looking for a way to enforce this constraint. (In case it matters, I'm particularly interested in solutions applicable to SQLite3 and PostgreSQL.) EDIT: Just to be clear, the description above does not preclude the existence of rows in table whose value of is not mentioned at all in table . For such values of there is no value of at all, principal or otherwise. It is only for those values of that appear in table that there must be one and only one row in table having . 

The explain result is identical to query 2(order by id asc vs order by id desc), however the time it took is far different. So I have several questions: 

Obviously MySQL did a full table scan so that it took over 4 seconds. And the query time when I force using the index is sane (0.01 sec) 

Why not use the index when , using that index reduces the rows to scan from over 5M to 30K, so there's just no way that MySQL should ignore that index. What does the column mean in the explain? I always thought it was how many rows MySQL thinks it should scan to get the result, if I'm correct, that in query 2, the is too wrong(the number in query 3 doesn't make sense either). Query 2 happens coz I'm using Rails 4, and when I write something like , AR will add an to the SQL, is there a way to avoid this? 

and detect the condition where the search fails. This means performing one such query for usually hundreds, often thousands, of genes. (BTW, most of these queries are usually performed by scripts written in Python, R, Perl, MATLAB, etc. using those language's DBI facilities.) Alternatively, one could concoct a (typically huge) SQL statement of the form 

But such a listing would not be possible with the schema shown above. Even if the constraint were removed from the definition of the column, the closest we would get is Listing 3 

...and from the result deduce the subset of invalid gene names. Maybe it's just me, but I pick up some potent code smell from such huge SQL statements. Bottom line, I don't have an entirely satisfactory solution, but since the problem must be very common, I figure that there must be standard solutions for it. If this is correct, please let me know what they are. BTW, assume that access to the DB is read-only. In particular, please rule out any solution that involves creating temporary tables. Also, in case it matters, ours is a MySQL database. 

Are there any configurations that I can change to stop this? It only appears to be coming from two servers. 

A colleague of mine and I were configuring Log Shipping in a test environment. We took a full backup of a database on LSPrimary01, a log backup, copied to LSSecondary01 and restored the backup and log . Then used the GUI on LSPrimary01 to configure Log Shipping. We already configured file sharing and proper permissions for Sean\LSServiceAccount. The following error was the result: 

Upon investigation of the account, it shows up under the Security object folder in SSMS. Also, we find that the account is associated to all the databases under User Mapping for the account properties. I've verified that 'MyReportAcct' has and , so on the surface every looks as expected. The rub comes when I try to alter the account or remove the mappings. I'm met with: 

...because there's no way to determine the appropriate value of for those rows where is . I'm looking for a normalized schema that would enforce the new set of constraints (and thus allow data like that shown in Listing 2). 

no two rows may have the same -value but different -values; the -value is never empty; the -value is never emtpy; 

This "non-solution" consists of defining some distinct values of that can somehow be recognized as , and redefining to make use of this information. For example: 

Now, suppose that instead of the three constraints above we had the following:   1'. no two rows may have the same non-empty -value but different -values;   2'. the -value is never empty; (Constraint 2' is the same as constraint 2; constraint 1' entails adding the qualifier "non-empty" to constraint 1.) With these new constraints the following listing, where the missing -values are , would become valid: Listing 2 

I'm looking for answers on all the services you disable, anything that you disable, uninstall, etc. The goal of this topic/question is have a running checklist of things that do NOT need to be on a SQL Server for an OLTP-type system. I've not been able to find a definitive list on this topic, just various things here and there. I wanted this list for my own edification as well as something the community could refer to as needed. My thought is to update the list as folks make suggestions in the original post. I know that some of the topics that'll come up can be considered subjective, but either way, I'd like you to explain your reasoning for why you make the suggested modification or disablement. Not all of these are blatantly obvious. 

This definition misses one constraint that must satisfy. In English, this constraint could be described like this: 

In the research group where I work, we must solve following problem hundreds, maybe thousands of times every day: given a set of putative gene names (typically a few hundred of them), flag those that are not in our (MySQL) database. This problem is solved in a number of ways by our various applications and scripts. I would like to optimize the process. The simplest approach, of course, is to iterate over the list of gene names (after removing any duplicates, of course), and for each gene name perform something like 

...but it made no difference: the output of remains unchanged. Is there some other way to optimize this query? 

to clarify the situation described in the question above; to provide table-initialization code that responders can use to test their proposals if they so wish (it's in fact the code I used to generate Listing 2); to give an example of the sort of hard-to-maintain hack that I'm trying to avoid. 

This server was recently installed and configured. I was in the process of creating some maintenance plans to backup the logs and DBs on a daily basis. Regardless of my method to perform a full backup, it would fail immediately citing the generic error message 

I have created the following as an automated job to run at midnight on every database server I manage: 

I believe I found the real issue. SharePoint 2010 is NOT compatible with SQL 2014. SQL Server 2014 and SharePoint supportability 

Action required: Use the following information to resolve the error, and then try the setup process again. 

Is there a command at the CLI or in PowerShell that will list the components installed for SQL? I'm looking for something like the Feature List you can get from running the discovery report from Tools in the SQL Server Installation Center program option. I'm running SQL Server 2012 on the CORE version of Windows Server 2008 R2 Enterprise. I've searched around the Net, but haven't found anything useful. 

don't quite agree with you about the query plan secondary indexes() already contains primary keys(). So in theory, that & could be performed with only, no need to read any records at all when doing . So in theory(just in theory), MySQL should read , find all that meets the where conditions, then pick the smallest (since there is a , only the smallest one is needed), then use that to retrieve the record. Besides, when , the query time is just fine. I'm a bit confused about this, jump to next. MySQL document explains the meaning of as . $URL$ I think you are right, there are over 5M records, and about 30K meets the where conditions. If those 30K are distributed equally, then MySQL should only scan couple of hundreds of records before it finds a match, thus saving the stuff at all. And about query 3, now I understand the explain result and query time (compared to query 2). Since those records are located at the 'bottom' of the 5M records(the first match is at 5628309), should be really fast coz MySQL should only read a couple of thousands of records(from the last one, in reverse order) before it finds a match. Anyway it makes sense to me now :) What I'm trying to say is, when you write , in Rails 3, the sql would be something like , while in Rails 4, it becomes , since this is causing me trouble in this particular case, I'm trying to find a way to avoid this . Anyway now I know should do the trick 

During our recent monthly maintenance window I ran into an error installing SP2 on SQL 2014. The following is a screenshot and the associated error messages. Let me know if you need anything more. Here is a list of things that I've tried: •Tried installing CU7 - failed with similar message •Tried installing CU8 - failed with similar message •Restarted Server each time and tried installing CU7, CU8, and SP2 - all failed with similar message 

I've recently audited a SharePoint server and found configurations that are against best practice. I'm hoping there is better and quicker way than right-clicking and changing these settings manually on over 100 database. For instance, all the databases are set to autogrow by 10MB and the log files are set to autogrow by 1%. I'd like for these to be a set number and not a percentage. Any resources or recommendations would be greatly appreciated!