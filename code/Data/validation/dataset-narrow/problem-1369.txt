Most levels in 3D platformer games are built on a 3D grid. The old Tomb Raider games are very obvious about this. (Press forward and the character moves one square every time, you know you can jump 3 squares if you are running but only 2 if you are standing, etc.) Even more recent examples, such as Darksiders 2 follow the same idea. The character has a defined set of abilities with regards to how far they can jump and run. The environment is built out of pieces that are relative to those measurements. Fluid animations will hide them. Another thing to consider is that for the most part, you can simplify the movement paths in your game down to 2D when you are designing it. Consider the ball sections of Metroid Prime, or how most of the time you are moving along a corridor or climbing the side of a wall. You rarely need to turn 90 degrees in the jumping sections of those games. Usually that is reserved for the arena fights. To make it easier to restrict the player from going off the expected path, newer games often severely restrict movement-enhancing items and abilities. Today, a grappling hook is only useful on specific points deliberately placed in the world. Contrast that to the hookshot in Zelda 64, which can be used on any wooden surface in the game. Other examples include only being able to wall-run or place portals on specific wall textures. Some tips for designing a platformer/adventure game that can be applied to 2D or 3D: 

Ogre Battle (SNES) does this, with the player having the option to cast powerful spells which are of limited quantity. 

Any slowness in this situation would be caused by the switching of texture states, as another poster also mentioned. If you are finding that you have performance problems you can combine all of your small textures into a larger sprite sheet texture to eliminate the switching of which texture is on the GPU. You will just need to use a rect to access the correct portion of the sprite sheet when you make the call to ContentManager.Load(). 

Since submesh 1 and 3 have the same material and they are all static, I'd like to render submesh 1 and 3 in a single drawcall. However, Unity is failing to batch those submeshes together. Is there a way to achieve this? 

You can see Editor build log to check which files contribute most to the size of your build. You can open it from within Unity by clicking on the list icon right abot the error icon on console view. (See image attached) 

Yes, you should always normalize light computation vectors. , so, if vectors are normalized will get you values in the range of [0,1] which is exacly what you want. 0 being light perpendicular to surface normal, 1 being light pointing exaclyt at the same direction of normal (thus giving most contribution). Negative values means light is hit the back of surface, thus the need o max(0.0, dot()). A few things worth noting: 1. Linear and Gamma Space Monitors use a non-linear color space (gamma), so you should be aware of this or you light will appear darker. Textures that come from programs are already written in gamma space and you should convert them to linear space to compute lighting and after lighting done you should convert final result to gamma again. Now you either use a sRGB texture and framebuffer extension to do this automatically for you or you need to do this is your shader. So, for instance, you'd have to do: 

You need to check two things: 1.Texture and Shader ETC1 doesn't support alpha. You'd have to use a separate texture read (which you seem to be doing on texture2D(CC_Texture1, v_texCoord2). You can use tools to extract alpha channel from a RGBA texture and use a single texCoord for both samplers. Your code could be something like this: 

Well, after a lot of more tests I realized that the problem was either in the way I was measuring time, which I find really unlikely due to the fact that I've tested many timers, or something in the graphics card that was preventing it from rendering to screen, like it was skipping frames. I found the exact term for that and it made a lot easier to search for the solution after. It's called (macro/micro) stuttering. It can be caused by a whole variety of this, not related to your game (yay! the art of PC game programming). It could be due to an anti-virus running, instant message programs interference, multi-GPU sincronization (micro stuttering), laptop clock variety due to power consumption settings, intel processors can give errors due to "intel speed stepping" that changes cpu clock based on cpu usage (that would probably mess up with my QFC timer) $URL$ it could be a driver problem (nvidia as of today 07/12/12 has a driver bug that causes micro-stuttering in single GPU for GTX 6 card family): $URL$ Well in my case I realized another particularity, as stated before that enabling vsync fixes the issue. What is probably happening is a tearing effect that gives the illusion of a frame skip, since the camera is fixed I don't see the "tear line", only notes scrolling weirdly. I can't really tell if a tearing is happening because it scrolls so fast, but I'm accepting it for now as vsync fixes the issue. I hope it helps someone out there struggling with this problem. 

Regarding the jumping problem: You need to incorporate the time since the last frame into your calculation when you apply velocity to position. Assuming you have perfected things for 60fps: 

I am looking for a tool that will output spritefonts for XNA consumption that have an outline effect. I know that this can be done by rendering the text multiple times, but I'd like to take care of it in the content pipeline. The options that I was able to find reference to were hosted at sites that are now offline. I know Nuclex has a vector font option, but again, I'd like to stick with sprite fonts and handle the rendering at compile time. If anyone can link to an archived copy of those free tools, it would be appreciated. 

I experienced some problems with in XNA when I tried to mix two different SpriteSort modes. (Begin with deferred, end, begin with BackToFront wasn't sorting properly.) I've settled on just giving everything I draw with SpriteBatch a depth value. To that end, what is the smallest increment I can use on the floating point variable that will be used as the depth parameter without running into rounding problems? The valid values for this float are between 0.0 and 1.0. It is a float, not a double, and the language is C#. UPDATE: My testing has shown that 0.008f is the smallest amount I can change my depth value by and be certain the sorting will work. I'm guessing there is something else at play in BasicEffect or SpriteBatch. What I am trying to use this for is the rendering of my game's map grid. I want to make heavy use of transparency and overlapping to create a specific visual look for the tiles, the doodads, and the characters. Essentially, I am using a painter's algorithm to draw the tiles in order from the back row to the front. I have them numbered so I know the ordering is correct. The doodads I am trying to draw on top of the map are not appearing when my depth decrementor is set to a low enough number to draw everything I will need. It only works properly in a range where I can only access about 100 unique depths. UPDATE about SpriteSortMode problems (as requested): Thus far in my project I have got by just fine using SpriteSortMode.Deferred for everything. I have all of the standard UI components you would expect, windowing, clipping, etc. working. Now I am attempting to draw my map grid. Like windowing/clipping this requires things to be done in a specific order to look right. The grid tiles draw in a certain order. To accommodate overlapping, doodads/characters draw on top of a tile before the next tile is drawn. No matter what I did, my doodads/characters would always be drawn under the tiles. Changing the order of draws had no impact. Even drawing all of the tiles and then drawing the doodads resulted in them showing up underneath the tiles. Especially odd was that my UI elements continued to appear above the problem tiles as I scrolled around the map. I switched to SpriteSortMode.BackToFront and with a high enough depth difference (~0.01) I see things drawing on the grid as expected, but this depth difference is way too high to support every visible tile of the map. I am searching for a better solution than to write code that will End and Begin a new SpriteBatch every time ~100 pieces are drawn. 

Check this link for more info on ETC1 and alpha: $URL$ 2. Blending You'll also need to set blending. I don't know how to do that in Cocos2D, but in OpenGL it would be something like this: 

[EDIT: FIXED - Calling setting texture max level fixed that] I'm optimizing my game and I've just implemented compressed (DXTn) texture loading in OpenGL. I've worked my way removing bugs but I can't figure out this one: objects w/ DXTn + mipmapped textures are not being rendered. It's not like they are appearing with a flat color, they just don't appear at all. DXTn textured objs render and mipmapped non-compressed textures render just fine. The texture in question is 256x256 I generate the mips all the way down 4x4, i.e 1 block. I've checked on gDebugger and it display all the levels (7) just fine. I'm using GL_LINEAR_MIPMAP_NEAREST for min filter and GL_LINEAR for mag one. The texture is being compressed and mipmaps being created offline with Paint.NET tool using super sampling method. (I also tried bilinear just in case) Source follow: [SNIPPET 1: Loading DDS into sys memory + Initializing Object] 

Also I don't understand the "+3" in the block size computation but looking for a solution for my problema I've encountered people defining it as that. I guess it won't make a differente for POT textures but I put just in case. Thanks. 

Now, if you want a texture compression that supports alpha you can use ETC2 (all opengl es 3 devices support it), and for better performance and quality ASTC. Not many devices support it now but the quality difference from ASTC to ETC1 is brutal, plus ASTC supports alpha. 

I'm writing a MIDI file loader. Everything is going fine until at some track I get a failbit exception while trying to read from file. I can't figure out why, I've checked the file size and it's ok too. Upon checking "errno" and it returns "0". Any ideas? Thanks. The snippet follows: 

I use . $URL$ It was written for XNA 3.1, but I updated it to XNA 4.0. You can find those changes here: $URL$ 

does all of the hard work for you. With you can easily convert a font file on your machine into the kind of sprite sheet you are asking about by defining an XML file. Once you add the XML file to your Content project load it with the : 

You mention that you want this to smoothly slide from one location to another. Using a simplistic linear function, aka velocity/speed will not accomplish this. It will result in a jerky start/stop. If you want to have a smooth slide transition you will need to implement a cubic curve or something similar. The class provides an implementation of this curve through the method. All you will need to do is provide it your start and end values and a between 0.0f and 1.0f representing the elapsed time of your animation. It will return the appropriate intermediate value. 

You can use your pixel shader approach but it is incomplete. You will also need to add some parameters to it that inform the pixel shader where you want your stencil to be located. 

Building modular rooms will make it easier for you to replace/cut/rearrange things based on play testing. 

On PC the sales boost you are going to get from Steam will always surpass the cut they take so you are going to be using . If you have been rejected by Steam, I would recommend that you use the over install shield. I found it easy to use and a far superior product. (It is also free.) There may be a third option that is even better, but I am not familiar with it. $URL$ $URL$ The NSIS installer feature set claims to now also support patching and "an optional silent automated installation" mode. I haven't used these features personally, but given my excellent experience with that software in the past I have no reason to believe they wouldn't work. Someone else will need to answer your Mac questions. 

I'd like to know what are my options for high resolution timer in Window. I want a timer with at least 1ms precision since I need it for a rhythm game. I'm using QueryPerformanceCounter now, but I read there are many problems I can have with it (variable clock due to laptop power consuption, intel speed stepping, multi-core sync gives negative times, etc). I tried SDL_GetTicks() but I realized it is implemented using QPC in Windows. What other options do I have? Thanks. 

I'm trying to optimize my PC game but I can find the bottleneck since every time I run it through a profiler (gDEBugger) it runs smooths. When running outside gDEBugger I get these annoying hiccups. It's not just the graphics, the sound also gets choppy. The drops are inconsistent across runs, i.e, sometimes I run the same scenario and get no drops at all, sometimes I get a few drops, and others the game is consistently slow. The only constant is: when running through gDEBugger I ALWAYS get a smooth run. I'm suspecting something outside my game is interfering and causing these drops, but what in the hell does gDEBugger do that nullifies these drops? A higher process priority? Any ideas? Thanks in advance. 

I'd like to slowdown music playback, say at half speed. I'm currently using SDLmixer. I assume I'd need to tell SDL that I have a 44KHz music and want to stream it at 22KHz, but when I pass in 22Khz it seems it re-samples my audio and plays at normal speed. Does anyone know how to do that, or any lib that supports it? I'm looking for free libs that allow me a commercial license (so no FMOD) Thanks in advance. 

For more information on linear and gamma space check this link: $URL$ and this is how add sRGB extension to do gamma/linear conversion automatically for you: $URL$ 2. A word on Specular I see you're using Reflect vector to compute specular. A better approach is to use Half vector. Check this: $URL$