Each cube face is made up of a quad, or two triangles. Let's take 3 points from either the quad, or one of the triangles, and call them $A,B,C$. You can get the normal to this surface by normalizing the cross product of $\overline{AB}$ and $\overline{BC}$. You can then use that surface normal to calculate lighting. You can do similar calculations to get the tangent and bitangent to then calculate $u,v$ values for texture mapping. I'm not sure why the edges not having normals makes you think you can't calculate lighting for the cube faces, but you totally can. You could even use the vertices to calculate a normal for the edges if you wanted, but I'm not sure why you would want to do that :P 

3x3 Details: let's say you have a 3x3 matrix $M$: $ M_{ij} = \begin{bmatrix} M_{1,1} & M_{1,2} & M_{1,3} \\ M_{2,1} & M_{2,2} & M_{2,3} \\ M_{3,1} & M_{3,2} & M_{3,3} \\ \end{bmatrix} $ Let's see what happens when you multiply that by a vector $\begin{bmatrix}1,0,0 \end{bmatrix}$: $ \begin{bmatrix} M_{1,1} & M_{1,2} & M_{1,3} \\ M_{2,1} & M_{2,2} & M_{2,3} \\ M_{3,1} & M_{3,2} & M_{3,3} \\ \end{bmatrix} * \begin{bmatrix} 1 \\ 0 \\ 0 \\ \end{bmatrix} = \begin{bmatrix} M_{1,1} \\ M_{2,1} \\ M_{3,1} \\ \end{bmatrix} $ Now let's try vector $\begin{bmatrix}0,1,0\end{bmatrix}$: $ \begin{bmatrix} M_{1,1} & M_{1,2} & M_{1,3} \\ M_{2,1} & M_{2,2} & M_{2,3} \\ M_{3,1} & M_{3,2} & M_{3,3} \\ \end{bmatrix} * \begin{bmatrix} 0 \\ 1 \\ 0 \\ \end{bmatrix} = \begin{bmatrix} M_{1,2} \\ M_{2,2} \\ M_{3,2} \\ \end{bmatrix} $ And lastly, vector $\begin{bmatrix}0,0,1\end{bmatrix}$: $ \begin{bmatrix} M_{1,1} & M_{1,2} & M_{1,3} \\ M_{2,1} & M_{2,2} & M_{2,3} \\ M_{3,1} & M_{3,2} & M_{3,3} \\ \end{bmatrix} * \begin{bmatrix} 0 \\ 0 \\ 1 \\ \end{bmatrix} = \begin{bmatrix} M_{1,3} \\ M_{2,3} \\ M_{3,3} \\ \end{bmatrix} $ This shows that whatever matrix $M$ is, the first column is the X axis vector of the coordinate space defined by the matrix. The second column is the Y axis vector, and the third column is the Z axis vector. These vectors are in global space. $ M = \begin{bmatrix} X_x & Y_x & Z_x \\ X_y & Y_y & Z_y \\ X_z & Y_z & Z_z \\ \end{bmatrix} $ You can even see that this is true in an identity matrix, where the X,Y and Z vectors are just what you'd expect them to be: $ M = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ \end{bmatrix} $ 

I have a Shadertoy which renders the image below using ray tracing. I'd like to add caustics, but am aware that in general they are a hard solution, especially without bidirectional ray tracing or photon mapping. Does anyone know if there is a way to analytically calculate caustics, or at least some of the caustics (or plausible caustic effects) in a situation like this? There is refraction going on here, not just transparency, in case that makes a difference. 

No, he's talking about subtracting the position of the cube from the vertex positions, so that your cube is positioned at the origin. If you positioned the cube at (10, 30, 15), you subtract that value from every vertex. Next, you rotate the vertices. Lastly, you add the position to the vertices again so the box goes back to where it was, but the vertices have been rotated around the location of the box. Doing rotation like this makes an object spin in place. If you didn't subtract the position before rotating, the object would orbit the origin, instead of spinning in place. 

Updated answer, now that pow is getting valid arguments: What you are seeing is called "banding" and it comes from the fact that the color channels are quantized into 8 bits - in other words, it comes from the fact that there are only 256 different shades of green, even though the math generating the colors is capable of much larger resolution. The banding on my system isn't as bad as what you are describing but it's still present. The reason it isn't as bad on my system is because you and I have different displays. Some computer displays don't actually even have a full 256 different shades of green. For instance, instead of having 8 bit color, they may only have 6 bit color, and they either dither it, temporally dither it, or neither and just let it look worse. One way to get around this problem is by dithering. There are various algorithms for dithering, with different computation and quality trade offs. A good modern dithering algorithm is called "interleaved gradient noise" which is fairly close to blue noise - which is the ideal - and is pretty cheap to calculate. Check out this link for more detailed information on different types of dithering, and how they compare: $URL$ First answer, from when pow was getting a negative value parameter: The issue is that you are passing a negative value to pow for the first argument, which has undefined behavior. What shows up on my screen is completely different than what shows up on yours. 

I've been working on implementing the technique from the paper "Designing look-and-feel using generalized crosshatching" which can be found at: $URL$ The paper uses triplanar texture mapping to put tilable "line shading" style textures onto 3d rendered models. It uses the brightness of the pixel to select which texture to use, where it has source textures of varying brightness levels like in the image below. 

To render an image for use with red & blue 3d glasses, the usual way to do it is to render from one point of view, convert it to a single intensity (greyscale) value per pixel, and then put that into the red color channel. Render from a slightly different point of view, convert that to greyscale again and put that into the blue channel. This can be prohibitive when rendering a single time is already very costly. Are there any methods by which you could take a single render, and corresponding depth buffer, and come up with something suitable for both red and blue channels? 

Bicubic sampling is pretty good for up sampling an image and making it larger, but is it a good choice for down sampling as well? Are there better choices?