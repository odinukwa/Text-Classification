Having done this, AMIs created from snapshots on this volume boots fine using pv-grub kernel aki-805ea7e9. UPDATE: Actually having the .deb installed makes apt-get very angry. Rather, just extracting it by might be the better option. 

I need to rsync a file tree to a specific pod in a kubernetes cluster. It seems it should be possible if only one can convince rsync that kubectl acts sort of like rsh. Something like: 

Distro is unlikely to make much difference in this regard. Generally speaking, 15 socket connections per second is peanuts on modern hardware. It is very likely that your code is going to be the problem, not the underlying OS. In particular, you may come to regret the overhead associated with SOAP calls. I have observed SOAP operations spending 80% or more of the CPU usage for XML-related overhead. Some development-related answers: 

If I remember correctly, just installing the postfix RPM on a CentOS box gives you a mail server that listens only on localhost. If you hit "netstat -ltnp" you should have a line like so: 

Doing "consumer &" will simply background the task and go on. If the owning shell terminates, it will terminate any background tasks. You say the script works on command line, but your daemon won't survive if you log out? You want to start your daemon with something like start-stop-daemon. EDIT: actually, on reading your text again, I'm not sure if consumer is a daemon at all? If you just want to run some code on startup (e.g. housecleaning), you write a line in /etc/rc.local. If the script takes a long time to run, you may want to disown it. I.e: 

Assuming /dev/sda2 is empty, you may want to move whatever data fills /dev/sda1 there, I suppose. The process goes something like this. Assuming it is /home filling /dev/sda1: 

I can not seem to find a method to help rsync construct the rsh command. Is there a way to do this? Or some other method by which relatively efficient file transfer can be achieved over a pipe? (I am aware of , but it can only be used onto the node?) 

Finally, ip6tables is your friend. The above config assumes that there is a IPv6 capable DNS server on :1::1. dnsmasq should do fine. Hope this will be enough information to get you googling on the right howtos. 

I think pvdisplay tells you free PEs on that physical volume. I assume that means PEs not allocated to logical volumes. 

If you want a bit extra security above other fine measure suggested in these answers, you may want to consider port-knocking. Port-knocking gives good protection against attackers that scan ranges of IP numbers for servers to attack, which in my experience is by far the most common attack in real life. 

Partial answer. First, know that Asterisk configuration is more like a programming language than, say, Apache configuration. There are numerous ways to create "nonsense" configurations. On the other hand, you can create very nifty services. There are three aspects to setting up an Asterisk installation: 

It is not clear from the question what freedom there is to choose implementation technology. If you can choose a distributed nosql database like Cassandra, replicating data across many nodes should be doable, under the assumption that it doesn't matter if it takes a second or two for data to propagate. I don't know about pushing system files, but you could probably push static web content with a clustered files system or even rsync. For maintaining the state of multiple machines, you may want to look into cfengine that will help you with both maintaining packages and configuration over many boxen. If you're going to the trouble, you should probably do networked syslogging for these boxen as well. 

authentication failed: authentication failure Meanwhile, there is no output from my debug-logging saslauthd. I interpret this as meaning that libsasl2 tries to uses sasldb auth rather than try to talk to saslauthd. What I can't figure out how to tell libsasl that I want it to talk to saslauthd. Various instructions inform you to create a file /etc/sasl2/smtpd.conf or /etc/postfix/sasl/smtpd.conf. I have tried creating these files containing: 

I thought 0.0.0.2 is a valid IP? UPDATE The issue is indeed periodic and has been going on for several days (since 2015-12-20 according to my nagios): 

Note that since we have disabled most package verification, packages may fail installation at this step. Pay close attention to output: 

If you are deploying on Linux, you could package your installation as PRM or DEB packages and give them dependencies. Then rpm/dpkg will refuse to install your application if the server is too old. There are good maven modules for creating such packages. 

Issue 2 can be worked around by manually editing /usr/lib/python2.4/site-packages/yum files (PYTHONPATH magic could be used to make this somewhat less hackish). The diff looks thus: 

This problem occurred after the machine rebooted for the first time after adding these rules, so presumably there is some difference between then and now. But what? Or is there some kernel bug that means these packets are dropped even tho the counter is incremented? The machine is a CentOS4 box, Linux 2.6.9-67.0.1.ELsmp. 

Not sure what you want to achieve exactly. The most trivial way to make sure that a specific box replies to a a certain DNS query with a certain IP is to edit the hosts file. If you want to see what sort of DNS queries your system makes, you can use wireshark or tcpdump. If you actually want to simulate DNS instability/delay/quirkiness, you need a trivial DNS server implementation, such as $URL$ For hosts file location, see $URL$ (!). EDIT: It seems like, for testing purposes you need only to trick the machine running your testing client(s) that your dev server is mywebsitedomain1.co.uk. Unless the testing clients runs its own dedicated DNS resolver (e.g. using libadns), editing the hosts files should be fine. Note the following example hack that I have in my /etc/hosts: 

I tried to add 0:01:0 as a spare to the set using but this seems to have forced the volume into readonly mode and blocked any attempts to use afacli on the controller. After waiting 10 mins or so, I rebooted. State remained as above. So no my question is: how do I convince the missing drive to re-join the mirror set? If it helps: 

I'm somewhat confused. Do you want to give users the ability to publish web from their home directory? If so, see the userdir module: $URL$ If you want to just have a VirtualHost pointing to /home/X/public_html, you write a VirtualHost section. Having said that, the error message "Permission denied: access to / denied" seems fishy. Unless I am much mistaken, / here is a directory and not a location, meaning your web server can't read the filesystem root dir, which would indicate something more basic is broken/misconfigured. 

To explain: your second if statement "if [ $? != "0" ]; then" tests for the exit status of the latest statement, which is no longer sftp, but the previous if statement. Then I wonder, will sftp really exit with non-zero if it has problems uploading files? Cursory tests indicate mine doesn't. 

I'll wager a guess: the only reason the devel package is needed is because it creates a more general .so name, presumably named /usr/lib64/mysql/libmysqlclient.so pointing to the pertinent version. Simply creating this symlink by hand should prolly be sufficient. You should be able use: 

Don't know about the start scripts. The "master" apache process should run as root (you'll notice it's the one with pid 1 for parent). The entry in passwd looks correct. 

Thus, works fine and if I manually add a default route for IPv6 it works fine. The resulting router advertisement looks like this: 

should do the trick once you get a start script into /etc/init.d. Having said that, if you install supervisor from a package and it didn't install and setup a start script, you are entitled to complain to the package maintainer. 

... or something to that effect. Need to set up pkey access, or this will be one massive password-speedtyping excercise. EDIT: On the subject of a single connection, see man ssh_config ControlMaster. This will mean you save the overhead of negotiating 5999 of those 6000 SSH sessions. EDIT2: Haha! I win! 

In Linux, if you have an open file handle on a file, moving or deleting the file will not affect the file handle. Thus, you cannot easily rotate the file without help from the process that writes to the file (it will simply keep writing to the deleted file). You need to investigate yajsw to see if it supports re-opening the log file. If it does, you can use logrotate, which is usually present on CentOS boxen to rotate the file. 

I suppose the shell TERMs it when it exits, which would be immediately, due to the '&'. Maybe you want to use start-stop-daemon? E.g: 

However, this time it failed to do the trick. I rebooted the box in the hope that the BIOS interface would have something, but nothing obvious. The current state of the RAID1 set is as follows: 

Also, traditionally, most phone extensions are personal, but in a modern company, most incoming calls are actually to a company function. You should probably consider not having personal extensions at all, and simply have an extension per function that rings all phones in that department/function. 

There are no static routes. On this configuration, hosts on vlan 10 are allowed to access the outside world, but hosts on vlan 12 are not. They provoke like log entries: 

Did the magic number of RPMs change between these versions? How do I work around this? EDIT (Clarification): I am not trying to upgrade an existing machine. I am trying to create a new installation using yum --installroot=/mnt groupinstall core. In order to get a working config, step one is to install the release rpm which contains the yum repo config. 

This cyrus-sasl mailing list post eventually set me on the right path. For posterity, an attempt to produce reasonably explicit config. /etc/postfix/main.cf: 

In the end, brute-forced a kernel image from Debian/unstable. Given a volume from AMI ebs/ubuntu-images-milestone/ubuntu-natty-11.04-beta2-i386-server-20110413.1 (ami-4c906c25) I had to do three things: 

Make sure you understand what is going on. I assume this is a LAMP system on a Linux box. Some tools to help you measure performance: atop, collectd, iostat, vmstat, iptraf, netacct. If you are using an Apache frontend, turn on logging of request roundtrip (see LogFormat %D). In mysql turn on logging of slow queries and set the threshold low (e.g. 5 seconds) so you can catch the problematic queries before your users notice them. Use mysqlreport to see if yuo should change your mysql configuration. Insert log statements in your PHP code that triggers if relevant parts take longer than acceptable to complete. Use e.g. logwatch to monitor logs for such lines and notify you when they occur. Once you understand which parts of your system produces load, start looking at your design to make it more modular. Then you create tools to measure the performance of each module in isolation to make sure that it stands up to your performance requirements.