Reading through the code, I can say that it is well written, concurrent access in mind, and at the first sight, it can be said that it has no flaws. I especially liked these lines: 

Method name is a common method name used by collection types to add a new element to the collection. An method with source as the first parameter and the items to be added as the second parameter does not make sense. and are bad names for parameters and should be changed at least to and or similar. And in Capitalization Conventions 

And here are the results of the test, which shows the method is invoked a total of 5 times for all the 100 threads. The test created 100 threads which access the method randomly within 500 ms. There is another thread for removing the item from the cache in 100 ms continuously (This is because, the cache policy doesn't seem to effectively remove the item at the exact point of time of expiration). The method lasts for a random time between 0 and 500 ms With the following results, it can be seen that the method is invoked a total of 5 times (which is the number of the cache not containing a instance for the given credentials, first one because the cache is empty, and for 4 more times because it is removed from the cache) I can't help myself thinking why the of returns when the item is added to the cache. This would have been implemented differently (as returning the added instance as ConcurrentDictionary does) 

The code is missing the class which I think is also important for the review. The cache items are added with keys and it is important for this method to return the same value for objects having the same credential values, and distinct values for instances with different credential values. Is it? Naming conventions. Class names should be PascalCase and the class violates this rule. Should be To achieve better encapsulation and seperation of concerns, (The creation of an empty credential object should be a concern for the Credentials class, which has control over the internals of itself) instead of having a field in this class, it is better to have a field (or property getter) in Credentials class. 

Therefore, You can simplify the exact same behaviour at least in terms of the final state as follows: 

Yes, it seems thread safe. I run a test to prove it which I give the details at the bottom, but first are some code review comments. 

You keep track of class instances and not bare integer values, You can re-use this class in other projects or forms (if designed & implemented correctly), You can extend this class to enrich it's functions etc.. (There are an infinite number of benefits) 

To prove that it is properly working, I run a 100 concurrent threads test with random access to the operation with the same credential instance. This test revealed that, 

You should always check if the parameters are passed in as null. Your code would fail with a null refererence exception at if is passed as null. 

You should also check the items of the passed in collection for null references. If any of the items of the would be null, your code would fail with a null refererence exception at 

You can wrap your timers in ExecutionPlan class. Using a class for wrapping the timers have many benefits. 

EDIT 1: You also don't have to check and assign moannie if it is passed in as euro because it already has the value euro: 

Instead of magical macro define a set of generic functions for managing the pool and define the macros to pass the sizeof (as needed) to those functions. In fact you store the sizeof of the type which is all you really need. 

This assumes that the container holds raw pointer and it owns the pointers. it is a better idea to then let the container hold smart pointers. These will automatically clear the object they hold when they get destroyed (using by default). 

first issue: you hardcode as the number of bits per unit: portability says it should be which may be something else on some architectures second issue: both members of int80 are signed, only should be while can be unsigned if you can guarantee that offset is between 0 and 80 then you don't need to test for 0, and just document that exceeding the bounds is undefined behavior 

There is a typo in the y components, both times only entity2 is used. I believe that is a copy-paste error. Your distance is better known as the manhattan distance. I suggest naming the method after it to avoid surprises. An other method of getting it uses the absolute value of the differences: 

This immediately tells the programmer that both bodies must be players. The later ones less so, You can invert the condition and put the markForDestroy call in the then clause. 

has capability for custom deleters. Besides that assuming you are doing this to deal with COM objects then you can use ComPtr and its 

This will loop over the data at most O(log n) times and puts the elements in heap order. However for pulling out the data there is no way to only look at the affected elements in O(log n) time. Which means that you can't sort a linked list with heapsort and still be in O(n log n) time complexity. Instead to sort a linked list in O(n log n) time you would use merge sort. This requires that you are able to be able to split the list up into separate linked lists in that you can merge. std::list has this functionality with it's member function. (It also has a member function that will do that built-in) 

This can clean up the init code as you don't have to do and can instead just pass directly. Though having said all that you can just put the List of neighbours straight in the and not deal with having to look it up in . 

To wait for all worker to finish you can join the threads (this will wait until the thread is finished) like you do in the destructor. You can check the property of std::thread to see if it's already been joined or add another boolean flag: 

You can name crutch into something better that describes what it represents. Or keep whether ChangeToSmall or ChangeToBig was called last and replace crutch with that property. 

This needs to be synchronized so no thread can mess with the list while another is checking the length to see if one needs to be removed. 

You are using strings to store numbers and booleans, bad ideaâ„¢. Store them as the type they need to be and only convert when needed (JSON allows floating point and boolean values without the explicit conversion to string) I'm not a fan of hungarian notation. The prefix is unnecessary and just adds clutter to the names. A good ide will allow you to highlight field differently from local variables. You should add getters for the properties. You have 2 different key-to-field mappings. I suggest that there should only be one of them. You can convert to 3 different objects I suggest that there should also be a way to get a LocationInfo object from one of those (and make sure the round-trip is valid). add and 

I need to run CPU-intensive tasks on a very old machine with overheating issues. The script below will monitor temperature and pause the jobs when it gets too high, continuing them when it's back to normal. The actual commands run are, of course, not included, since they are irrelevant to the question. I am looking for hidden traps I may have set in my code (listed at the bottom), and for other things I have done incorrectly. Aside from special characters in the commands and arguments that are run, which are hand created so I can control that risk, what traps or "got-ya's" have I unknowingly set into the code? What ways are there for making this more error-proof, or better in other ways? For the timing function I know I could have used the 

What is their proper order? What order, if predictable, will place them in? As I read it, they will all be considered as by even though they are not This results in non-deterministic behavoir for a sorting algorythm that relies on . I can't say what their proper order should be, but it should have an order, as they are not equal. is the place to correct for this. Possibly by doing a string comparisson for integer results of . Edit Consider these strings. What should the final order be? 

This was developed in response to a question on Stack Overflow, Removing comments using regex. What the OP needed was a regular expression to use in C# to remove comnents from lines of a file. All comments were specified as beginning with a double slash and everything after that is ignored. Comments may also begin at the start of a line, resulting in the line being blank. Quotes, double or single, when properly closed, will shield any double slashes from triggering a comment. There was no indication that the target file was a C# source file, only that the processing file was C#. Taking advantage of the C# environment given by the problem enabled the use of conditional matching. These constructs are, to my knowledge, only supported in the and engines, so were acceptable to the OP's use case, but not in many other cases. When used the pattern will return the non-comment portion of the line(s). It will return a newline for lines of code that are either blank, or have a comment beginning in the first column. This keeps the line numbers the same in the original version and the stipped version if the results are written to a new file. Makes comparison easier. The patterns given here are as they need to be seen by the regex engine. I am not a C# programmer, so I don't know all the nuances of escaping quoted strings. Getting the pattern into the code, such that all the backslashes and quotes are seen properly by the regex engine was explicitly left to the OP. The pattern was built and tested under the ignore white-space adn multi-line options, rather than the other way around, so the commented version is the original and the single line version was created from it. The comments were intended to aid the OP in understanding the pattern, so they are rather verbose. In my testing it passed every pathological test I could throw at it, and I believe it is sound. The test file I created is: 

Another consideration would be hex strings. I haven't looked at them relative to your code, but I know that often I've been less than satisfied with how they have been sorted by other routines and tools. Sorted purely on ASCII value they sort nicely (if case insensitive), but adding the parsing you do, will they remain "natural" or not. Of course, hex string aren't natural, in an of themselves, but some of us computer types think they are/ :)