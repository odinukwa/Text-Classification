I don't think Oracle keeps track of past closed queries. However, you can find out what cursors a session has opened with . Since many applications cache the cursors for later reuse (this is automatic in PL/SQL: a cursor won't be completely discarded unless you reach the maximum number of open cursors), in many cases all past queries will be in this view: 

I agree the Oracle docs can be a bit bland, however they are in general very complete. Once you learn how to locate the relevant piece of information you're looking for, they are often the best resource you can find online. In your case I would suggest you take a look at the PL/SQL Packages and Types Reference book, where you will find the complete documentation of all standard packages. The chapter, contains a collection of examples, in particular how to set up your directories to enable access. Once you have setup your directory object, you can create a file in PL/SQL with something like the following : 

The most likely cause of a mutating table error is the misuse of triggers. Here is a typical example: 

Yes, most analytic functions can be rewritten with semi-join. In your case it would probably not be very efficient: 

Most likely using a cluster for this query won't be beneficial. A cluster in Oracle allows data from multiple tables to be stored physically close when they share a common key (here I suppose). This allows some query to perform better but a cluster will intrinsically consume more space than standard heap tables because for each key there will be some unused space. Insert-only heap tables on the other hand are one of the most efficient way to store data space-wise, since the rows fill all blocks nicely up to the HWM. In your case since you don't have a filter so all rows will be read, producing a FULL SCAN of the data. Because the rows are stored in a more compact manner in heap tables, the cost will be less than the cost for the cluster. The cluster, however, should have an edge when you look for a specific key, but this will also depend on the distribution of the data (number of rows per key), and on the length of the rows. You could build an example where the heap tables with regular B-Tree indexes will outperform a cluster for single-key queries. In conclusion, clustering tables in Oracle will help for some queries, but will also be hurtful to others, it has restrictions and drawbacks, it is not a silver bullet for optimal performance. Heap tables are the default for a good reason: they have good performance for most queries. 

@a_horse_with_no_name is correct in recommending the 11g express and you would have more certainty that the project would not run out of room. You should consider a proviso when you supply the database that you make no representation as to how long it can be used. Even though you think you will only have ten tables software grows and requests to change or tinker with things never stop. For example: 

Due to an interesting coding style the application does inserts on some tables with a null ID which fires the trigger and uses the existing sequence. For other tables it gets the ID of the newest record and adds 1. In this case the sequence is not used and gets out of synch with the number of records in the table. How can I tell if the next value of a sequence is valid for an insert? I could read all triggers for the sequence name and then do some dynamic SQL to compare the maximum ID and the current value of the sequence but it seems a bit clunky. 

I get hundreds of results that are identical for case, white space and hidden characters. I verified the identical nature using two text tools. The only difference I can find is the length of the description due to the difference in character set. I tried using COMPOSE, CONVERT and CAST to only detect real changes in the description but this gives the same results as using only an equivalence operator. How can I compare two strings in SQL that use different character sets and find the ones that have different text? Edit: Raj asks if I have used CAST as in 

Although this may look like table churn it allows you to calculate the price and discount that was applied today and in the past. You can change your discount every day by inserting a new row in ITEM_DISCOUNT 

I upgraded a 9i install to 11g with only one problem. Database links between 11g and our legacy 8i database are no longer supported. I have to transfer data from 11g to 8i two or three times a day so I thought it might be possible to use 10g express to link the databases. The data would be created in 11g, written to a table in 10g and then written to 8i. (I agree this is not the most elegant solution and I can improve it using advanced queue tables). Does 10g express support database links to Oracle 8i? Edit: thanks for the link to the Oracle documentation. Has anyone actually done this with 10g express? Edit: The 8i database is Oracle8i Enterprise Edition Release 8.1.7.0.0 - Production The intermediate would be the 10g express for windows The origin database is Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - Production 

In the first case the database will interpret PROCESSED as a variable, and its value, even if constant won't be learned until execution time. An index on will be used only if status has a strong selectivity for all values (ie there are many different values). Since you have only 3 values, Oracle makes a FULL SCAN since from its point of view any of the 3 values could be used. In the second case, an index will be used if you have statistics on this column that show that the value 0 is very selective (ie there are few rows processed). Oracle knows at compile time that this value won't change thus an index scan will always be effective. So, if you're sure that there are few rows processed, you will have to help the optimizer, for example with an hint like . Or you could use comments in your SQL: . Also remember that FULL SCAN are not evil. 

There seems to be something wrong here: the 0 cost on the index full scan is suspicious and if I had to guess I would say that you're missing something: probably the stats on the index. This in turn leads the optimizer to believe that it can run the FULL INDEX SCAN "for free" and goes on with a suboptimal plan. This could also be a rounding error problem, since there is very little data (1k tiny rows, probably fits in a single block!). So either there is some stats missing, or too little data to be meaningful. Interestingly, if we run your test with a large sample (say 1M rows), the optimizer is happy to go with an index scan. If we insert some data instead and do a standard stats analyze, we find a more logical plan (11.2.0.3): 

The jobs submitted while the window is closed should be queued and run later when the window is opened. 

Range partitioning involves a bit more maintenance because you have to create the partitions yourself. However, once the partitions are created, range and interval work similarly. 

You can add a lot of value to your career at little or no cost except for some of your time. You need a desktop computer or server with at least 4 GB of ram. Download Oracle virtual box or pick a pre configured image here. Install and configure.I learned more by breaking things than by reading in books or videos so don't be afraid to break your database repeatedly as you figure how to use the tools of the trade. With virtual machines you can take a snapshot, break the image and revert to the saved snapshot. Once you have installed the database you can try adding a schema of your design or play with Oracle APEX to get a quick idea about web applications. All the Fusion applications are available for download like BEA weblogic and you can play with some Hello world apps in Java. Then try and duplicate some of the things you need to do at work like backup, tuning, RMAN and anything else you need to practice on. It won't be easy but it will reward you with hands on experience which will give you confidence for work tasks. 

You have not specified the data type of ExpireMonth. If it is a date or timestamp you can try this select * from CARDS where EXTRACT(MONTH FROM EXPIREMONTH) + 1 = EXTRACT(MONTH FROM CURRENT_TIMESTAMP) + 1 

Try doing a test case. Make a dummy table and insert 100,000 records using your sequence from the database. I'm betting you will have no problems. Next try inserting the same thing from your application. Could this be caused by other issues such as an Oracle client mismatch? Another solution that would fix the issue but not problem is to add a trigger on the table. Before Insert on table on Dallas.X IF :the_id is null THEN SELECT x_seq.nextval INTO :the_id FROM dual; END IF; 

We use Lucene.Net to search for contacts on our Oracle database. It's a bit of an investment in coding to set up the indexer, index and searched fields but once it's done you take advantage of the many search options. Users report the usual problems: enter too wide a search term and get back too many results but it is really good for names where the name entered is, for example: "Robertson" but your search is "Bert" 

I am not entirely sure if I have come to the right place, because this question involves both SQL Server and .Net. Apologies if this is not an appropriate place for my question! I am currently working on an in-house tool to transfer data from our ERP system to our SharePoint. Specifically, my boss wants the closing of a project in the ERP system to trigger a workflow in SharePoint. My current line of thinking is to use the SQL Server Service Broker - create a T-SQL trigger on the projects table in the ERP database to send a message whenever a project is closed. The message would like carry an XML payload with some information on the project. I have done something very similar before, so that should not be too much of a problem. In the next step I would have to receive these messages, extract the information from the XML payload and create entries in a list in our SharePoint server. Adding items to a SharePoint list from a C# program is also something I have done before, so that should not be a problem either. My question is how I should approach the transfer from the Service Broker Message Queue to the SharePoint list. My first idea was to write a stored procedure in C# to receive messages from the queue, extract the relevant information from the XML payload, and then create a list item SharePoint. (Stored procedures in C# is not something I have done before!) As far as I could find out, this should not be a problem per se. However, it would require access to the SharePoint client assemblies from the stored procedure. Also, I would like to do some logging, and being a lazy slob, I would like to use Log4Net for that. So I would need access to two assemblies. (More actually, I think the SharePoint client library is split up into several assemblies.) Can I just load these assemblies into the SQL Server along with the one for my stored procedure, and then reference them from within the SQL Server? If so, are there any pitfalls, things I need to keep in mind? Or can I just install the required assemblies on the database server and reference them from within my stored procedure? Another option just comes to my mind - I could use Fody Costura, I think, to massage the additional assemblies into the one carrying my stored procedure... Are there any significant downsides to this? The alternative, of course, would be a program running externally from the SQL Server. This seems in some ways to be a better alternative - the problem with the SharePoint and Log4Net assemblies disappears. Also, I could deploy the resulting program on an arbitrary machine. In that case, though, I am not sure how to interact with the Service Broker and the Message queue. Can I just issue a RECEIVE statement via an SqlCommand instance and extract the fields like from a regular SELECT statement? Would I have to finish the conversation? I have found some hints to a Service Broker API, but where do I get the assemblies? So, my questions, in short, are: - Can I reference other assemblies from a CLR stored procedure? - I so, how? What are the pros and cons? - If now, how do I speak to the Service Broker from an external program? Do I need other assemblies besides the SQL Server Client? Thank you very much for any insight you might be able to share with me, Benjamin 

When my clients have a request that has unique business logic like this one I try turning the question around and asking why this is needed. Best way to make sure only one copy is running is not to let users have execute on the procedure at all. If this procedure is so special then it's use should be restricted to dba/developers. Another way is to only run this procedure as a job. Add a check in the procedure to see if any jobs calling this are running. If they are then stop further processing and log the occurrence. 

The best way to install XE and other products is to install XE first, then any other Oracle version afterwards. I think you can fix this by 

Try adding (SERVICE=Dedicated) to your TNS entry on the client computer that you are using and then run your query again. There could be other causes but this is the most common: you are trying to access data using a shared connection when a dedicated connection is required. Edit: Are there any other log or trace file entries when this error happens? 

We use Lucene.Net in our ASP.NET application. It indexes the database fields using the Query Parser methods and I believe it will do what you want. My only proviso is that with the number of records you want to search I would think a dedicated server or two would be required to index the data. And it is quite possible that at the end of the day when you have spent some time configuring Lucene and the hardware and writing the connectors you could have just made a data warehouse and got something similar. 

By Oracle 11 everything you can do with a CTXCAT index you can do more with a CONTENT index. Why not use that? Edit: The op asks if CONTENT indexes must be synced. Yes, this is correct. I find the time and load factor to do this is entirely acceptable for smaller records sets. Your mileage may vary based on record size. Further reference: