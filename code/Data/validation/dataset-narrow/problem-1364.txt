This will give you more control over what goes in what coordinate space. Matrices can be very easy and convenient to use, but in my opinion SpriteBatch doesn't work with them well. 

Considering the entire point of public/protected/private encapsulation is to abstract the class so it's easy to use, why does the programmer also have to decide if a method is callable from blueprints? Shouldn't all public methods/variables be visible in blueprints? How should I determine if a member should be visible in blueprints? Should I only add the macro when they're strictly needed? Should I aim to make blueprint interfaces even more abstract than the corresponding C++ interface? 

I have been reading this article: $URL$ which describes how a game object should be constructed out of components. It also encourages the decoupling of components, which brings up a problem with input, collision detection, and things that cause events to be triggered. If I have a game object, which is a player and this player has 3 components; PlayerSoundManager, PlayerCollisionDetection, and PlayerStateManager, how would I go about making sure they have no references to each other? If PlayerCollisionDetection detects that a player should die, messages should be sent to the other two components telling the player to play a death sound, and change it's state. Would it be wrong to put collision detection methods throughout all components and perform each reaction separately? 

not sure when you are running Mouse.GetState() as this is required to update the state of the previous and current mouseState objects what i would be looking to do is 

forgive me if i understood your question incorrectly, i have given this some thought in the past and decided that i would create an Enum for each action, and map each action to an enum for the controller method and an enum for the button /key press this would in theory allow you to use both controller and keyboard (and mouse for that matter at the same time) all you need to do is code the listening method to return the correct enum set when asking for the mapping of an action finally when in you update loop that key is pressed you need to fire that event and have any component that is listening for it respond accordingly. personally i would just create a wrapper class to do this for you and have the components talk to the wrapper (therefore maintaining separation of concerns a bit more) 

Using these rules, a component can be enabled and disabled on state transitions and work correctly. A serialized list or dictionary can allow you to drag and drop each component into a state to allow this control from the editor. 

This way we're rotation the vector from the target to the origin( camera position ) about ( 0, 0, 0 ). This will give us our rotated vector relative to the target, then we simply add the target vector to get back to where we were. 

The only way to load an asset from an asset bundle into memory is to load the entire thing, decompress and pull out the asset you want, then unload the entire thing, except the assets you want. This seems impractical for sharing assets between bundles. For example, if asset bundle A wants a single asset from asset bundle B, it must load all of B, pull out the asset, then destroy B. The alternative to this is to extract the shared assets and create a new bundle call asset bundle C. The problem with this is that B must have been designed this way before being built, which it won't be if it was built before A (it has to be since A depends on B). Using the resources folder results in a huge blob of bytes that, from what I understand, cannot be changed after build, and is certainly not differ able for patches. Putting the pros of asset bundles and the resource folder together, I figure that having an asset bundle for every asset is the best of both worlds. Is there problems with this? Is my understanding of asset bundles or the resource folder flawed? 

depends on the license the song is available under, Creative Commons license has many guises some of which allow for usage so long as you nominate artist. the various licenses are explained quite well at 'open game art' $URL$ 

there are a number of Camera Tutorials around that will show you how to go about creating a Matrix that will automatically move your camera to a position that you determine all you then need to do is pass it to the Spritebatch and everything will work as expected what you need to be careful with is then converting a onscreen event to a world position $URL$ code from article 

as a quick response to a very open question you need to decide why you want to learn these things if it is to purely make games in your spare time why not have a look at unity3d if it is to become a programmer / gamedeveloper you should first learn the very basics of c++ $URL$ or any other language you may choose. after that you need to start thinking about which platforms you want to target and types of games you would like to make. then i would start to consider your options in line with DirectX or openGL but always keep the options open to things like XNA, monogame or other libraries there are thousands of tutorials out there microsoft has plenty of DirectX tutorials, and reimers.net has some also 

You haven't shown any code, so I don't know for sure but I think your sprites have an origin that lies in the middle of it. Here is how the actual sprite is created in model space: 

So, my question is, can I get Unity's NetworkView.RPC method to put it's serialised objects into this "args" parameter? If not, can anyone see anyway around this? By the way I'm using Vexe's framework, so you might see unusual things like "base.Serializer" etc. 

Unity will invoke the RPC method on ALL methods with that name that appear in any of the game object's components. Yes, you could do that, I personally wouldn't recommend it. It will add unneeded dependencies in your project, and pretty much destroys the point OOP. Right now the RPC scope thing is really quite terrible. Imagine if you have an RPC method in a base class called A. Suppose classes B and C inherit from A. Now, if you attach scripts of both B and C to a single game object( not unrealistic ), RPC calls to methods in the base class simply won't work properly. Fortunately, this seems to be getting fixed: $URL$ They seem to be sorting out the networking component of Unity. Hopefully we're not waiting too long. 

the code doesn't do anything with it i can also wrap the draw method like this also whilst it maynot be the cleanest solution (it leaves a empty component in release mode) it does allow me to ignore any if debug anywhere else in the project. 

where _time is the time since last frame. although down side of this is that it will not map actual path accurately just be sure the ball is not so close as to confuse it with the current ball 

there is certainly a change in thought process when working with game development. so some practice there would be a requirement but ultimately like any form of creative work a portfolio would be your strongest asset 

draw each separately and place on top of each other with the tile i would try to draw in order(topleft to bottom right), or define the the specific layer it should be drawn to (you can probably compute this from world coordinates (or tile index) i would imagine the solution may vary from engine to engine but this would be how i approached it from an XNA / MonoGame pov 

I'm developing a multiplayer game that does not have prediction. It implements client-side interpolation. The problem with this is that input delay can be perceived. I've measured the various times involved in calculating the delay(packet arrival time, server respond time, time spent interpolating), and it seems about 50ms is spent on interpolating(correct), and 60ms is spent on ping and what I can only assume to be unfortunate message arrival time. The ping is 18ms, which leaves 42ms. If the message arrives at the server immediately after the server has finished reading it's incoming messages this frame, we suffer at least a 16ms delay(at 60fps) that wouldn't be there if the message arrived right before the reading. If this happens with both the server and the client, the delay really adds up, especially at lower frame rates. How can posts like this $URL$ claim to have exactly 50ms delay with 0 ping if this is an issue? If it's relevant, this is being developed with Unity3d and the Lidgren networking library in C#. I've moved the server snapshot writing to a different thread with a lock around the game world update method. This helped a lot, but from what I understand moving the reading to a different thread won't help in the same way, because the client won't be able to use the new information until the next frame anyway. 

I would consider looking into a procedural generation solution for these. this would include the 'stats',and could possibly include the image. when loading up the cards you are not loading an image but loading up a 'seed' for the card which will allow you generate any information required on game load. this would save significant amounts of hard drive space how the seed looks and works would depend heavily on the implementation of the procedural generation all the caching and threading answers would apply to this solution also 

use Texture2D.getData() to extract the colors array then use this array to create a new Texture and add a pixel on each time increment you should be able to modify the below to your need 

i think mortal online released a map showing locations of player deaths some time back, however why not think of it another way, give a few companies a call and tell them what you are doing and if they are willing to help, tell them anything you learn you will share with them, i'm sure some will be more than willing to pass some free work your way 

I've implemented client side interpolation, where a specified delay is put on each client. This allows them to interpolate between positions and rotations. Unfortunately, this means every thing else must be delayed, otherwise events ( like a particle effect on a collision ) will happen ahead of time( according to the interpolated data. ) Should I delay everything along with the interpolated data, or do I have the wrong idea about client side interpolation? I haven't seen a single mention of this problem anywhere, which makes me think I'm missing something. 

There we go. Our meteor should be fully functional. It can be constructed( with any height, speed, damage, and texture ), it can be updated( moves downwards at it's falling speed ), and it can be drawn at it's current location. So, how do we get a bunch of them on screen now? Well, let's go back to the Game1 class. Here we want to do a few things; load our meteor texture, make our random object, make a list of meteors, make it so we can add one when the 'm' key is pressed: 

I performed something recently where i ripped every word out of war and peace whilst it does not contain every single word in the dictionary it does have the added benefit of being able to tally word usage to get an idea of usage distribution you will also find slang words and names however, although these can be filtered rather simply 

Using the Component Based approach (c#) i have created a debug object that gets added as component to the Overall solution it is able to handle all debug requests that i'm interested in and draw them to screen by passing an object to the handler i have then wrapped anything that it does within the compiler if statements 

it depends on what the output of distance(v1,v2) is if it is a decimal (float or double) over a vector it is likely that distancesquared would be a lot quicker 

This vector scaled downwards instead because it was negative to begin with. So, if we scale by a positive number, it's just going to get further away from the origin, the same with the top vectors. They just have different directions. You might wonder why the cube is constructed like this. The cube's origin is 0, 0, 0( this is chosen to simplify things like placing the object, and scaling. Like I said, the origin doesn't have to be 0, 0, 0, but it's a good idea ) so, to get a cube of area 1, we want the total length between vectors in each component to be 1. So, you can see how it works mathematically. Technically the origin is as arbitrary as the bottom center of the cube. Having weird origins can be a pain when scaling though. 

So this basically does what we did before except now we're changing our asset's bundle in code rather than the editor. This can be useful, but maybe not the best solution depending on what you're going for. Another option is the AssetBundleBuild struct that Unity provides: