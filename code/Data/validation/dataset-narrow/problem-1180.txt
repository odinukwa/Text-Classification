He gave a little indirect concrete (not theoretical) contribution to assistive technologies: Stephen Hawking's speech tech released by Intel: "... Software that helps Prof Stephen Hawking to speak via a computer has been published online by Intel, the company that created it. ..." There is a short description also on his site. 

I use the user17410 equivalent formulation: Input: $n$ vectors $X = \{ x_1, \dots, x_m \}$ over $\{0,1\}^n$, $n$ is part of the input Question: Are there two different subsets $A,B \subseteq X$ such that $$\sum_{x \in A} x = \sum_{x \in B} x$$ The hardness proof involve many intermediate reductions that follow the same "chain" used to prove the hardness of the standard EQUAL SUBSET SUM problem: X3C $\leq$ SUBSET SUM $\leq$ PARTITION $\leq$ EVEN-ODD PARTITION $\leq$ EQUAL SUBSET SUM (I'm still checking it so it may be wrong :) STEP 1 The following problem (0-1 VECTOR SUBSET SUM) is NP-complete: given $X = \{ x_1, \dots, x_m \}$, $x_i$ vectors over $\{0,1\}^n$ and a target sum vector $t$, decide if there is $A \subseteq X$ such that $$\sum_{x \in A} x = t$$ Proof: Direct reduction from EXACT COVER BY 3-SETS (X3C): given a set of $n$ elements $Y = \{y_1,...,y_n\}$ and a collection $C$ of $m$ three elements subsets $C = \{C_1,...,C_m\}$ we build the corresponding 0-1 VECTOR SUM instance setting $x_i[j] = 1$ if and only if element $j$ is included in $C_i$; $t = [1,1,...1]$. STEP 2 Finding two equal sum subsets $A,B$ among $m$ 0-1 vectors over $\{0,1\}^n$, is equivalent to finding two equal sum subsets $A,B$ of vectors with element of bounded size $x_1 ... x_m$ where $max\{x_i\} = O((mn)^k)$ for fixed $k$. For example the set of vectors: 

For what concern "... what approaches have been taken and (in all probability) failed ...", see the P-versus-NP Page that collects links to papers/authors that try to settle the "P versus NP" question (in either way) :-) 

(1) Hennie, One-tape, off-line Turing machine computations (1965) (2) Kobayashi, On the structure of one-tape nondeterministic Turing machine time hierarchy (1985) 

The gadgets equivalent to nodes of degree 2 and 1 are similar (and we can also build "fill" gadgets to fill the holes of the original grid graph). Now replacing the two central cells of one gadget with the central unit that sends the power on one direction and a terminal at the other endpoint, the game SHOULD have a solution iif the original graph has an Hamiltonian cycle. 

($\Rightarrow$) Suppose that $\bigcup_{j \in A \subseteq \{1,...,3n\}} C_j$ is an exact cover of the original RESTRICTED X3C instance. Then by construction: $$\bigcup_{j \in A } ( L_{j,1} \cup L_{j,2} \cup L_{j,3} \cup L'_{j,1} \cup L'_{j,2} \cup L'_{j,3} \cup D_{j,7} ) \cup \bigcup_{j \notin A } (L_{j,4} \cup L_{j,5} \cup L'_{j,4} \cup L'_{j,5} \cup D_{j,7}) $$ is an exact cover of SINGLE OVERLAP RESTRICTED X3C. ($\Leftarrow$) Suppose that there exists an exact cover of the SINGLE OVERLAP RESTRICTED X3C instance. Every original element $x_i$ must be included exactly once in the cover, but, as seen above, the only way to include an element $x_i$ is by choosing a group of triples $L_{j,1},L_{j,2},L_{j,3}$ that correspond to an original triple $C_j$ that contains $x_i$. Furthermore if $L_p, L_q, p \neq q$ are included in the exact cover we have $L_p \cap L_q = \emptyset$. So the collection $L_{j,k}$ of subsets in the SINGLE OVERLAP RESTRICTED X3C exact cover correspond to a valid cover $\bigcup C_j$ of the original RESTRICTED X3C instance. The reduction can be done in polynomial time, so we can conclude that SINGLE OVERLAP RESTRICTED X3C is NP-complete. Just note that a SINGLE OVERLAP RESTRICTED X3C instance built using the above reduction can contain two valid and distinct exact covers of the original RESTRICTED X3C problem, but we are sure that if only one exact cover exists, it can be "mirrored" to form a valid exact cover of SINGLE OVERLAP RESTRICTED X3C. Let me know if you need a more formal proof for a paper. 

So with the special input encoding described above that gives it enough space on the finite tape, a two-way DFA with one counter and unary alphabet can compute every recursive function. If the approach is correct, it would be interesting to reason about how to choose $T'(n) \gg T(n)$ or when it is enough to pick a large odd $k \gg 2$ and encode the input as $1^m$, $m = 2^n k^n$ 

So the total time of the spaghetti sort is: $T = \sqrt{ \frac{2H}{g}} + \frac{H}{c} + N \times \frac{2H}{c}$ If we switch to the turing machine world, we can simulate the kitchen using a bidemensional array ... 

This is a possible reduction from 3-partition which is strongly NP-complete. Given a set $A = \{a_1,a_2,...,a_{3m}\}$ of $3m$ positibe integers, and a target sum $B$. The basic idea is simple: if we found a read sequence like $Rx1\; Rx2\; Rx1$, even if the last write of $x$ before the sequence was a $Wx2$, the first $Rx1$ forces to "use" another $Wx2$ to satisfy the $Rx2$ in the middle. We represent each $a_i$ with a unary chain $P_{a_i}$ made of $a_i+2$ write operations: the first operation is a $Wx2$ (green boxes in the figure), followed by $a_i$ write operations $Wy2$ (gray boxes), followed by a single $Wz2$ (blue boxes) write operation. We add three auxiliary chains $P_{c_1}, P_{c_2}, P_{c_3}$. $P_{c_1}$ made with $4m$ write operations $Wx1$, $P_{c_2}$ made with $B \cdot m = \sum_{i=1}^{3m} a_i$ write operations $Wy1$, $P_{c_3}$ made with $4m$ write operations $Wz1$. Now we build the chain $P_0$ made only with read operations in the following way: concatenate $m$ slot subsequences; each slot subsequence is made with: 

A tool that can be used to prove negative/impossibility results is the incompressibility method: Theorem (Incompressibility Theorem) Let $c$ be a positive integer. For each fixed $y$, every finite set $A$ of cardinality $m$ has at least $m(1-2^{-c})+1$ elements $X$ with $C(x \mid y) \geq \log m - c$ Some well-known applications are: a single tape Turing machine requires $O(n^2)$ steps to decide $\{ ww^R\}$; a DFA cannot recognize $a^n b^n$; impossibility of there being only finitely many primes (and estimates the size of the nth prime correctly to within a log n factor); .... Ultimately the above theorem relies on the Pigeon Principle which has itself some nice direct applications; for example: Theorem: if we color the points in the plane red or blue. Then for any distance $d > 0$, we can find two points at distance $d$ from each other that have the same color. Proof: Pick any equilateral triangle with side equal to $d$ in the real plane. It has three vertices, so by the pigeonhole principle two of them must have the same color, and they are at distance $d$ from each other by construction. 

The problem seems NP-complete and this is a possible reduction from SET COVER. Suppose you have an universe $A$ of $n$ elements: $A = \{a_1,...,a_n\}$, a collection of $m$ subsets $\mathcal{S} = \{S_1,S_2,...,S_m\}$ (with $S_i \subseteq A$) and an integer $k$. The SET COVER problem asks for a sub-collection $\mathcal{C} \subseteq \mathcal{S}$ of size at most $k$ such that $\bigcup_{S_i \in \mathcal{C}} S_i = A$ (with $|\mathcal{C}| \leq k$). The reduction to your problem (I call it 3DM-relaxed, 3DMR) can be done in the following way. The subsets $S_i$ are simulated using one or more elements of the set $X$, the elements of the universe $A$ are simulated using elements of the sets $Y$ and $Z$ ($a_{2j}$ is simulated with an element $y_{a_{2j-1}}$ of $Y$, $a_{2j-1}$ is simulated with an element $z_{a_{2j}}$ of $Z$). We start with $X = \{ e_1,e_2,...,e_{k} \}$ that will force the $|\mathcal{C}|=k$ constraint. Then, for every subset $S_i$ we create the triple: $(x^1_{S_i}, y_{S_i}, dum)$, where $dum$ is a new element of $Z$; and add the $k$ triples: $(e_1,y_{S_i}, dum),(e_2,y_{S_i}, dum),...,(e_{k},y_{S_i}, dum)$ Note that all $dum$ elements are distinct! In this way at most $k$ of the $x^1_{S_i}$ will be "free" to cover the elements representing the $a_j$: indeed the $(e,\cdot,\cdot)$ triples can include at most $k$ of the $y_{S_i}$, the remaining $m-k$ must be included by the corresponding $(x^1_{S_i},\cdot,\cdot)$ triple. To link the $x^1_{S_i}$ to the elements $y_{a_{2j}}, z_{a_{2j-1}}$ that correspond to the elements of the universe in $S_i$, we add three bridge triples: $(x^1_{S_i},y_{B_i},z_{B_i})$, $(x^2_{S_i},y_{B_i},dum)$, $(x^3_{S_i},dum,z_{B_i})$ At this point the elements of $A$ can be linked to $x^2_{S_i}$ and $x^3_{S_i}$ (or we can further extend the capacity of $S_i$ adding more bridge triples). For example adding the triples: $(x^2_{S_i},y_{a_2},z_{a_1}), (x^3_{S_i},y_{a_4},z_{a_3})$ we simulate the set: $S_i = \{ a_1, a_2, a_3, a_4\}$. The fundamental point is that if $x^1_{S_i}$ is "used" to cover the element $y_{S_i}$ (blue edges in the figure) then: 

This is a complete rewrite of my answer (I don't know if the interpretation is now correct, so tell me if you need further details) ... 1) solve conflicts in a shared vertex using a small circle centered on it and finding the intersection points between the circle and the segments that share that vertex; and add a small segment between two consecutive in/out segments (just "shorten" the end/start side of two consecutive in/out segments) (see figure) 

Each tree should have the same depth (we just can pick the max of the depth required for all the clauses/variables/S); and we must increase the value of $K$ accordingly (the number of steps to reach $C_j$ from $S$). We can include in $C$ all the needed (not blue) edges required to reach the clause nodes because they share no vertex. Furthermore with this construction we are able to build a simple path $P$ that traverse each vertex and each blue edge, just add extra nodes to avoid shortcuts between the clauses or variables: 

The beast is extremely powerful, for example we can build a TM $M$ that accepts every string of the form $L_Y = \{ r\; 0^n \; 1^m\;A \mid m \leq n \}$ and rejects every string of the form $L_N = \{ r\; 0^n \; 1^m\;A \mid m > n \}$ The idea is to transform the first $r$ into $R$ and then let the head reach the middle of the string then do a "stateless" zig-zag; if it reaches $A$ before $R$ then it accepts. Informal description: 

I think that "COLLECTIONS" stands for "queues, stacks, linked lists, trees, ..." From $URL$ Through careful design and implementation it's possible to build data structures that are safe for concurrent use without needing to manage locks or block threads. These non-blocking data structures can increase performance by allowing extra concurrency and can improve robustness by avoiding some of the problems caused by priority inversion in local settings, or machine and link failures in distributed systems. The best overall introduction to our non-blocking algorithms is the paper Concurrent programming without locks, currently under submission, which covers our designs for multi-word compare-and-swap, word-based software transactional memory and object-based software transactional memory. If "lock-free" means "do not use operarting system's semaphores, mutex, monitors, ..." then I think (but I'm not an expert) that every collection can be made lock-free using atomic read-write-modify primitives that must be supported by the hardware. A computational overhead is needed, but I think that for simple structures like lists, trees, hash tables ... the overall computational complexity of searches/insertions/deletions $O(\cdot)$ does not change. Exhaustive documentation on the subject can be found online: $URL$ (... and further references at the end of each document)