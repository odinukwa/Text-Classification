isBoundaryPoint traverses pixels around a given pixel to see if there is a pixel with alpha = 0. If a pixel has an alpha of 0, then it must be a boundary pixel. 

So here is my problem. For the first explosion these algorithms work just fine. The clockwise and counterclockwise traces work just great and the linked list is reestablished with the new borders. However, let's say a second explosion occurs within the first explosion. All of the sudden, a clockwise trace has the potential to become a counterclockwise trace if the terrain is sloping down. Because of how my logic is currently set up, the linked list will become inaccurate as which pointer gets assigned to which depends on the trace being clockwise or counter clockwise. For clockwise traces, I assign 

Bear with me as this will be a rather lengthy post. For the last month I have been working on an open source Cocos2D, Box2D Destructible Terrain Engine. I have some questions regarding its implementation. TLDR-> When tracing images, how can I account for a divided image where there is a column or row of alpha separating the sprite? How can I leverage a dynamic programming (or something else) type approach to make this algorithm efficient. Some Context: In the engine, destructible terrain sprites are created with MutableTextures which allow for direct manipulation of pixel values. An alpha value of zero is considered to be destroyed or non existent terrain. Now in order to use these mutable texture sprites with Box2D, I need an efficient algorithm to trace the image and create a set of vertices which can be used to define the terrain border. From research, there where two ways I could go about this. I could create many, composite polygons (avoid concave angles) to fill the terrain or just trace the border with EdgeShapes. I opted for EdgeShapes. 

If you use triangle picking, you only need to solve for a line/plane intersection test to find the point on the triangle that you clicked on. Use the raycast as your line and treat the triangle as a plane. 

You can kill two birds in one stone. USC Interactive Media Division or USC Game Development The Princeton Review rated USC as the number 1 Game Design school, Digipen rated 2nd. $URL$ 

For a game like you described you might consider going for a full Planner based solution. This allows you to describe simple transformations of the world state the AI can perform. Essentially the AI plans a number of moves ahead of time to reach its desired goal. This approach is computationally expensive but for a turn based game it's a great fit over classical min/max and alpha/beta pruning techniques. The issue you run into with the Rule Based System you described is having to constantly tweak conditionals and re-prioritize the list. When the list of rules grow larger they become nontrivial to fix small issues without affecting everything else. Utility systems have similar issues when a large number of utility functions constantly struggle between themselves. STRIPS is a well known planner algorithm that was used very effectively in F.E.A.R $URL$ Jeff Orkin's paper on his STRIPS implementation for F.E.A.R is a great starting place. A SDK to F.E.A.R is also available to take a look at some of the AI implementation details. $URL$ 

Context: I am working on a 2D Destructible Terrain engine for Cocos2D with Box2D. All images, when a level loads, have their border's traced and cached for the purposes of forming Box2D b2EdgeShape boundaries. Image boundaries are traversed in a clockwise direction with each boundary point stored in an object called a TerPixel. A border pixel is defined as follows where if any of a pixel's 8 bordering pixels have an alpha of 0, it is a border pixel. 

I believe many 3D engines utilize variations of these artifact reduction techniques. So, how do they avoid the shadow casting issue described above? 

Culling front faces reduces most of the shadow acne but creates another problem that none of the articles have mentioned. The screenshot below shows the issue. If you look at the white box in front of horned creature, you will notice the creatures's shadow is cast upon the other side of the box. This is because the front faces of the box are culled which leads the back faces to compare their depth values against geometry to the north of the box. 

In general this is what is happening: Starting from a corner, it traverses the sprite's texture until it finds a non alpha pixel. It then will 'climb' around all the border pixels caching their location until it reaches the same point again. The array of pixels found are then smoothed (averaged) and reduced based on curvature. However, I am running into problems where if a player destroys the terrain to where it is split in half, only half of the image is traced. I can't think of a way to account for this and am asking for help here. Also the other issue with my current algorithm, is it will become 'stuck' when there is a straight line of pixels as it won't visit already visited pixels again. When this happens the tracing is incomplete (albeit this is a rare edge case) Lastly, performance... When a player destroys the terrain, I know exactly which columns of the texture are modified. What I would like to figure out is a way I can avoid retracing the unaffected columns and just retrace the altered columns. Thanks for reading this long post. Any help would be very welcomed EDIT Here is a video demonstrating the algorithms in action. At the end it of the video it incorrectly draws the edge of the terrain. This is one of the edge cases described above where there is a linear line of pixels. $URL$ 

A good response should be fact based, and any subjective subjects like difficulty should be based on an explained experiences with the product. 

PEP-0342 details coroutine implementation in Python. You can create your own scheduler and tasks which can simulate multithreading on a single thread. This is the same way that Javascript frameworks allow for multithreaded like processing even though Javascript is run on a single process. 

Ai Game Dev Excellent source of Game Ai information from videos, to interviews, to articles, etc etc. The best content has to be paid for but is worth it since there are a lot of interviews with Game AI developers about techniques that aren't published anywhere else. On top of that it allows you access to their AI Sandbox application for testing out your own AI implementations. 

While doing a BS in CS at a California State University there was only one game development course which was group based where each group was to deliver a complete game from scratch in 10 weeks. Each group consisted of 4 programmers. This single game was worth 100% of the grade. It was straight C++ and OpenGL with weekly deliveries from all groups. One of the hardest classes I've ever had but at the same time we learned everything about how game engines really work. Rarely do students learn this anymore since most are spoiled with engines or frameworks that abstract all the "hard" stuff away. My professor published a paper about the class in 37th ASEE/IEEE Frontiers in Education Conference 2007 Student Teamwork: A Capstone Course in Game Programming The game my group created Images from my Portfolio Video of the game from another teammate 

Recently, I have started modifying my shadow map pipeline to reduce shadow acne. After reading through various articles, many suggest either using a bias value, which is subtracted from the depth value being compared to the shadow map 

traverseBoundary points (along with findNextBoundaryPixel) navigates itself around the image pixel by pixel. It stores the visited pixels in a set, and uses the set to check if it has visited there before. It will continue traversing until the start point equals the end point or there are no more pixels left to traverse. This algorithm is the issue tbh... It breaks apart when an image is split in two or there is a linear line of pixels. I could use some suggestions here. 

TerPixel stores a pointer to its next neighbor pixel which forms a circular singly linked list and stores a pointer to a TerrainBlob object which holds the physics body it belongs too. Every found border pixel is stored in a NSMutableDictionary called borderPixels. 

Naturally, this also leads to these shadows also being cast below the floor as well as above. Here is a screenshot of the bottom of the floor. It is difficult to see but you can see the shadows being cast. 

Sergio you might want to aim more toward a Game Development math book like Essential Mathematics for Games and Interactive Applications, Second Edition: A Programmer's Guide Instead of the classical Linear Algebra you would learn in college. Also like Ron Warholic said, stating what your math comfort level is would better help us taylor a specific book. 

Open Dynamics Engine is another semi-popular open source middleware solution for physics and collision. $URL$ PhysX is another popular collision/physics middleware from NVIDIA. Binary available. $URL$ Last but not least is Havok which is the gold standard of collision/physics. Binary available. $URL$ 

Well there are certainly copyright trolls around this topic. If you ever try to use the word "Edge" in your game title, prepare to be sued by Tim Langdell Bytes: Tim Langdell & the IGDA 

The equivalent to Navigation Meshes for 3D spaces is Navigation Volumes. Havok AI implements both navigation volumes and a volume pathfinder as shown in their GDC 2011 demonstration. The principle of A* in a volume is the same as A* on a navigation mesh. Since A* will find a path over any graph it doesn't matter if the graph is represented by a point to multiple points, a polygon to multiple polygons, or a volume to multiple volumes. The algorithm will still find a solution if one exists. Some slight nuances that are different with paths found on navigation meshes is how you determine path points at the edge of line segments, at the ends, or maybe at the middle? The same can be true of of navigation volumes, to determine the cost to traverse to the next volume you'll typically have to pick a point within the volume, midpoint/edge/etc. This all essentially boils down to the heuristic part of the A* algorithm you must supply yourself, or use a basic Euclidean distance algorithm. Path Following is not Pathfinding How your AI determines to follow this path is something completely different and is referred to as Path Following. The typical strategy for Path Following is to allow your AI to look ahead of where it's traveling to see if it can short cut the path to make more natural curved movements. Havok AI Demo at GDC 2011 

I am currently implementing basic shadow mapping in my C++ Custom Engine using GLSL 4.10. It is currently working with basic PCF anti-aliasing and very minimal reduction for unwanted artifacts. Here is a screenshot for reference: 

This turned out to work fairly well and didn't kill the fps. However, what is hurting from a performance and algorithmic perspective, is retracing the image. The algorithm for tracing the image is posted below where the final array called ImageBorderPointsSimplified contains a set of vertices which can be given to box2d to trace the sprite. On average it contains 15-25 points for a medium sized 800x800 terrain sprite. 

Whenever the terrain becomes altered, let's say through a circular explosion, a part of the image texture needs to be retraced in order to form the next physics border. My two current algorithms for this are posted below. The retraceEffectedTerrainBodies loops through a rectangle which fully encompasses the explosion radius. It removes from the cache all previous border pixels which have an alpha of 0 after the explosion. When it finds a border pixel that was not previously in the cache, it retraces the border twice. First it finds an existing border pixel going clockwise then reconnects the linked list. Next, it does another trace going counter clockwise until it finds another previously existing border pixel. I denoted the problem areas with the comment: // ** PROBLEM IS HERE ** // 

Unity is a very popular engine/WYSIWYG editor which allows programmers to expose easy to modify "components" which artists/designers can attach to entities to give functionality within the game. A bunch of components come standard which provide a lot of the basic functionality for games. From the Unity site: 

The Mario AI Allows you to implement an AI Agent to control Mario. Different levels of map details are available to allow a simple implementation or implementations with near engine level map details. The API is a server/server type implementation using Java. Additionally a Level Generation API is provided for creating user generated levels. 

So typically Havok works best with normal human sized objects with a gravity of 9.8m/s^2 and dealing with everything in meters. In my Game though there will be a large variety of scales from millimeter sized objects to meter sized objects. Typically this rules out running a standard Havok setup and dealing with things in a meter scale. Would it be best to increase everything by 10x or some scalar like this and increase gravity likewise? I understand this would also decrease how far objects can be away from the origin but for the sake of this question assume everything is relatively close to the origin, a hundred meters max. Issues of concern Object penetration - Havok usually allows some object penetration in the 2-3cm range in the meter scale. Floating point precision - Issues dealing with distances of objects etc, typically physics breaks down at the kilometer scale in Havok. Unseen - other unseen issues that may result with such large differences in scale. 

findCurvature locates the midpoint between 2 points and compares that midpoint to a point in-between the two outer points. The distance between the midpoint and the middle point gives a measure of curvature. If there is high curvature, more vertices are needed to trace the image accurately. Simplify vertices reduces the amount of points needed to trace the image by looking at the curvature of a set of points. When the total curvature breaks the arbitrary threshhold, it will use the given point for the final trace. 

So what ends up happening is the pointers form a half moon shaped border because they point to the old border pointers. I need the 'relinking' to be opposite when this situation occurs. My question is how can I develop an algorithm, with my current tracing method, to accurately recreate the linked list regardless of a clockwise or counter clockwise direction or how can I correctly take into account the direction? I realize this post is long and still may need more information. Let me know and I will provide it. EDIT Here is a short video illustrating the problem. Sorry about the quality.. The emulator isn't the best $URL$ 

One of the Cocos2D games I am working on has circular explosion effects. These explosion effects need to deal a percentage of their set maximum damage to all game characters (represented by rectangular bounding boxes as the objects in question are tanks) within the explosion radius. So this boils down to circle to rectangle collision and how far away the circle's radius is from the closest rectangle edge. I took a stab at figuring this out last night, but I believe there may be a better way. In particular, I don't know the best way to determine what percentage of damage to apply based on the distance calculated. Note : All tank objects have an anchor point of (0,0) so position is according to bottom left corner of bounding box. Explosion point is the center point of the circular explosion.