I don't think your issue is timing related. If you change your object velocity so that the amount of movement per update is very low (i.e. less than 0.5 units per update) my guess is that your object will never move at all! Currently, you are tracking a moving position over time as an integer (SDL_Rect is integer based). Any fractional movement associated with each update is lost due to the casting to an integer. Over time, these missing fractional movements add up and lead to jittery, non-smooth movement of the object overall. This is especially obvious for slower moving objects where the rounding doesn't average out as well and the discarded fractional portion represents a larger part of the overall movement. The solution is to track your positions in floating point coordinates, then convert to integer coordinates only when rendering. 

Once you have handled a touch by firing a bullet you need to record that you have already reacted to that touch and that you shouldn't on subsequent updates. Each touch location has a unique Id field that is maintained for as long as the touch remains active, even across frames. A simple approach would be to maintain a list of all the touch Ids you have already handled, and ignore those touches when performing your update. 

Are you writing your own XML importer/exporter, or using the built-in IntermediateSerializer? If you're writing your own, then you have the answer to your own question since you're the one implementing it. Otherwise, I believe that the built-in IntermediateSerializer just knows to treat deserialized collections as collections and assumes that the named members of your top level objects that contain these collections are able to accept these objects as collection items, otherwise it'll bork. It'd be a pretty lame serializer if you couldn't instantiate subclasses to stick in a base class collection from XML. I say "believe" because I haven't tried to examine the IL or anything like that. Just going based on my own futzing with it. I put my first whack at a component system on github just recently, and this is what IntermediateSerializer (should be XNA 4, if not it's 3.1 and 4 likely exports similar data): $URL$ Here's a snippet: 

Farseer is based on Box2D.XNA, and looking in their repository, I'm seeing what looks like managed C++ (reference). I'm not familiar enough with managed C++ do know if it can be used to generate Mono-compatible .NET DLLs. However, it looks like there's a native C# port of Box2D here. Just run it through MoMA and then try compiling it in MonoDevelop. I dunno if there's any compatibility scanner for MonoTouch, but last I read the main things you need to avoid are and unsafe code, and it's not likely those are used in this port of Box2D. 

It sounds like for each bone you are currently defining the texture to be rendered - you might as well allow for more flexibility and include a texture origin offset in your bone structure as well (relative to either of the joints you choose). That way you can be sure the rendered texture will be consistently placed. 

There is no built-in Kinect support in XNA currently, so any Kinect development on the Xbox 360 is out of the question. If it is one day introduced, it may well be similar to the available Windows SDK, but there has been nothing announced. As for licenses and fees, you can develop for the Xbox 360 if you have a $99 AppHub account, available from $URL$ 

The rectangles are actually colliding properly but you are drawing them at a location other than where you they actually are. If you change the origin parameter in your draw call to be Vector2.Zero your collision code should work as expected. By specifying a non-zero origin you are drawing your rectangles at an offset location from the position where you are performing your collision detection. 

This seems to catch everything, but all those raycasts make me queasy, and I'm not sure how to test that this works for enough cases. Is there a better way? EDIT If this really is just the way things are with 3D collision, an overview of why in the general case would be just as welcome as something specific to Unity. 

There's a whole wide world of audio programming fun out there A book that I haven't managed to read much of yet (damn school) is The Audio Programming Book by Richard Boulanger and Victor Lazzarini. The first 60-70 pages are a basic C primer wrapped up in music-specfic examples and may get a little boring, but they get to the good stuff later on like oscillators and filters. There's a lot of popular visual tools, libraries, and mini programming languages for creating or prototyping computer music: 

First things first: If you're targeting XBLIG and Windows desktop, you're using XACT, right? Just making sure. Unless you have a compelling reason not to, you should be using XACT. It's got warts, but it solves too many problems for it not be used. That is, unless you're looking to also compile with MonoGame or deploy to Windows Phone. Then it's not so useful. 

You need to have the full XNA game studio installed on every machine that will use your tool. From the WinForms2 sample page you linked to: 

Looks like the Unity docs are for the most recent released version only. The Set method was added in version 3.5.0*, which is why it isn't available in 3.4.2. *based on the information at $URL$ 

If you know in your Update method that you don't need or want to render anything simply call SupressDraw() on your game object ($URL$ You don't need to add any additional logic into your Draw method to handle this, and your frame skipping logic can be moved into your Update call. 

Moving the joystick in a complete circle gives you the upper bounds of the joystick range, but the at rest (i.e. no input) position of the joystick can't be accurately determined from those values. You could assume that that rest position is the exact center of the available range but that is only true in ideal circumstances. Over time controllers wear in non-uniform ways. You want the actual rest position for the device, which can only be accurately determined by asking for it during calibration. 

If your characters' footsteps sound different enough, then yes. It's also common to split it up into small, medium, and large footstep sounds because, for example, are human and elf sounds really going to be that different? Save on the diskspace and memory and reuse some sounds. 

Back up the along its hit normal Raycast down the negated hit normal for , on If that fails, repeat steps 1 and 2 with the non-negated normal If that fails, try steps 1 to 3 with Repeat 4 until successful or until all contact points exhausted. Give up, return . 

OpenTK is being used for MonoGame. MonoGame only supports the 2D api of XNA at the moment unfortunately, but you mentioned you had some OpenGL experience so you can use the OpenTK wrapper to do 3d graphics. You could also probably find a few scene graph libraries that are implemented in C# or in C++ with C# wrappers. For audio, OpenTK wraps OpenAL, or if you want something more robust and plan on releasing the game as freeware, then FMOD doesn't cost anything to use. It gets pricy if you want to charge for your game. A cheaper alternative would be BASS. 

When playing and you hit the P key your if(CurrentGameState == GameStates.Playing) block is executed, changing the state to paused. Then the if(CurrentGameState == GameStates.Paused) block that follows also runs (because you just changed the state to paused above and the P key state hasn't changed), changing the game state back to playing. This is why you never experience the paused state. At the very least, I'd make the code for each state exclusive within the update method, either by using a switch statement or the following: 

Are you using a SpriteBatch to render your overlay in the second image? If so, SpriteBatch in 3.1 sets render states when drawing (including disabling the depth buffer) that you need to restore before drawing in 3D. See this article for the exact states changed. 

Obviously you can improve the performance of this example and could remove touch Ids from the list of those tracked when the TouchLocation state is released, but the basic idea of tracking which touches you have handled and ignoring them on subsequent updates is the same. You could also limit firing a bullet to the initial touch location by simply checking that the touch state is TouchLocationState.Pressed, which should only be true for the first frame in which the touch is active. I haven't used that method myself. 

Assuming you have your , and as demonstrated in your screenshots, here's how to get a relative vector representing this hypotenuse: 

Yes. Otherwise you get the "machine gun" effect," which sounds like its name. It's especially bad with multiple impact sounds. For quick, repeated sounds, you typically grab a few different-enough samples, and then trigger each of those with their pitch subtly adjusted on each instance of the SFX being triggered. 

Alternatively, if you have a list of hittable GameObjects and there aren't that many in that list, you can bypass the call and do a squared distance comparison on each. The advantage of using Physics.OverlapSphere is that PhysX does smart things to prune colliders it would otherwise have to check against. But if you already have that list filtered down enough, you can save on not having to call out to the native physics code. It all depends on the cost of iterating through your hittable set vs the cost of calling out to Physics.OverlapSphere. Start with OverlapSphere for simplicity, and then if you find yourself needing to cut down on physics calls, then this is one place to possibly look at after you profile. If you need to bone up on trig, Khan Academy has some videos. 

8 kilobytes per second is the number I have seen tossed around on the AppHub forums. There is a short description of how headers and voice affect this number on Shawn Hargreaves blog. 

You also aren't allowed to distribute the full XNA studio installer in your install package, so if you are creating a tool to be distributed with your game the content pipeline isn't a great fit. It's likely not reasonable to expect end-users to install a developer tool to be able to use your custom tool. 

My guess is the try/catch overhead for each iteration of a potentially large nested loop was killing your performance and that the analysis tool somehow affected the exception handler overhead. You could easily test that by removing the exception handling and running normally, without the profiler. You definitely don't want a try/catch on the inside of a tight loop. You would be much better off ensuring that you account for anything that can generate an exception within your loop via conditional checks, or at the very least put the try/catch around the loop as a whole. 

Look at the command line tool for ImageMagick. It allows you to do batch processing on images, including transforms such as rotation. It's also useful for generating simple spritesheets (not the "packed" kind, but the kind where each the image is cut up into frames of equal width and height). 

You're probably at the stage where you'll get the most information by looking at various tutorial postings for specific engines online. There's also a decent enough number of open source games you can check out. One interesting thing to study might be the Monocle Engine. 

See example program here: $URL$ Your clients must have knowledge of Ptr for it to work. In order to make the transition from value-type land to reference-type land in these Push/Pop functions, you have to pass around the Ptr. Now that being said, you mentioned this should be for beginners. Why are you making them thinks about pointers in C#? Or maybe you aren't, but that's a consequence of this approach. If you are actually going to be pushing and popping state, why not maintain an actual stack? (Or List that you use with Stack semantics). Or maybe just always copy the user data to a temp state before you render, leaving their own data untouched? Without seeing how your code would use this feature, it's tough for me to recommend a good approach. I can see some beginners liking see both Push() and Pop() in their code though, since they can better understand then what's going on instead of assuming it's all magic.