You can clearly see that there is no kernel distinction between threads and processes. I've no idea what you're doing but whatever it is doesn't conform to the way Linux works, at least for me. 

Bit of a shot in the dark but I've seen this before and managed to debug it. Its a real bizarre edgecase though. If your clocksource is set to jiffies certain processors do not stay in sync with one another, leading to a situation where the time on one processor differs from the time on another processor. It can be out be a difference of only 1 second for this to cause a problem in mysql. You can test for this by doing: 

I never end up getting a TTL exceeded message however. Check what you have setup in your router and port forwarding, something appears to be incorrectly configured. 

I think the LXC option (not libvirt-lxc) is better maintained. Having read the sourcecode, it feels rushed. Traditional LXC certainly has newer features whicih have been better tested. Both require a degree of compatibility by the init system being ran in them, but I suspect that you'll find LXC slightly more "turn-key" than the option particularly in regards getting distros to work in them. 

Seeing as nobody else has yet mentioned it, its possible to do this with the module. You'll need to check the pam stack is invoking this module by looking in and adding as an value if it is not there. IE 

The first value if you cat that gives you precisely what you are after it would appear. For the record I couldn't get the output to match it even with some amount of fudging but I gather if thats what the kernel says its more authoritative than the list you get from anyway. 

You should use cgroups to do this. See "man cgrules.conf" and "man cgconfig.conf". Later versions of systemctl on fedora should support sticking users directly into a cgroup so you can do it better that way. This wont limit CPU in the sense that if there is available CPU resources (which nobody is using) it will use all the CPU however it something else is also demanding CPU it will allocate a share of the CPU based off of the configured "cpu.shares" value. Also as suggested sticking a ulimit on CPU time will ensure a running process is given a cumalative number of jiffies before being killed for using too much CPU. This might negatively impact long running processes a user is using which over a long period of time have accumulated a certain number of jiffies naturally. You could also use cgroups to enforce that all a users processes live on one of your cores only, so that you can at least guarantee if one CPU is being overwhelmed it has no negative impact on the rest of the operating systems processes. CGroups is also a awesome way to limit memory usage. You can combine it with pam_limits to prevent fork bombing. Edit: I should also point out what I think your asking for is not necessarily relevant. Having 1 process use up 100% of the CPU is not necessarily bad, providing time is given for other processes to run. The completely fair scheduler on linux guarantees this behaviour anyway. If the CPU is just idling theres nothing wrong with one process using up all the CPU. Your problem only comes where multiple processes are demanding CPU time and one of the processes is hogging the CPU. This is where cgroups should be of benefit as it permits you control how much cpu time you'll allocate different process in the event of CPU contention. 

What you are referring to is process checkpointing. There is some work in the later kernels to offer this (in conjunction with the freezer cgroup) but its not ready yet. This is actually very difficult to achieve well unfortunately because certain resources which are shared go stale after being unavailable for a fixed period of time (TCP springs to mind, although this may also apply to applications that use a wall clock, or perhaps some shared memory that changes state during a processes offline period). As for stopping the process when it reaches a certain memory utilization, theres a hack I can think of that will do this. 

This tells you which booleans control this behaviour and what they do, you should enable the boolean which is the most restrictive of the two. So in your case . 

This sounds as if the two events are unconnected to me. You've probably run the query, then it got stored in the query cache, so when you re-run the query the results are fetched from cache rather than scanning the tables to retrieve the data. 

The behaviour you are seeing is due to the way that Linux allocates memory on a NUMA system. I am assuming (without knowing) that the 32GB system is non-numa, or not numa enough for Linux to care. The behaviour of how to deal with numa is dictated by the option. By default, linux will detect if you are using a numa system and change the reclaim flags if it feels it would give better performance. Memory is split up into zones, in numa system there is a zone for the first CPU socket and a zone for the second. These come up as and . You can see them if you cat . When the zone reclaim mode is set to 1, allocation from the first CPU socket will cause reclaim to occur on the memory zone associated with that CPU, this is because it is more efficient in terms of performance to reclaim from a local numa node. Reclaim in this sense is dropping pages such as clearing the cache, or swapping stuff out on that node. Setting the value to 0 causes no reclaims to occur if the zone is filling up, instead allocating into the foreign numa zones for the memory. This comes at a cost of a breif lockage of the other CPU to gain exclusive access to that memory zone.