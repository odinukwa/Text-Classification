Success - go to step two, failure - exit(f). Success - exit(s), failure - go to step three Success - go to step four, failure - exit(f). Success - exit(s), failure - exit(f). 

Regarding your first question in general: I do not understand how an execution plan can reveal 3,141,000 Rows if it actually returns ZERO rows. How is this possible? The final output rows count isn't known to the optimiser when it generates a plan. So all it can consider are the estimates it can calculate from statistics. (In the case of your "bad" plan, the estimated output rows was actually 4.4 which was based on the first estimate in the plan.) If those estimates are outdated, or insufficiently accurate (sample vs fullscan of unevenly distributed data for example) then a poor plan can be generated even with a simple query. In addition, if a plan is reused with different variables, the estimates the plan was generated from may be wildly inaccurate. (And I think that's what sp_BlitzErik is leaning towards as the cause in your particular case.) 

Since both servers show similar reads and similar CPU "seconds", but the new server example shows that the duration was the same as the overall CPU time, the spikes you're seeing are likely due to less-parallel execution plans sometimes being generated--perhaps simply due to the CPUs being unusually busy at those times. Note that the CPU "time" shown is the total CPU milliseconds used over possibly multiple cores--which would have to be the case in your old server example where the CPU time was 6 sec but the actual duration was 1.5 sec. 

This can happen when you restore a database that was created on another server, and the database owner login account doesn't exist or has a different SID on the server you restored to. Choose a login that you are comfortable with owning the database, and execute this: 

You're right to consider both Avg_fragmentation_in_percent and Avg_page_space_used_in_percent when considering whether to do reorganise, rebuild, or nothing. Even if Avg_fragmentation_in_percent is low, a low Avg_page_space_used_in_percent may gain benefit from reorganisation (due to the extra IO and cache resources used by unfilled pages). And the "greater than 30% = rebuild" advise may be better read as "if Avg_fragmentation_in_percent > 30% and you have been regularly reorganising, then rebuild". If you haven't been reorganising, then try that first, since as your test shows, that may be all that's needed even with very high Avg_fragmentation_in_percent. As for the exact trigger levels to use, that really depends on your data and how it's used, and on various other factors like those jesijesi posted. 

As far as SQL Server config: Since you're not using SQL Server clustering with shared storage, I believe you don't need to do anything but configure all your instances with Tempdb on T drive (or whatever standard path you choose). See Example A at $URL$ As for how to ensure that T drive is available as local storage in all your VMs for when SQL Server starts up, that someone else will have to help with (perhaps stackoverflow with virtualisation tags). And be sure to test your whole failover process, don't take anyone's word for it. 

Scott's answer made me realise you might have enough space for this: Create a datetime2 column with a temporary name, and transfer the original column contents to it in batches (to prevent your log running out of space -- and I'm assuming your database is in Simple recovery model). Then drop the original column, and rename the new column to the old column name. 

For some reason, the new CE is using different indexes, both of which give an estimate of 1 row, hence the ill-advised loop join. Are you in a position to update statistics on both tables WITH FULLSCAN? If that doesn't help, please post the table and index definitions (with only table/column/index names anonymised). Asides: The ObjectX aliasing in your sample code is very confusing, you may want to reconsider next time you need to anonymise, especially for a more complex query. AliasX for all aliases, with X matching the ObjectX, could be an improvement. By the way, if you haven't carefully considered the consistent use of nolock, you may want to read this: $URL$ 

Note that "3MillValue" in two places would need to be hard-coded with the value that returns that amount, and that OPTIMIZE FOR is the key to this technique. 

I believe the basic issue is that the query is doing multiple heavy table scans due to no index support. Try adding the following indexes: CREATE NONCLUSTERED INDEX TEST ON STOCKDEBUGTRIGGERED (ChangeDate) CREATE NONCLUSTERED INDEX TEST ON STOCKDEBUG(ProductID, StockOld, StockNew) There may be further tweaks, so please post the stats and execution plan with these indexes added. 

It's critical that you do not enable RCSI on a database without the application vendor and your own developers certifying that they support it. The reason is that the behaviour of all your read queries will change, but not actually break in such a way that replaying your workload will detect. Read section 3 at $URL$ To answer your specific questions: 

$URL$ looks like what you need. Unfortunately I don't know enough to be more specific. Update: I believe hot2use's answer may only apply for background updates, which I don't think your call will trigger. See $URL$ My guess is that the way you are calling the refresh will complete the request before exiting the procedure, but that depends on what "the foreground process" means in Oracle. 

It's not clear to me how your first paragraph relates to the second, but I can answer the following bit: 

Since the three operations ended within 3 miliseconds of each other, it looks to me like the first two simply were able to wrap up and report their completion just that little bit faster than the third. (Note the End_Time is the end time of the operation, not the time the operation was logged, which would be slightly later.) Note row E is the only stored proc call. It's possible there's slightly more overhead in wrapping up such a call. 

The process at $URL$ can help with this. To prevent it happening in future you may need to look at the configuration of the Distribution clean up: distribution job. 

Ok, with only a nightly large insert even nolock can only be an issue during that presumably minimal-activity period, so all I would suggest to change in your latest query version is to remove the "[varchar1] ASC," as it's unnecessary (since there will only be one selected) and will actually interfere. The indexing is going to be key. I'd try replacing your nonclustered index with the following: Create Index [i_table_index] ON Table1 (date1, varchar1, varchar8) INCLUDE (varchar9, varchar4, varchar5, varchar6, varchar7, xml1) This will satisfy your query without cluster key lookups. Why date1 first? Because only the first index column can be used for range scans, and clearly if your users are going to need up to 65k rows at a time they will need largish date ranges. However, it's possible the selectiveness of varchar1 may outweigh the range scan benefit, or that I've not fully understood the first-index-column-only rule (for which I can't find a good source at the moment--and it's possible the rule is actually range-scan-on-any-column-but-only-one). So since you've apparently got real-world data to test on, I would certainly also try this index instead (just the first two columns are swapped): Create Index [i_table_index] ON Table1 (varchar1, date1, varchar8) INCLUDE (varchar9, varchar4, varchar5, varchar6, varchar7, xml1) Also, beware that having date1 first may make the first query page (i.e. OFFSET 0) work nice and fast, but bog down with high OFFSET values. So test both index options with both high and low OFFSET values. Note I'm assuming that date1 ascending will be usable for the sort and fetch, but that depends how it's implemented internally. You may have to add DESC after date1 (in either index proposed so far), which I believe will make a internally fragmented mess of newly inserted pages in the nonclustered index--but perhaps you can run a reorg after the insert job. Finally, the long INCLUDE clause will duplicate nearly all the data in your table, which may be an issue especially with large XML. (Disk space may not be such an issue, but the added memory caching may make a difference.) So you may want to test with just varchar9 in the INCLUDE clause (kept there to efficiently satisfy the filter), as it's possible the non-filtering lookups may perform acceptably. And you might even want to try keeping the PK as is, having no non-clustered index, and clustering on (date1, varchar1, varchar8) which would satisfy the queries in the same way as the long include, but with no wasted space. However if it turns out you need DESC after date1, clustering in this way would possibly cause too much fragmentation pain. 

Given the low rate of inserts, your proposed index will be completely fine, and perfect for the usage goal. Given a fresh index with fill factor 100%, and sufficient history for each organisation to fill a page, there will be a page split on the first subsequent insert for each organisation. But then there won't be another page split for that organisation until the new page is filled up. Even these splits and fragmentation can be mitigated by starting with a <100 fill factor, and regular reorganise. Aaron's thought regarding using non-clustered was probably because that would allow you to cluster on the always ascending identity column, ensuring the only splits and fragmentation you will get is in a very compact separate index. But I suspect he was only mentioning that in the context of you wanting very much to avoid fragmentation, and not as something really necessary in this scenario. 

What you've described is really it. Self-signed keys are just fine for TDE in production as they will not need to be verifiable remotely. Having said that, using EKM apparently adds another layer of security. See here and here. But for self-signed, you can test your multi-domain requirement (which I'm quite sure makes no difference) using this info. 

Here's a start from $URL$ There are plenty of ways of monitoring DDL changes. You can set up DDL triggers to output changes to some set of tables. You could set up a task to monitor the default trace and try to capture changes into a table again. You could use Profiler to set up a server-side trace and capture events that show structural changes which output to a file. You might, if you’re feeling terribly smart and brave, use Extended Events. All of these are ‘intrusive’ in that they require actions that make changes on the server and possibly impact performance. We can discuss details of any that might be an option in your scenario. By the way, DDL triggers can actually capture the client IP using this: 

(First two paragraphs are repeats of my comments.) When Amazon specifies "log processing" as a use case, I'd suspect they're talking about infrequently-flushed IIS logs and the like, not database logs. And although ST1 is specified as not suited for "small, random" workloads, my reading of $URL$ would be that it's not suited for "small and/or random" workloads. But this, and your questions of how the limits are enforced/calculated, are probably something you need to get clarified from AWS. "Will SQL 2014 automatically increase the size of units it writes to the log in response to an increase in log file latency?" I'm pretty sure it won't by default. But if you can afford some data loss risk, then delayed durability may be just what you need: $URL$ If you do end up moving to ST1, AWS's online conversion option sounds far riskier than "Add a new ST1 volume to the mirror, take the mirror offline, move the log file from the old volume to the new one, then bring the mirror back up, failover, and repeat with the principal", which should work well for this. (Moving or dropping the primary log file with the database online is not an option.) 

If running your query multiple times in serial takes 50% overall of a 16 core CPU, that means it's going parallel internally (i.e. SQL Server is splitting up the work over multiple cores), and you can't expect linear gains by running it in parallel "externally" (or whatever the correct terminology would be...). Try your tests again with "OPTION(MAXDOP 1)" added to the query (SQL Server only), which will ensure each run only uses one core, and I think you'll see what I mean. 

Ok, at this point I would be considering "manually" replacing statistics to tide me over. I haven't done this myself, but it should work in theory... You can confirm that this would work as follows: 1. Restore the pre-upgrade database to your LIVE system and confirm that the query is fast in that database, and delete that database once done. (This test is to eliminate any additional environmental differences as the cause. If the query is slow, then the rest of this proposal may be useless.) 1a. Restore the pre-upgrade database to your test system and confirm that the query is fast. 2. Update statistics, and confirm that the query is slow (cancel after a couple minutes of course) 3. Set compat to 120 and confirm that the query is still slow 4. Set compat back to 100 and confirm that the query is still slow 5. Restore another copy of the pre-upgrade database (I'll refer to this as Rest2, and the earlier as Rest1) 6. Extract all statistics from Rest2 using the techniques at $URL$ for all tables involved in the problematic queries (or all tables if that's simpler) 7. Apply the statistics to Rest1, and see if query is now fast (you may need to dbcc freeproccache first). If it works, then it's almost certainly safe to apply the statistics to your live database--just make sure you have ONLY statistics scripted. And also set its compat level to 100. You should then see the queries run fast (though you may need to dbcc freeproccache first--but consider the possible effect on live performance). Note I'm assuming here (based on your original post) that you do not have statistics autoupdate turned on, and that your data changes slowly enough that your old statistics will do until you figure out how to get your workload working with compat 120 and/or updated statistics (and you may as well sort both at this point). 

The reason it's not working is that your join causes each row to be updated multiple times, but each update sees only the original values, not the cumulative values of previous updates. So your updates are in effect cancelling the previous updates. (Or maybe SQL only allows one row update per statement. Either way the result is the same, with different resource use.) Here's a quick and poorly formatted repro: 

Create a login that has only Public and DBcreator Server roles. Map the new login to user DBO in all existing databases. 

This may be a file permissions/uac issue. To prove/disprove that, create a new folder and copy (not move) the excel file into it, then give the windows security group "Everyone" Full control on the folder and its files. Update your export query with the new file location and try running it again. If that works (or if you at least get a different error), then bear in mind that wherever you want to have the export file in the end, the file will need read/write permission assigned for the user account your SQL Server service runs under. (Or the "Everyone" group, but that wouldn't be best security practice.)