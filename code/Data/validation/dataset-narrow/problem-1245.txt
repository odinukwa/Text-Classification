This looks a lot like the I/O API described by Felleisen et al in A Functional I/O System (or Fun for Freshman Kids). Basically, you write (in the simpler, non-distributed setting), a series of event handlers, each of which accepts the current state, and returns an updated state. Finally, there's a handler, which produces the "output" for each state. If we recast this API slightly, we can package up the handlers and the current state together, and each time a handler returns both a new state and a new set of handlers. We might call this package of state and operations an "object". :) If we then make the result a pair of this object, and the "output", then we have exactly the type of resumptions. Interestingly, in the paper, Felleisen et al do exactly this when moving to the distributed setting -- every operation returns a pair of new state and "output" in the form of messages to be sent to the other participants in the system. 

The relaxation of Calinescu, Karloff and Rabani for the undirected Multiway Cut problem is one my favorites. Had a big influence on subsequent work. $URL$ 

There is a nice book by Gartner and Matousek on SDPs and their applications to approximation algorithms. It covers a lot with the added benefit of giving a good introduction to the theory of semi-definite programming. See $URL$ 

Yes, this variant, and in fact a further generalization has been considered in the literature. See the paper below for the problem they call capacitated facility location. J. Bar-Ilan, G. Kortsarz and D. Peleg, Generalized submodular cover problems and applications, Theoretical Computer Science, 250:179-200, 2001. 

I strongly disagree with the last paragraph. Blanket statements like that are not useful. If you look at papers in many systems areas such as networking, databases, AI and so on you will see that plenty of approximation algorithms are used in practice. There are some problems for which one desires very accurate answers; for example say an airline interesting in optimizing its fleet scheduling. In such cases people use various heuristics that take substantial computational time but get better results than a generic approximation algorithm can give. Now for some theoretical reasons for studying approximation algorithms. First, what explains the fact that knapsack is very easy in practice while graph coloring is quite hard? Both are NP-Hard and poly-time reducible to each other. Second, by studying approximation algorithms for special cases of a problem one can pin-point what classes of instances are likely to be easy or hard. For example we know that many problems admit a PTAS in planar and minor-free graphs while they are much harder in arbitrary general graphs. The idea of approximation pervades modern algorithm design. For example, people use data streaming algorithms and without the approximation lens is hard to understand/design algorithms because even simple problems cannot be solved exactly. 

Then, you continue applying recursive bisection by cycling through the axes until # pieces = # processors, obtaining something like the following: 

and so on. You must understand that, in general, there are no rigorous rules of thumb when making these choices. As pointed out by @Suresh, this a matter of experience, requires a careful understanding of the domain, and some inspired guessing as well. The good news is that once you have made your choices, then there are rigorous ways to proceed. Probably, the best model overall for a given problem is the one given by the Minimum Description Length Principle (essentially the Occam's razor): the best model is the smallest one. But determining it is beyond hope. So, the best model is almost always, the one that works best for you, given your explicit and even implicit assumptions. That said, analytical and numerical approaches allows you to explore the behavior of a model, but the assumption here is that the underlying model is known. It's up to you to derive this model. Observational approaches allows you to derive a model from the experimentally observed data. Analytical models may lead to a closed-form solution; they are of great importance, given their power: if and when an analytical model may be successfully applied, then you will be able to deduce almost everything there is to know about a system. Their major drawback is limited applicability, since much of the world is simply too complicated to be described this way. Examples include ODE, PDE, difference equations, variational calculus and stochastic processes. Numerical models are required when the equations in an analytical model are too complex to be solved exactly in closed-form. This usually happens as soon as we move too far from linearity to nonlinearity. It's important to remember that numerical and analytical solutions are complementary approaches rather than exclusive alternatives. Examples include Runge-Kutta methods, finite element methods, cellular automata and lattice gases. Observational models can come from introspection or observation (or both).In some cases you may want to infer a model from experimentally measured data.This model may then be used to characterize and classify the data at hand, or to generalize from the measurements to predict the outcome of new observations etc. Examples include function fitting, SVD, Fourier and Wavelets transforms, neural networks, genetic algorithms, Expectation-Maximization algorithms, Wiener and Kalman filters, HMM, and time series. A very good introductory book you may want to read is The nature of mathematical modeling. Of course, given the huge amount of topics covered, do not expect a detailed treatment. 

See the following paper by Khanna etal on syntactic vs computational views of approximability. MaxSNP is a syntactic class while APX is a computational class. dl.acm.org/citation.cfm?id=298507 Made comment into answer as per Suresh's request. 

If the demands satisfy the no-bottleneck assumption, that is $\max_i d_i \leq \min_e c(e)$ then a constant factor approximation is known even for trees. See $URL$ which gives a 48-approx for trees. For paths a better bound can be obtained and may have been shown but I am not sure where or whether it was published. For the general case it is not quite clear what the best known result is. One can get an easy $O(\log n)$-approximation as follows. Consider the problem of maximizing the number of requests that can be feasibly routed; there is a constant factor approximation for this problem, see $URL$ Using this as a black box one can do a greedy set-cover like algorithm to repeatedly pack as many requests as possible to get the desired $O(\log n)$-approximation. A paper by Chalermsook on coloring rectangles may have some implications including giving an $O(\log \log n)$-approximation; the paper is available at $URL$ However it may require figuring out several technical details. One suspects that there is a constant factor approximation for the coloring problem. 

Our work on soft verification of contracts is related, at OOPSLA 2012 and ICFP 2014, allows you to write contracts, which are a lot like ACSL specs, and then either statically verify them or use them a dynamic checks at runtime. 

The ACL2 system includes all of the features of your language, and supports impressive automated theorem proving about program in that language. In ACL2, you would write the theorem you describe as: 

First, your friend is wrong about the history of the $\lambda$-calculus. Church created the untyped calculus first, which he intended as a foundation for mathematics. Fairly quickly, it was discovered that the logic derived from this calculus was inconsistent (because non-terminating programs existed). Eventually Church developed the simple theory of types as well, and many other things besides, but that wasn't the original point of the system. An excellent overview of the history is found in this paper. Second, the simply-typed lambda calculus is a quite restrictive language. You need some form of recursive type to write any interesting kind of program in it. Certainly, it would be impossible to write the kinds of programs in McCarthy's original paper with the $\lambda$-calculi based type systems understood in 1958. Cutting-edge programming type systems at that point were the ones found in Fortran and COBOL. 

The simplex algorithm is not in P. CLRS therefore states that, even though in practice it works "well", there are some inputs causing the algorithm to run in exponential time. This is strictly related to the algorithm, not to its implementation: you will face this independently of how exactly you implement the algorithm. However, LP is in P. This was proved by Khachian in 1979, however his ellipsoid algorithm is not practical. Today, interior points methods are widely used. The first one was discovered by Karmarkar in 1984. If you are interested in practical implementations, take a look at: GUROBI, free for academic use, is right now the best optimizer available (both sequential and shared-memory parallel versions): $URL$ the GLPK library: $URL$ this is an open source project, providing implementations for: 

The result by Tim Griffin that control operators such as are related to classical logic, extending the Curry-Howard correspondence. Basically, the typing of is such that if $E$ has type $\neg\neg \tau$, then $\mathtt{call/cc}{(E)}$ has type $\tau$. This works out when interpreting the type $\neg\tau$ as $\tau\rightarrow\bot$, as is standard in logic, and corresponds to the type of a function that takes a $\tau$ and never returns. That's exactly what a continuation does, making the correspondence work. His paper, "A Formulae-as-types notion of control", appears in POPL 1990. 

I believe that the following paper explores some of this connection, mostly by using continuations to backtrack when things happen in parsers. But there's definitely more to do here. 

Decentralized algorithms for variants of this problem have been published in A distributed and privacy preserving algorithm for identifying information hubs in social networks and Social Influence Analysis in Large-scale Networks. 

If you do not want to delve into the gory details, a very good introduction to parallelization design patterns is provided by the book Patterns for Parallel Programming by Mattson, Sanders and Massingill. You will find general, widely applicable solutions to parallelization and even a brief introduction to both OpenMP and MPI. The book starts by introducing design patterns and concurrency. Then, the authors proceed to illustrate how to exploit the concurrency, how to structure the algorithm, and how to actually implement the algorithm taking into account synchronization and communication. Again, this is not a textbook on parallel algorithms. It does a very good job of presenting materials strictly related to parallel software engineering, with both a practical and theoretical focus. Therefore, it should suit perfectly your needs. 

Core calculi for Java typically take the classes-as-types approach. Two well-known examples are Featherweight Java and Classic Java. 

First, this entirely depends on what you take to be your set of contexts. If is a context, then contextual equivalence is syntactic equivalence. Traditionally, contexts for contextual equivalence are taken to be contexts in which "expressions", in whatever meaning that has in the language, can appear. This rules out contexts like , where the context places its argument inside a string literal. These kinds of contexts were also, IIRC, ruled out by Quine when he originally described referential transparency. From this perspective, I think is also not a context. Instead, the contexts are the places where expression evaluation could potentially happen, such as in the body of a function or in the argument of an application. Potentially problematically, this means that in a Lisp program with macros (or a Racket or Scheme program) you don't know what the contexts are until you run the potentially-nonterminating macro expansion process, because you don't even know where the expressions are. Whether you think this is a problem or not is mostly a philosophical question rather than a technical one. 

I am interested in understanding the structure of the class of graphs $G$ such that there is no vertex induced subgraph on four vertices that is a perfect matching. Stated differently for any four vertices $a,b,c,d$ in $G$ if $ab$ and $cd$ are edges then the graph should have at least one more edge on the four vertices. Has this class been studied previously? Any references or insights would be appreciated. We understand this class when restricted to bipartite graphs but the general case seems more tricky. 

I will consider the case of non-negative weights only. As I mentioned in the comment the problem is related to the minimum k-way cut problem where the goal is to partition a given graph G into k non-trivial components to minimize the number (or weight in the weighted case) of edges crossing the partition. This is the same as maximizing the number of edges in the partitions. Since k-way cut is NP-Hard the maximization problem is also NP-Hard. However, for fixed $k$, $k$-way cut can be solved in polynomial time. In terms of approximation here is an idea to get a simple $(1-2(k-1)/n)$-approximation which is good if $k$ is small compared to $n$. To see this, simply take the partition to be the $k-1$ smallest degree vertices and the rest of the vertices. In terms of the k-way cut the # of edges cut by this partition is at most $2(k-1)/n \cdot |E|$. Thus the number of edges remaining inside the large piece is at least $(1- 2(k-1)/n) |E|$. Update: If the weights can be negative then I believe the problem is inapproximable via a reduction from k-coloring. Given a graph $G$, set each edge's weight to be $-1$. Thus we are seeking a $k$-partition to minimize the number of edges inside the parts. If $G$ is k-colorable then we can achieve 0, otherwise it will be at least 1. In terms of the negative weights the max value will be 0 if $G$ is k-colorable, otherwise no more than -1. 

The simply-typed lambda calculus is actually surprisingly weak. For example, it can't recognize the regular language $\mathtt{a}^*$. I've never found a precise characterization of the set of languages that STLC can recognize, though. 

Game theory played a significant role in solutions to the "full abstraction problem" in programming language semantics. In particular, the first fully-abstract semantics for Plotkin's PCF were given using games as models. The relevant citations are: Full Abstraction for PCF, by Samson Abramsky, Radha Jagadeesan, and Pasquale Malacaria and On Full Abstraction for PCF: I, II, and III, by J.M.E. Hyland and C.-H.L. Ong which both appeared in Information and Computation, Volume 163, Issue 2, 15 December 2000. 

Reynolds is referring to so-called unhygenic macros, as found in traditional Lisp implementations, including modern Common Lisp. The basic problem is that a variable referenced in a macro might change behavior when the macro is used, or that a variable seemingly bound around a macro use could be inadvertently captured by the macro. These issues were first remedied in macro systems for Scheme, in particular Kohlbecker et al's 1986 paper Hygenic Macro Expansion, and improved by Clinger and Rees' 1991 paper Macros that Work.