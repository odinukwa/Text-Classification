Can you use and to read in all of your numbers and operators at once, from a line like or ? matches a regular expression, and is the pattern for any single character. Error Handling: What happens if the user types in a bad operator? If someone tries to ask for , the operation is ignored in this case. Instead of getting the result of = 12, they could get a result of 21 without realizing there was a mistake. A good way to protect against that is to use a statement in your switch block. A way to handle these errors and let the program or the user know there was a mistake is by writing 

is a primitive type, while is a class. That distinction won't cause a logical error here, but consistency always helps when a program grows larger and more complex. Order of Operations: Your program handles each step of the calculation correctly, but it doesn't understand Order of Operations. That's a more complex concept that you'll have to look at a whole expression for instead of being able to handle each operation piece by piece. The fully object-oriented solution is to treat the expression and the individual operations as their own objects and apply logic to those objects piece by piece. You could, for instance, create a list of numbers and operations, and scan through that list, applying the highest-priority (multiplication and division in this case) operations first. The fully functional solution is to scan the expression and use recursion to decide which numbers need to into first, returning the results of each step up until the base function returns the final answer. There are many ways to do it, and you can think about how you'd like to implement it in your calculator 

In addition to @Edwards excellent answer there are some things I would like to mention: Pass by reference to const unless you need a copy When you pass an argument to a function like here: 

As you can see no bias here. The things to take note of: The reroll takes care of the bias; and using the largest possible chunkSize and thus using the largest part possible of the output range of rand() avoids the issue with the low bits being of poor quality (unless you have a very large range but then you're SOL anyway). The probability of a re-roll is: 

As you haven't explained what the code is supposed to do I'm going to go out on a limb here and assume that it is a filter for a text box that will show suggestions/predictions for what you are about to type. Better data structure If that is the case then there is a data structure called a Trie (wikipedia) which is commonly used for this. By using a trie you will get faster performance and less memory usage than your current code. You should check it out. 

Nice solution. This code is pretty legible, which is great if you have to debug anything. There are a few simple ways you can make your program more user-friendly and resistant to user error. Input: For the user, it can be tedious to type in their values on every line, always being asked for 

is never actually changed or used. is functionally equivalent to the loop that you wrote. This is a fairly common pattern, and there are a few ways to go about organizing it. Yours is handy because the variable communicates that this loop will continue until something is 'done'. The best place to explain to the reader how a loop is supposed to terminate is right there in the condition. One more descriptive (but also less clean) way to write that condition would be 

This assigns the operator to and performs the comparison without the need for a statement. You can use a do-while loop to handle the first number and print "Operator: " to the console before reading , if you like. 

Object Oriented Programming: Generally, static variables should be reserved for variables that are shared between multiple instances of a class, and any other variables should be made local or non-static. The static variables you've defined here work properly, but reorganizing the methods and changing the variables into local ones will make it easier to add functionality to this calculator later. 

See the examples at RosettaCode or Wikipedia for example. For comparison, RosettaCode's Trial Division task has a loop like your function. So the immediate performance issue is that a sieve will be much faster than trial division. 

In general it looks good to me. I'd clarify the comments a bit more. Q=1 is typically used for the extra strong Lucas test, P=1,Q=-1 is used by about half the cases for the standard or strong Lucas test (the rest have a different Q). Some info on the various tests can be seen on my Pseudoprime Statistics page. What happens if n is even? For example, Lucas_5(6,1) = (1189,6726). Mod 1000 should yield (189,726). But the routine gives us (689,726). This is an artifact of the halving method used. My solution was to use a different, slower, method in that case, since it's rarely used (never by a standard primality test, but there are more uses that just those). For D=0, we can return a solution. See the Wikipedia page. Check the cases where P and/or Q and/or D exceeds n. It looks from a quick test that the returned Q_k values are out of range for k={0,1}. Doing a check and mod up front may improve performance. Consider instead of using libmp. Up to you, but I like fewer dependencies. I don't know all the tradeoffs between the two however. For the Q=1 case (used by the extra strong Lucas test) there is yet another method that can be faster. If D can be inverted mod n, then we can calculate V_k with 2 mulmods per bit, then compute U_k using the inverse. I hate to add more cases, and of course you'd need to benchmark to see if it worked better for your infrastructure and use. 

Background I'm writing code for an 8-bit MCU with very limited RAM (1KiB) and program flash space (64KiB). I have a C++14 capable compiler with no standard library implementation available. This is a good enough excuse for me to do some recreational template programming. :) In the project where I intend to use this I need to be able to create a densely packed, complex, configurable tuple of varying types and values. And I need this data structure to be stored in program space, so I need it to be usable as . About the code In the code below I have used for the size type because the MCU has 8-bit words and an (which has to be 16 bits to be standard compliant) thus is "extended precision" for my MCU and incurs speed and program size overhead. And frankly, with 1K of ram I'm not expecting to make tuples with more than 255 elements. The code is put into a single file for your reviewing pleasure and uses which is technically not available on my target, but I intend to re-implement it as the next step. This code is written for PC first to be able to debug and test it. I'm happy for any comments on suggestions on the code, but please bear in mind the target architecture. tuple_test.cpp 

Once happy with what you have, you may find it entertaining to look at some other solutions, e.g. Haskell, Perl serial / parallel, PARI and Mathematica Additional info Dec 2016: Example times for fast implementation in serial, time for first n Fibonacci primes: 

Unless I'm misunderstanding what your iterators are doing. A simple SoE will have something that looks like: 

It's possible to improve on this using gwnum instead of GMP. The former is much faster at compositeness tests for large inputs (over 4000 digits). The downside is that programming correctly using it is much harder than GMP. Typical use in 2016 would be using something like the GMP program to do the selection and sieving to output candidates, then use a script running PFGW to weed out composites using its fast Fermat test, then using GMP again for a good primality test on the results to confirm. 

The problem is that for arbitrary 18 digit numbers this is still going to be slow and may or may not hit your target time (it's about 0.11s each for 1000 numbers on my computer with 10 other computations running). I can speed that up about 3x using primes to 2000 then a mod-30 wheel. Going to Pollard-Rho makes it run thousands of times faster. If you really need it fast, you're going to want something like Pollard's Rho, Brent's improvements to Rho, P-1, or SQUFOF. Trial division (even efficiently done) is just too slow for general numbers this size. The basic Pollard's Rho is pretty simple -- the only real trick is doing an efficient . Brent isn't too hard -- more or less just running the gcds in batches with backtracking when needed. For this size, P-1 is probably going to be slower than Rho/Brent. SQUFOF is more complicated to implement. An additional complication is that now you need a primality test to know when you're done (deterministic M-R with at most 7 selected bases, or BPSW). It's possible to skip that by just using Rho etc. opportunistically, but that doesn't fully utilize the idea.