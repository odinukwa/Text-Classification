You are changing the source address on the IP packets. Router0 will not ARP for an address in the range you are translating to because it knows it has no direct connection to that network. ARP only works for directly connected networks. What you need to do is to let Router0 and Router1 know to go to for any destination addresses in your translation range. This is routing 101. A router gets routes into its routing table from three different ways: directly connected networks, statically configured routes, and/or a routing protocol. Since your proposed network is not directly connected to either Router0 or Router1, you will need to either statically configure a route for it in those routers, or you will need to run a routing protocols with those routers and the ASA, and have the ASA tell those routers that it has your translation network via . You also need to somehow let the ASA know what networks are behind each of the other routers. 

This really is vendor specific, and it depends on what you mean by traffic filters. Most business-grade routers support some form of static access lists. Some have cloud-based support to get filter changes. Reflexive access lists, firewall features, NAT support, etc. may depend on both the vendor and the license level, and could be considered dynamic filters, allowing inbound traffic only for established outbound connections. 

Dynamic ARP Inspection and IP Source Guard require DHCP Snooping to function. What happens, assuming you do not have trust configured between the switches is that PC-A will not work when connected to Switch-B because Switch-A knows the IP address of PC-A belongs only on the original interface to which it was connected on Switch-A. The DHCP Snooping on each switch is independent of the other switch; the switches do not share this information. You configure it on each switch, and you configure trust for that between the switches. Each switch then manages this for the devices connected to itself, and trusts that the other switch is doing the same. 

Also, why are you using half duplex for the connections to R1 and R6? You should use auto, except under extraordinary circumstances that require half duplex. 

Most telcos will assign/sell you one or more DID (Direct Inward Dial) range of numbers, and these can be much larger than the actual number of outside lines that you have. This can be an entire exchange (expensive), or a small range (e.g. 10 numbers). 

The loopback interface is useful because it is an interface with an IP address which never goes down. OSPF, without a specifically defined Router ID, will pick a Router ID on its own. It chooses the Router ID from the IP addresses of the configured and enabled interfaces. A loopback is a good choice since the loopback interface is always up unless someone specifically shuts it down. Other interfaces may go down if there is a problem on the link. 

TCP can't get scattered over different servers. TCP is a connection-oriented protocol, and it creates a connection. If a link to a server to which you have a connection goes down, the connection will time out. You would need to create a new connection to the next server in line. Anycast is nothing more than using the routing protocol to get the traffic to the nearest network with that network address. 

You have a misunderstanding; there is nothing in OSPF which has any requirement for BGP, or any other routing protocol. The OSPF concept of AS doesn't mean that it must be a BGP AS; it means that it is a network outside the scope of the OSPF areas connected to the area 0 for the OSPF area. The outside AS can be as simple as connected routes of a router which are not natively injected into OSPF. Using redistribution to get the connected routes into OSPF makes them external routes (routes from a different AS) inside OSPF. In fact, you could have two OSPF ASes which can redistribute routes from one to the other using redistribution. As far as OSPF is concerned redistribution from any source into OSPF is injecting routes from a different AS. A stub area which has routes redistributed into is would need to be NSSA. 

Collapsing IPv4 addresses like that is not a standard the way it is with IPv6. There are some applications which can take addresses like that, but you will find that most do not. It is fine, and recommended, to leave off the leading zeros in each IPv4 octet (some things will misread leading zeros to mean octal notation), but you shouldn't collapse octets. 

I'm not completely following your question. Any IP address assigned to your computer is a real IP address which your computer uses. It may be a private IP address which can be reused in different networks, or it may be a public address which is supposed to be unique in the world (I think this is what you mean). IP addresses are assigned to your computer either by being statically assigned, or being assigned through DHCP. If you want to know the public IP address assigned to your router, then you can look in your router, or browse one of the websites which will tell you what your public IP address is. The ISP owns one or more blocks of public IP addresses, and it will assign your router an address via DHCP or PPP. Since some RIRs no longer have nay blocks of public IPv4 addresses to assign to the ISPs, many ISP have started using CGN which will assign private IP addresses to your router. This causes a double-NAT, which causes all kinds of problems. The ISP does not assign your private IP addresses, you do that. There are three blocks of private IP addresses (, , and ) which you can use to assign your private IP addressing. The router manufacturers all used to use , but in recent years, they have mostly moved to using . It doesn't matter which block of private addresses you use. Your router is running NAT which translates all your private addresses to a single public address (assuming your ISP isn't using CGN). In order to reach your LAN from the public Internet, you will need to set up NAT forwarding rules to be able to translate from the public IP address to one of your private IP addresses. This is known as port forwarding, and it is done by TCP or UDP port number, and you can only have one TCP or UDP port reach one private IP address inside your LAN. For instance, if you run a web server (nominally port 80), you can configure your router to forward any traffic arriving on the public address using port 80 to the web server inside your LAN. 

This type of thing is handled in routing all the time. Your MikroTik is off-topic here, but your Cisco router is on-topic. In your Cisco router, you can set two static, default routes with different administrative distances. The link with the lower AD will be preferred. When that link goes down, the route is removed from the routing table, and the other default route now takes over. When the preferred link comes back up, its route is reinstalled in the routing table. This is called a floating, static route. 

The first entry with the destination of with a mask of means that any IPv4 packets which don't match any other entries will be sent to the gateway . The second entry of with a mask of means that any IPv4 packets withing the range of will be sent on the same link as this host. In other words, any packets destined for the local network will use ARP (or the ARP cache) to build a frame for the local network. Any other packets will ARP (or use the ARP cache) for the gateway MAC address to build the frame. 

I think you are looking at this incorrectly. Typically, you would have multiple SSIDs, including one for guests. The VLAN for the guest SSID would only be allowed to be routed to the Internet, while other SSIDs would be on networks which have various internal access restrictions, or not. Often, 802.1X is used for such authentication, but there are other authentication methods, and Cisco WLCs support several (see Authentication on Wireless LAN Controllers Configuration Examples). A guest would only be able to be authenticated on the guest SSID since the guest credentials will not exist for the other SSIDs. 

The IP protocol defines the network addressing. The TCP protocol is one of many protocols that can ride on top of the IP protocol. TCP and UDP are the two most talked about layer-4 protocols that ride on the layer-3 IP protocol, but there are others. This provides flexibility in networking that would otherwise be unavailable. 

Setting up the configuration synchronization mode () involves creating a switch profile (). Cisco has a lot of documents regarding this, e.g. Chapter: Configuring Switch Profiles: 

Routers route between networks, not from a network back to the same network, so each router interface must be in a different network. There are a couple of ways to handle this, but the easiest would be to simply set up a transparent firewall between the cable modem and the workstations. If you need a router because you will have several networks behind it, then you can use private addressing and one-to-one NAT for the workstations that are going to use the public addresses. The most awkward way would be to subnet your public address block because that would waste addresses on network and broadcast addresses for each subnet. 

You are back to comparing apples and oranges. You just can't compare two dissimilar things. Routing protocols are used to determine the direction traffic should be sent. How it is sent (switched) in that direction has nothing to do with the routing protocol. You can use a map to determine the direction to go to get to a particular location (routing), but how you get to the destination (switching) can be by walking, car, bus, plane, train, etc. One really doesn't necessarily depend on the other. 

Layer-3 switches are layer-2 switches, with some routing. Ports used as layer-3 ports will not use STP since it doesn't make sense to use it on a routed link, but the ports used as layer-2 switch ports will have STP. In most layer-3 switches, how a port is used (layer-2 or layer-3) can be changed by configuration. It is also possible to disable STP on many layer-2 or layer-3 switches. As Sebastian pointed out, the are far too many switch manufacturers and models for there to be any single source to add to your documentation. 

Think about years ago. Your internal links were probably 100 Mbps, but your External links were probably T1 (1.5 Mbps) or maybe T3 (45 Mbps). If you had two external paths, one on a T1, and one on a T3. You would want to always prefer the external path using the T3, so you would assign fixed costs to each of the external paths, preferring the T3 path. It really makes no sense to count the internal cost because of the great discrepancy between the primary and secondary external paths. The internal cost is relatively minor compared to the external speeds. Contrast that with today, where you may have 1 Gbps internal links, and 1 Gbps (or maybe even 10 Gbps external links). It then makes sense that you also count the internal cost because the internal cost is greater than the external cost. 

Today, almost all switching, and much of routing, is handled in hardware, so the processor speed comes into play for exceptions. For things like servers, it is possible that the processor isn't fast enough. This has been the case in the past. When 1 Gbps ethernet first came out, the bus used in PCs and servers could only handle 400 Mbps. What happens when the processor isn't fast enough is that traffic gets dropped. A lot of traffic may be dropped, anyway, since that is how congestion is handled, if done correctly. RED (Random Early Detection) is a method used to randomly drop packets in queues in order to prevent them from filling and tail-dropping packets. This can help to prevent TCP synchronization. A lot of drops occur on switches, where multiple ports of a speed may need to send to another single port of the same speed. 

That depends. If a host sends an ARP request to another host, including a router, but it receives no reply, then the host ARP table entry will be marked for the router IPv4 address. What the router has in its ARP table depends on whether or not the router got the ARP request, and whether or not the router already has an ARP table entry for the host. 

You must use an SFP module and cable that is of the same standard as what you have on the switch. That is probably a SPF module. You insert the SFP module in the SFP interface and connect the cable between the devices. You must also configure the interfaces. Typically, you will either enable routing on the switch and configure a routed interface, or you will configure it as a trunk and configure subinterfaces on the router. 

A bridge (a switch is a high-density bridge) can help reduce the number of devices in a collision domain by breaking a single collision domain into multiple, separate collision domains with fewer devices on each collision domain than were on the original collision domain. Each interface on a bridge is a separate collision domain. Assuming you were replacing a hub, where every interface is in the same collision domain, with a switch. Suddenly, you have more collision domains, but there are less devices on each collision domain than were on the original collision domain. 

I'm not completely sure what you mean. A link will have a bandwidth. Let's assume 10 Mbps ethernet. Ethernet has some overhead: a seven octet synchronization, a one octet start-of-frame delimiter, a 14 octet frame header, and a four octet frame-check-sequence. There is also a 12 octet inter-packet-gap between frames. When your 100 octet packet is encapsulated in an ethernet frame, then it ends up as a 126 octet frame. At 10 Mbps, it takes seconds to fully transmit. Your 5000 octet packet is a 5026 octet frame that takes seconds to fully transmit. Obviously, it takes nearly 40 times longer to transmit the 5000 octet packet than it does to transmit the 100 octet packet on ethernet. The bits travel at the same rate, but you have 50 times the number of bits in the larger packet. All this assumes that everything is on the same LAN. Notice that the percentage of overhead is much larger on the smaller packet, so if you are transmitting a lot of data, it will take longer with smaller packets than larger packets due to the amount of overhead on the frames. That doesn't take into account the overhead on the packet headers themselves, nor the overhead on the transport layer datagrams. Individually, larger packets take more time to transmit, but in aggregate, data may be sent faster with larger packets because the percentage of overhead is smaller with larger packets.