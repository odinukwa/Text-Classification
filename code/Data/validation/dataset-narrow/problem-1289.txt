Now I won't end up using this, it's for the initial networking testing phase. I'll probably end up using dead reckoning. However I have a couple questions: 1: I am using TCP for all my networking. However it jumps and skips if you drop any packets at all, so I'd like to switch to UDP and have a numbering mechanism to make sure all packets arrive. Is there a preferred Networking Schema for game communication? 2: For critical things like object hits with bullets Should I implement a second port for these important events, or just use the same UDP proto? 3: (Side Question) How should I regulate my framerate with the networked game? I don't want to have an unnecessary Sleep in each frame... 

Local Host: All the network testing I've done on localhost has been completely misleading. Since it's a perfect environment it's useless... Packet Loss: The packet loss and latency you experience will differ based on your current lan set up. I've set up on several separate routers, and gotten completely different results. Recommendation: It would be horrifically slow to compile, throw the executable elsewhere, recompile (in the beginning, before menus and such) run it on your compie, and connect, then test. What I've done lately is have a persistant server (on another computer) that simply forwards whatever is sent over any port to a partner, and set my program up as a client, so there's no further config necessary. It's a path that's treated me well so far. 

Well When I play games I absolutely hate the opportunity to cheat until I've played the whole way through. Because I'll get frustrated with one part and want to skip it, so I'll revert to cheats, but it will make the whole game horribly boring! What I'd do is have the player run through at least once before enabling cheats. Then once you do, enable them all, because it really should open up the game, make it a sand box of sorts. 

The important step here is when you have a bottom collision you add the other object's velocity to your position. This allows you to move about freely on their platform and have your own physics unaffected by it's (you may want to, instead, change your axis velocity to theirs and add their other axis's position to the object in question) 

Instead of delaying a set number of frames, why not only update frame if the time elapsed since the last update is xx? (for instance 100 ms) You're animations will look great- and won't depend on your framerate. In other words: have a class variable to store the update time, and when your update function rolls around, if (the current time - previous update time > desired frame time) increment frame() 

Forenote: My engine uses a collision detection class that checks collisions with all objects real time, only when an object moves, and only in the grid squares it currently occupies. My Solution: When I ran against problems like this in my 2d platformer, I did something like the following : -(engine detects possible collisions, quickly) -(game informs engine to check exact collisions for particular object)[returns vector of object*] -(object looks at depth of penetration, as well as previous position relative to other object's previous position, to determine which side to slide out of) -(object moves, and averages it's velocity with object's velocity (if the object is moving)) 

I know that many games are using bitmap fonts. Which are the advantages for vector-based font rendering / manipulation when compared to bitmap fonts and in which scenarios would they matter the most? Prefer a focus on 2d games when answering this question. If relevant, please include examples for games using either approach. EDIT: Please also include your personal preference if you have experience with the matter. Some factors you might consider: 

Background: I am developing a simple falling blocks game in 2d, targeted for pc. I would like to add text labels for level, score, and menu buttons. I am using SFML which uses FreeType internally, so vector-based features are easily available for my project. In my view, font sizes in simple games often don't vary, and bitmap fonts should be easier for cross-platform concerns (font-formats and font rendering quality). But I am unsure if I am missing some important points here, especially since I want to polish the looks of the final game. 

In order to detect and reproduce bugs in an MMO, recording game sessions on the server can help. How can such recording and replay of the data be implemented to be accurate, i.e. be 100% deterministic / produce exactly the same result on each replay? I intend to record timestamped incoming messages as the only data necessary, if possible. The playback would use the database snapshot as present at the beginning of the recording. Details about the MMO 

If the background is static you could probably come up with a background size which works well across most devices because the general form factor is similar - unless you also target pads in which case you probably need two versions anyway. The third option mentioned is suitable if the background can be constructed from repeatable tiles, like a brick wall. 

With barely enough time at our hands to complete the games we craft, how can you strike a good balance between solid software architecture and making good progress to get it all done? My personal challenge: How about being effective today and long-term thinking at the same time? Plus, while you're doing it you may just as well want to learn new things on the way instead of resorting to the same repetitive patterns you've been using those past 5 years? 

In particular, consider timing issues: If run-time for computations on playback differ from the run-times when recorded, frame times will also differ and can for example affect the movement of NPC units (move 3px instead of 1px). How to make sure that in the replay AI has the same time constraints compared to when recorded? Fixed time-step? Record the time deltas between each frame and on replay make sure those deltas determine the actual frame time? 

constructs a new SkullDemon object and assigns it to the skullDIns variable. Subsequently you modify this copy instead of the object in the container. I think you should have more success doing this: 

I would recommend SFML if you are using c++. It will get you something on the screen quickly and using it with your c++ game code is straight forward. 

I've never used Unity, so I don't know what it has to offer for this specific problem, but I would create this effect with one of these methods: 

You can create a room that is in the shape of a regular convex polygon with arbitrary sides, size and rotation. Steps: 

If my understanding is correct, this moves the memory from VRAM into RAM. Casting the render target to a texture does not move the memory into RAM, so it was still subject to VRAM shenanigans. 

If your projectile has a consistent velocity throughout, here is how to make it stop exactly on the target when it reaches the target: First measure the distance between the starting point of the projectile and the target. 

You can then create a doughnut shaped room by subtracting a smaller generated room from the center of a larger generated room. You should keep the walls of the smaller generated room though. Since I found this interesting I went ahead and tried implementing it myself. I would recommend not looking at my code until you have tried to write it yourself though. 

My game generates small "minimaps" for each room you go to, which are rendered onto render targets then stored in textures and displayed on the world map. When the game is saved, each new minimap is saved on the hard drive. If the game is in full screen and the user minimizes the game, the minimaps that were generated, not loaded off the hard drive, will become blank. Since I don't know exactly what render targets are doing in the background, I have no idea how to prevent this, or restore the textures if they are lost. How can I prevent/workaround this problem? EDIT: I did do 

I'm trying to make a shader that changes the color of a sprite the way the XNA spriteBatch.draw() color parameter changes color. I don't know exactly what it is called (the closest word I can think of is 'tinting' but that's not right I don't think) and it's kind of hard to explain the way it looks. Say you set the parameter to 'Red' -- white pixels in the original texture would become completely red, while black pixels would remain black. Grey pixels would look dark red, blue pixels might look purple, green pixels might look brownish. If you set the parameter to 'Black' the texture would become completely black. Does anyone know the math behind this, or what this technique is called? It's probably very simple and I'm just not seeing it. Thanks! 

Where and represent the position of the target. You'll also need to keep track of the distance travelled, so just make a variable like . Then, whenever you update the position of the projectile, you'll need to add its value to . When exceeds , you know the projectile must have gone through the target point. 

but alas, this conversion doesn't seem to prevent the issue from occuring. I believe this is because is still a reference to a render target. Perhaps I need to perform a deep clone? If so, how? Also, the preserve contents thing doesn't work for this situation either.