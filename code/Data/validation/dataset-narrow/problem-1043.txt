The bottleneck is - as you assumed - the upstream: If it is saturated by the upload, it will introduce high latency into the TCP packets (as far as large downloads are concerned) and on DNS queries and HTTP requests (as opposed to their replies) - this will result in a highly perceivable sluggishness. Since the biggest part of this latency comes from queing and buffering, the solution is to throttle your uploads to something like 95% of available upload bandwidth - this will keep queues and buffers close to empty but will not significantly impede your uploads. 

A dead battery can easily trick the power supply logic into a state. When gaming, it is absolutely possible, that a spike in power consumption overloads the AC power supply, taking energy from the battery for a few milliseconds. If this fails, the PSL will shut it down. A second after the load spike, these few joules will charge back into the battery. The fact, that meager AC power supplies can barely power the Laptop under full load (leaving no headroom to charge the battery) is one of the reasons, why business class notebooks often come with different sizes of AC adapters, a light (but meager) one for the road and a true flying brick for the office. 

What of course remains as a privacy risk is, that the GPS data is open to everybody who listens in - this might or might not be acceptable to you. 

URLs exist in database for easy maintainability A Script (bash, PHP, whatever) creates a PHP script from the DB and a template, defining an array with the original path as the key and the new path as a value, then looking up the requested document path and if found redirecting to the new one, if not showing a 404. This "script creating script" is run, if the DB changes The generated script is used as a 404 fallback 

Finally use to remove the orphaned PV (with pvpath most likely being , you should check with first) I recommend you use on your PV after releasing it, but make sure you use the correct pvpath (check with before releasing it) After that, you can use the partitioning tool of your choice to adapt the partitions to your liking, this might include creating a smaller PV or not. 

The only way to provide a "hard real-time" guarantee without a race window is to make sure, a write is acknowledged only after it has hit both sides. The usual way to achieve this is with a cluster file system (such as OCFS2 or GFS2) on a shared block device. Such a shared block device can easily and inexpensively be build using DRBD. As with any sync mechanism, your intra-cluster network must be able to carry the change rate with acceptable latency. The cheat sheet is around the lines of 

Now you can calculate the number of repetitions necessary. As an alternative, you can just use a "safe" number of repetitions, as too many won't hurt. Step 2: Loop the file and cut it to needed length create "concat.txt" with this content 

EDIT There seems to be a discussion about the overvoltage question going on in the comments - let me clarify: No charger in the world will give a 0.000000% tolerance on the stated voltage, e.g. my HP-branded laptop charger produces between 18.4 (highest load) and 20.9 Volts (idle) while specified for 19.4 Volts. I found this out, while a checked a cheap chinese car charger and used a multimeter to compare it to the original charger. This is why all devices (including laptops) are designed to handle a +/- tolerance on their respective stated input voltages. Laptops tend to have a very high tolerance, as they have switching power circuits inside them to cater for the many different voltages a laptop internally uses (From ca. 1.4 Volts to ca. 14 Volts) This implies, that a charger with a small (5%) difference on the nominal voltage is very unlikely to do any harm to the device. And i did call it a rule of thumb because no universal hard limits can be given. 

Again: I advise strongly not to do that, it might be much easier to adapt your file to allow without a PW 

So attaching USB hard disks to two hosts at the same time is a tricky proposition: Neither the bus, nor most of the file systems are designed to do that. The typical and most likely best way to tackle this problem is to attach one disk to each computer, then use network shares to make it accessable to the other. 

In Disk management removing the drive letters from the other partitions should do the trick - Windows will (better: should) remember this setting for this USB stick. 

There is a solution that seems tu do exactly whjat you want: the cyrus server together with its implementation. basically is a server-sided domain-specific scripting language, that allows you to create elaborate rules for finding a target folder for an email. Its intended use is to auto-sort e.g. mailing list mails into their respective folders, but since any header can be used as a criterion, you can also use the receiver. A complete setup would consist of 

13 hours seems quite right, prepare for test 3 and 4 to take REALLY long. But in fact, you can already cancel it: There is something wrong with your memory subsystem, not necessarily the RAM itself, but most often so. Try reseating the DIMMs and running it again, but don't be too hopeful - in case the errors reappear in a second run bisect the error: Run memtest86 with DIMMs 1&2, 3&4 and 1&3 - this will tell you waht you need to replace. EDIT: renamed 'pass' with 'test' in the first sentence to accuratly reflect current memtest86 nomenclature 

Gearman's config file is a bit hidden under Ubuntu: Take a look at . Adding will listen on localhost, while might be what you want. 

The most transparent way to achieve this, is to manually loop: Automatic loop works only in very new versions of ffmpeg, which might not be available in many distros. First create a concat file , that repeats A 3 times: 

A nice fellow named John van Sickle maintains up-to-date static builds of ffmpeg at $URL$ Static build ofcourse means, the binary is largish, but you simply don't care for a two-page dependency list. I always wanted to thank John - looks like a good place to do so here. 

Hebrew is written right to left - this makes the aleph character carry the information, that the next character should be printed left of it. If you hex-check your document (or move the cursor through your text with the arrow keys in a suitable editor), you will notice, that you get to the alpeh first, then to the digit. I.e.: The assumption "next character == character to the right" does not hold. 

You need a 2-Step process for each clip, plus some preparation Preparation: Create 1s silent black video by using /dev/zero as input with exactly same codec settings as the clips Per Video (assuming video is 34.56 secs long): Write concat file 

After your changes, you no longer have a problem, but a simple problem: After cloning, your will be the same on and , so you will need to edit the version on and have it point at the new UUID for the root file system. 

You might want to add some stricter checks including sanity-checking, as nmblookup might fail, if myServerName is down: 

Use your batch file, then create a shortcut () to it with window type set to "hidden". Now set this shortcut as a handler for the file typ . The point is, that the window style "hidden" is applied only to the initial window (the batch file), but not any susequent windows opened (i.e the GUI window) 

A NAS will typically not access the OS disk at all, after ist has completed the startup - so you won't see a difference. That said, you might want to take care, if, where and when it writes logfiles: Log write load can be a PITA with USB. 

First of all: We are talking of incoming mail here - remember, that outgoing mail is a completely different thing. No for this to work, you need two ingredients: 

As for the first part of the question: While a spinning disk has read and write operations on the physical layer as well as on the logical, the physical operations on Flash memory are , and . This implies, that a logical write is translated into a on an empty (erased) block. Modern SSD controllers keep an inventory of already erased blocks and use these to satisfy a logical write as fast as possible. The erase operation for the now unused cell can be deferred to later, if current bandwidth demands or controller load are high. So in fact using a different block is nothing but a performance tuning mechanism, albeit a very important one. 

Short answer: Yes you can Long answer: Applications (as opposed to the OS kernel components) do not see the "real" (or physical) memory layout. The Computer's MMU is instructed by the OS to create a unique "fake" (or virtual) memory layout for the application, that is essentially empty. The process will simply not see the RAM that is already used (apart from Statistics) 

Not in an R710, but I have seen this with other onboard Broadcoms, it was always a defective NIC, I suspect you will need to either add a plug-in NIC or do without it. You can verify this by booting from a plain vanilla (non-XEN) USB stick and saturate the NIC (e.g. with a few s) - you will most likely see some error messages concerning bus errors just before the crash. 

As mentioned in the comments, there is a fundamental difference between a stereo file and a stereo recording. Nothing stops us from creating a file, that has both stereo channels fed from a single audio source - this is e.g. Standard for old recordings remastered for CD. The typical way to get an idea of whether a stereo file actually contains sterophonic content is to calculate the quadratic sum of the number of zero-passes per second on both channels. I do not know, if Audacity or other free software tools have this bilt-in. Turns out, that the human eye is quite good in spotting channel differences, so if the number of recordings to check is low, a wave graph (as produced by audacity) should give you a good feel, whether this is stereophonic or not. 

You would start by checking existance of the disk by looking at , then run on it, parsing the output for "ext4", then try to mount it. Failures in and would lead to a and a retry. 

Only under very controlled circumstances: Both computers must have a compatible processor and operating system. Not a specific processor, but a set of compatible processors. E.g. a file compiled for compatibility with x86 and no extensions will work on every Intel or AMD x86 or x64 processor, assuming the OS is compatible. First and foremost the machine code from the compilation step. In addition to that, a few other socalled "sections" will have e.g. resources (ever wondered, why an executable has a dedicated Icon on Windows, even if it is not running, but just shown in explorer), the description of binary compatibility and more. This is a side effect of 1.: Whenever the OS provides compatibility with the executable format, it can be launched. Modern Windows versions provide a range of compatibility: DOS, Win16, Win32, Win64, dotnet are the most important ones. The OS provides the executable with an environment, that is indispensable for execution. Those environments differ wildly between Linux and Windows. This means, you can't directly run executables from one on the other. There are projects underway to bridge this gap: The WINE project aims to allow launching of Windows executables on Linux (and other OSes), while the Cygwin project aims to make it possible to run Linux software on Windows. Cygwin doesn't aim for binary compatibility, but to allow for recompilation of unmodified source. 

First of all disable swap. You are trashing disk, in essence exchanging it against nothing. Next either configure realistic connection counts or upgrade RAM - wordpress ist notoriously memory-hungry. Finally: If you can replace Apache with nginx and either php-fm or hhvm, you can get way better. 

Windows is (without additional software) unable to display a typical Linux-formatted partition (extX, xfs) - this limitation does not apply the other way round. You can try installing an ext4 IFS driver into WIndows, but YMMV. 

When approaching this question you have to understand the different layers of networking involved here: 

The ususal way to do this is to use an SSH tunnel, typically running on port 22. If your VNC client doen't have an option for that, you can use (or better the scriptable companion ). 

The "From" header is set by the MUA (i.e. your mail program), meaning you can most likely put there whatever you please. If you use the standard GMail client, i.e. the web interface, you must live with the settings provided there. If on the other hand you use another client, such as e.g. Thunderbird or another web interface connecting via IMAP/SMTP you have wiggle room. Many mail programs are scriptable (or at least "hackable") - you would need to persuade it to use the original "To:" header as basis for the new "From:" header, which should be quite doable if you use one of the open-source web clients. Another way would be a dummy SMTP server, that just manipulates the headers and then passes the result to Google's SMTP server. 

A 32 bit OS can only address 4G different memory locations. Many items of hardware map into this address space and so reduce the number of locations, that can be used to address RAM. Any main RAM, that finds no addressable space can not be used. Graphic cards typically fall into this category: They map a lot of their onboard RAM into the address space to allow speedy transfer of data between the Computer and the card, so the observed value is not unexpected. By using a 64 bit OS, the adressable locations are in theory 4G times 4G, in reality much less, but still more than enough. In this case, the OS can use the mapped space from your hardware (e.g. graphics card) and the full RAM at the same time. There exist workarounds for this, e.g. the PAE system, but this has to be correctly used in every single driver on the system to avoid hard crashes (e.g. blue screens). Since many 3rd party drivers do not implement this properly, Microsoft has chosen for newer 32 bit versions of Windows not to use PAE, which makes it simply impossible to use more than 4G adresses (system RAM + hardware reserved adresses) at the same time. In e.g. Windows Server 2003 Data Center Edition 32 bit, this was enabled - the rationale presumably being, that enterprise-class hardware would come with well-written drivers. 

This is a deliberate design choice: It enforces a delay between two password inputs, in the process making a brute force attack on the password harder. 

You don't need to stop your processes, if you use a file system, that can grow online (such as ext{2,3,4} or ocfs2)