There is nothing 'magical' about Oracle and its recover ability. As long as you have your ASM metadata somewhere available, you can import it on a spare host and use that in a fresh installation to attach your SAN hosted files/LUNs and use that to continue your run on. Important is to know that all your data is in ASM and all your ASM disks are on the SAN. If you do happen to have some files containing application data are left on the Server that ran your databases before it crashed, it might cause an extra challenge. Knowing that it is technically possible is one thing, the ability to perform such a recovery is an other one. The only way to gain that ability is to train for it. Each OS has some things that make it more or less easy to do. This is for any failure scenario. 

The physical standby database must be physically the same as the primary database and this means the versions must be identical. A logical standby database can be any version, depending on how it is implemented. With 3rd party tools you can go from v10 to v12 and back. The restrictions here are on the data types that are to be replicated. If this is for an upgrade, you start with a physical standby database, convert that to a logical standby for the upgrade. 

No need to de-install Oracle rdbms software. Just install and configure ASM. If you have enough storage available you can copy your database to ASM using rman. 

Normally this error has to do with a lack of resources. What else is running on this server that consumes memory? There is a good chance that due to lack of memory your server is swapping and doing so, it takes too long to start processes. Monitor your memory usage. If your application does bulk updates, without limits, this could easily fill your entire memory. See Bulk Processing with BULK COLLECT and FORALL for a good explanation. If your data set is growing over time, surprises are waiting to happen. Use limits in the pl/sql code. Shutting down a database because there are performance problems is not exactly a solution for a problem, it is the denial of a real existing problem. Normally a database is online and available, a solid piece of foundation for an application. If your database/data has any value for your company, hire a dba to help you evaluate your systems. 

In Oracle Grid Control you can make a global view of your entire enterprise. This is an advantage above DB Control. It is slightly easier to authorize employees for certain targets in Grid Control. If your mail gateway changes, you have the advantage of only one location to change. When making clones, Grid Control has the advantage of not having repository parts in the target databases. On the other hand, DB Control is closer to the database and most of the times better support for new features. Oracle Grid Control Requires quite some resources to run and in many cases at least one dedicated dba to keep it running. You have no single point of failure for management. Oracle DB Control is very easy to setup. With a little smart thinking you can build a central page with links to all DB Consoles that you want, complete with links to the documentation. Grid Control easily gets mixed up when making clones, even without a local repository in the target. I think it is a personal choice. At the moment, after having wrestled with many GC installations, I think having an own repository for historic data and links to Oracle DB Consoles is not a bad idea. 

and try again. It does not have much to do with the filesystem blocksize but aligning your database storage blocks sizes with the storage blocksizes is performance wise a smart thing to do. 

gives some clues about the commandline options. study the errors. If there is a complaint about the dmp file, read the first few blocks. From those you can find who exported it, what type export it is and even some version info. It is a bit binary but just readable enough to get this info. tip: If your data has a real value for your company, hire a real dba to make a decent setup and have someone as a backup. It is easy to build a system that work happily for years and due to hardware issues suddenly become less happy. It's a pity if that costs your company the head. This is regardless for what brand of database you setup. 

It looks like a new schema in the existing database is the best option. Forget about having more instances on one server, this does not give the optimal performance and utilization. One of the biggest advantages of having schema's for different applications in one database is that Oracle Resource Control can be used to control the workload. In the ideal case, one server has one instance. When you create a new database for this application, Oracle Resource Control can not be used so the databases are fighting each other. 

You can do most of this by using a login.sql. login.sql is executed during - surprising - login and is loaded from your SQLPATH or current directory. For the examples you gave, your really chose the worst case. Problem is the sqlterminator. Whatever you put in there, the forward slash is maintained as a free sqlterminator. Next to that, sqlplus first scans for the sqlterminator and does this before scanning to the string terminator. A bug if you ask me. The forward slash can be used in a string as long as it is not alone on a seperate line. As soon as sqlplus finds the character specified as sqlterminator, it ignores everything else and stops reading. The forward slash can be handled, as long as it is not alone on a line. login.sql contains: 

Since no other sessions are accessing your table now, the lock shows as NOT BLOCKING. As soon as an other session tries to manage that table, it suddenly feels it is BLOCKED. The index is used so you can not manage it as long as other sessions are using it. Having indexes on havily loaded tables is for sure like putting a brake on the loader process. You could help yourself by checking out the docs. See Conventional and Direct Path Loads Maybe partitioning can help you. Than you can prepare a single table, load that, finish it's indexing and perform partition exchange. Just don't create global indexes on such a table. 

To me it looks like you did not start the listener but it is started. Your problem seems to be the tcp connection and not the ipc. So the listener is running, you can not reach it using tcp. Test this using If the telnet does not give a connection, a firewall is blocking you. Stop/edit the firewall. 

Which version of Oracle Database do you use? You essentially want a different plan based on the contents of the arguments. Oracle tried to make that possible in 9i, 10g and finally got this working in 11g. Use SQL Plan stability and Adaptive Cursor Sharing. Adaptive cursor sharing will make the database search for a better plan when it detects that a certain argument causes a bad performance, so the next time it will perform better. SQL Plan Stability makes sure the database ends up with a collection of good/accepted plans that give a satisfactory performance. 

In Oracle if you have the diagnostics pack available, simply go to the Performance tab in Grid Control or DBConsole and see which sessions are currently playing with your database. If it happened longer ago, take a dive into the awr reports and find the top SQL based on various metrics. It would help, if you mentioned a bit more about the actual database you are using, for example, brand, sometimes platform and versions. 

You can not drop the datafile. You can move it to a better location and keep it there. If you want to get rid if it, re-create the tablespace and copy the data to the new tablespace. Drop the old tablespace and rename the new tablespace. Don't forget to give quota to your schemas similar as they have on the old tablespace. 

No, the reading of your cats, dogs and humans tables wont block other processes that are inserting in them. 

Can you ignore the pre entered value for the PK, so effectively only using the sequence? The way it works now is almost as bad as querying the max(pk)+1 from the table. 

global indexes are made unusable when you drop or move a partition. This is because there are entries pointing to physical addresses in your partition, that are no longer valid. If you can, try to avoid global indexes. You can do this by making them local. 

The error message is very clear, you need to specify a procedure or a valid pl/sql block. If you really want to truncate the aud$ table from a piece of pl/sql, you will need to use dynamic SQL. 

Good news: it is free! Also, it is based on Java so it runs on a lot of platforms. See this nice video where it is introduced 

Reading the packages can help a lot. For the SQL access advisor take a look at SQL Access Advisor in Oracle Database