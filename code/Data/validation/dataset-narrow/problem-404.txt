I think you should be able to use the command to set up your connection in SSMS. Create a shortcut on your desktop (or wherever), and set this as the target location: 

If this is a workgroup, then may be the name of the computer SQL Server is installed on. Obviously, the account you're setting here will have to exist on the computer hosting SQL Server. This setup also works for domain users trying to connect to a SQL Server instance in another domain. 

(Assuming DB2 for Linux/Unix/Windows here, since you don't specify, but this will probably also work on the other platforms.) You don't have to do funky date math, there is a built-in function that will do it for you: 

While @user22610's answer will work great if your DB2 platform is Linux/Unix/Windows, it will not work on Mainframe DB2 (z/OS). If you're using that platform, this would be your command: 

All it does is fire a simple SQL query to a local Sql Server 2012 instance using async I/O API. Notice the Max Pool Size is set to 1000. This function is then called by the following code: 

I know how to filter the list of tables - using the filter icon. However, this icon is disabled when the Databases node is selected. Still, I am wondering whether it is possible. 

There is also an export feature, which allows to export some data and here is the problem - it actually exports the database itself: 

Note, that I do not need a super duper tool, which knows to do all the pairwise conversions. Until now I used $URL$ to convert SQLite to Sql Server CE, but besides having had to fix several bugs in their code, there is a deeper issue with their conversion - all the integral types become 64 bits long after the conversion, which is not good for me. Thanks. 

In short, compiled code goes through these steps to generate a usable : Precompile -> Creates a DBRM (with C[++], the precompiler outputs the precompiled SQL to an HFS file, which can be sent through the command-line bind program) -> the DBRM is optimized and a set of access paths (a ) is created -> The package is added to a , which is a group of packages that allow you to create a "search path" for your programs to look through. Since these programs are statically bound, if your table statistics change drastically, then the access path the optimizer chose at bind-time might not be the best path anymore, and re-binding will allow it to re-evaluate the SQL and perhaps choose a better path. 

When you run a program through a DB2 pre-compiler, runs through your program, and if it finds any embedded SQL (in COBOL, these are statement blocks that go from to ), it carefully rips the SQL out, and replaces it with a call to the COBOL-DB2 interface. After this, there are two outputs of the , the COBOL source that has had all the embedded SQL removed ( from now on), and a that contains all the SQL that was removed (). Precompile does do some basic syntax checking, but be aware that the checks are only based on your table declarations within the program. It doesn't attach to DB2 to verify these! These two files are completely separate, and when you run the COBOL program, it has to find an and a that were generated at the same time. At this point, is compiled and linked with the standard COBOL compiler into a and placed in a load library to be used later. However, there is still a lot of work to be done with , the DBRM. This is where comes in. is sort of like a compiler for the embedded SQL code, and the output of the "compile" is a . In order to BIND the SQL into an executable "package", the BIND process attaches to DB2 and does a few things: 

At first I am starting 100 async IOs, each taking 16 seconds. And it works great, so I increase the count to 200, 300, ..., 700 - boom! A failure, which I have never encountered before. Now, I know the formal cause - the default is exactly 15 seconds. Indeed, increasing the connection timeout (in the connection string) or firing 700 IOs for 15 seconds, instead of 16 - works. But something bad happens - the overall time jumps by a factor of two. It is as if the database server refuses to accept that many concurrent IOs (the exact figure is between 600 and 700), but the client side does not know about it and attempts to open all of them. Anyway, through error and trial (using binary search) I have found that limit to be 648. My question is - where does this number come from? How to change it? The max user connections is 32768, but that is not the case in reality. Is this because this is a Development license of an otherwise Enterprise edition of Sql Server 2012? 

The function will ensure that you'll always have at least 14 characters (it implicitly casts the first argument to , and then pads on the left with the last argument to at least the number of characters specified in the second arg), which the function can then cast to a . This won't work if you're on the Mainframe DB2 (the only type of generated columns DB2 for z/OS supports is identity columns, row change timestamps, or rowids). I'm not sure about DB2 for iSeries. 

Edit (update for comment): If you are using the command line processor, you can pass in either a single bind package (), or a list of bind filenames (). If you pass in a list, the filename has to be prepended with a (e.g. ). Inside the .lst file, you can either put each package on an individual line, or you can separate them with : 

Stupid, right? We also came to think so. So, I had to write a tool, which given an old export file converts it to some database independent binary format. The problem is how to unit test it? At the very least, I need 4 databases with identical data, which brings me to my question: 

And I am calling this code with various combinations of and to explore the behavior of the async database IO. Please, find below example outputs: 

I have a bunch of *.frm, *.myd and *.myi files, which are a MySQL database store. I need to extract the data kept in these files, but I do not have a MySQL database engine at my disposal. Is there a tool or library, which can do this? Please, do not suggest installing the database engine (be it MySQL or MariaDB or other MySQL forks). My question is specific about extracting the data without the full blown database engine. In essence, I am looking for an embedded database engine, which can be distributed with my code and which demands no installation. I am not looking into doing complex queries, I just need to fetch all the data from one or two particular tables. Thanks. EDIT I am aware of $URL$ but I do not understand how to download it. What is the licensing for commercial usage? Should I download and install the full blown database to get hold on the libmysqld files (headers, lib + dll)? Even though I do not need the full database? In short, it creates more questions than answers. I am still looking for an advice. 

According to this Microsoft KB article, SQL Server 2005 (in any form, even with all the Service Packs installed) is not supported on Windows 8. 

There is a free version of DB2, the Express-C Edition, which includes most of the features of the "real" DB2 servers. It doesn't include some features, like label-based access controls or table partitioning; and it can only use up to 2GB of RAM and 2 processing cores. Have a look at this article to see what you may be missing out on from some of the "upper tier" editions of DB2. 

I see your Info Center link goes to LUW 9.7, and you mention that you've programmed in Java, but most of the experience I have with binding is with DB2 on the Mainframe with COBOL. So, you may need to adapt the explanation a bit (but generally, the concepts should be the same). I believe that binding is only relevant when you are compiling programs that include embedded SQL which is precompiled (statically bound SQL). If, for example, you're using JDBC, you aren't required to run a BIND. The JDBC driver will the statement dynamically.