Yes. Indeed, an oracle $A$ satisfies $\mathsf{NP}^A=\mathsf{NP}$ if and only if $A \in \mathsf{NP} \cap \mathsf{coNP}$. This class is called $\mathsf{Low(NP)}$ or sometimes $\mathsf{L_1 P}$ (see the link and the paper cited there for more of an explanation of the low hierarchy in general). Your intuition about "determinism" is actually somewhat correct (although it's not deterministic enough for us to conclude $\mathsf{P} = \mathsf{NP} \cap \mathsf{coNP}$). Try this as an exercise and you'll see this intuition vindicated: first show - carefully, spelling out the details - that if $A \in \mathsf{P}$, then $\mathsf{NP}^{A} = \mathsf{NP}$. Figure out exactly the part of your proof that doesn't work if you only assume $A \in \mathsf{NP}$, and then realize why that part does work when $A \in \mathsf{NP} \cap \mathsf{coNP}$. (Showing the converse is not too difficult either: $\mathsf{NP}^A = \mathsf{NP}$ implies $A \in \mathsf{NP} \cap \mathsf{coNP}$.) 

Here's one that almost doesn't relativize. $NEXP$ is not contained in $NP$ by the nondeterministic time hierarchy theorem. But one can construct, relatively easily, an oracle in which $NEXP$ is infinitely-often contained in $NP$. Formally, this means that there is an oracle relative to which there is a $NEXP$-complete problem $X$ such that $X$ agrees with (the relativized version of) $SAT$ infinitely often. 

Bounds on number of connected components, and more generally Betti numbers, of semi-algebraic varieties and hyperplane arrangements (and their complements) have been used for several lower bounds on algebraic computation and decision trees. For just a few big references, see: 

There is also cstheory-jobs.org, which in principle seems like a great clearinghouse for CS Theory jobs, but appears to be underutilized. Job posters, advertise here! 

Yes, but I'm not sure it means much. Yes in a trivial way: suppose $\varphi$ is an isomorphism between two $\mathsf{NP}$-complete languages $L_1, L_2$, and $L_1$ exhibits a phase transition with respect to some parameter $m(x)$. Then so does $L_2$, with respect to the parameter $m_2(y) := m(\varphi^{-1}(y))$. (This relies on the fact that "phase transition" talks about the fraction of satisfiable instances jumping from 0 to 1, as a fraction of an exponential number of instances of a given size, and p-isomorphisms preserve densities up to a polynomial.) I'm not sure this is such a meaningful statement, however, because the parameter $m_2$ above can be totally unnatural from the point of view of $L_2$. Most phase transitions of interest are with respect to some natural parameter (e.g. clause-to-variable ratio in k-SAT, density of a graph, etc.). But those natural parameters are defined in terms of some "internal" structure to the instances, not by just treating the problem instances as abstract strings in $\Sigma^*$ ($\Sigma$ your finite alphabet). But p-isomorphism does just treat inputs as abstract strings, and "knows nothing" about the internal structure that we like to impose on them. So, sure, you can say that all paddable languages have a phase transition since k-SAT does. But that doesn't tell you if, for example, solvability of quadratic Diophantine equations exhibits a phase transition in terms of any parameter that is natural from the point of view of Diophantine equations... 

In other words, for all instances, some witness is easy to find if there is one. And yet not all witnesses are easily verifiable. (Note that if R is in class 2, then the projection of R onto its first factor is simply in P. This is what I meant by saying that class 2 is a class of relational problems.) 

1) Depending on exactly what was meant, the conclusion in Kaveh's observation can be strengthened from $\mathsf{NP} \subseteq \mathsf{P/poly}$ to $\mathsf{P} = \mathsf{NP}$, essentially using Mahaney's Theorem. That is, if there is an algorithm which solves SAT and runs in time $\leq p(n)$ on all instances of length $n$ except for possibly $q(n)$ such instances, where $p$ and $q$ are both polynomials, then in fact $\mathsf{P} = \mathsf{NP}$. See, e.g. Meyer and Paterson and references therein, or Schoning's monograph "Complexity and Structure". So if this captures your notion of "hard instances" then there must be more than $poly(n)$ many hard instances for each $n$, assuming $\mathsf{P} \neq \mathsf{NP}$. FYI, such algorithms are sometimes referred to as "apt" or "APT" algorithms, for "almost polynomial time" (not to be confused with the more modern complexity class $\mathsf{almostP}$, which happens to equal $\mathsf{BPP}$). 2) The above can be strengthened even further, as follows. Assume $\mathsf{P} \neq \mathsf{NP}$. Then the above says that for any algorithm solving SAT and any polynomial $p$, there is a set of instances of super-polynomial size on which the algorithm takes more than $p(n)$ time. But the set can depend on the algorithm. The stronger result switches the quantifiers, and concludes: there is a super-polynomial size set H (for "hard") such that for any algorithm A solving SAT and any polynomial p, A takes more than $p(n)$ time on all but finitely many elements of H. Such an H is called a complexity core (the size assumption is not part of the definition of complexity core). The definition and existence of complexity cores was given by Lynch. The result I just quoted is proved by Orponen and Schoning. 

What is the funniest TCS-related published work you know? Please include only those that are intended to be funny. Works which are explicitly crafted to be intelligently humorous (rather than, say, a published collection of short jokes regarding complexity theory) are preferred. Works with humorous (actually humorous, not just cute) titles are also accepted. Please only one work per answer so the "best" ones can bubble to the top. 

One example I know of: secure circuit evaluation. Very powerful in theory, but too complicated to ever use in practice, because it would involve taking your code, unrolling it into a circuit, and then doing secure evaluation of each gate one at a time. 

In terms of complexity reasons (rather than complete problems): The Hartmanis-Immerman-Sewelson Theorem should also work in this context, namely: $\mathsf{EXP} \neq \oplus \mathsf{EXP}$ iff there is a polynomially sparse set in $\oplus \mathsf{P} \backslash \mathsf{P}$. Given how far apart we think $\mathsf{P}$ and $\oplus \mathsf{P}$ are - e.g. Toda showed that $\mathsf{PH} \subseteq \mathsf{BPP}^{\oplus \mathsf{P}}$ - it would be quite surprising if there were no sparse sets in their difference. More directly, if there were no sparse sets in their difference, it would say that for every $\mathsf{NP}$ verifier, if the number of strings of length $n$ with an odd number of witnesses is bounded by $n^{O(1)}$, then the problem [of telling whether there is an odd number of witnesses] must be in $\mathsf{P}$. This seems like quite a striking and unlikely fact. 

I think the answer is yes, even today there is no known natural problem that is a candidate for violating the Isomorphism Conjecture. The primary reason is that typically natural NP-complete problems are very easily seen to be paddable, which Berman and Hartmanis showed suffices to be isomorphic to SAT. For natural graph-related problems this typically involves adding extra vertices that are, e.g., disconnected from the graph, or connected in a very particular (but usually obvious) way. For the decision version of optimization problems, it typically involves adding new dummy variables with no constraints on them. And so on. 

Higman's Embedding Theorem: The finitely generated computably presented groups are precisely the finitely generated subgroups of finitely presented groups. Furthermore, every computably presented group (even ones countably generated) is a subgroup of a finitely presented group. Note that this statement could relativize to: "The $O$-computably presented groups (with some oracle $O$) are precisely the finitely generated subgroups of finitely presented groups," but it does not, as one can prove that for some uncomputable $O$ there are $O$-computably presented groups that are not computably presented. Indeed, I think any non-relativizing result of computability theory must have something of this flavor, as some part of the result or its proof must somehow "nail down" true computability from computability with an oracle $O$. In this case, it is the finiteness which nails down "actual computability." Note that, as Scott Aaronson asked for, this result is invariant to any of the usual models of computation (Turing machine, RAM, etc), but does not relativize (again, because all of the usual models of "actual" computation share some common "finiteness property"). On the other hand, one might argue that this "doesn't count" for this question, as it is more akin to a definition of computability using groups than it is a "result of computability theory." On the other other hand, it is a definition of computability that is robust to model yet that doesn't relativize. (In contrast to, say, Kleene's characterization of the computable functions which easily relativizes, by simply adding the characteristic function of your oracle to the generating set of functions. There seems to be no analogous operation for groups in the context of Higman Embedding.) 

The above is a book on "just" group theory, but of the books on pure group theory, it is probably the most relevant to Graph Isomorphism. A book that is more directly about algorithms for graph isomorphism, which puts group-theoretic algorithms at center stage, is: 

Prior to $\mathsf{IP} = \mathsf{PSPACE}$, it was thought possible that even $\mathsf{coNP}$ wasn't contained in $\mathsf{IP}$: in Fortnow-Sipser 1988 they conjectured this to be the case and gave an oracle relative to which it was true. 

I don't know the history, but "immune" always struck me as fairly appropriate terminology. ("Simple" never really did, but I never thought of the analogy with simple groups before - it's nice, even though it's not quite a perfect fit.) The English word immune has two general uses: (1) biological (immune to disease), and (2) more general ("not affected or influenced by something"), and both of these seem to fit with the computability definition. Immune sets are immune (in the non-technical sense) to the effects of (containing infinite) ce sets, in some sense. It also ties well with "productive", as immune sets are somewhat the opposite of productive sets, and in that context, I think of the use of productive as in "productive cough." 

In some sense, nothing: Berman & Hartmanis showed that if two languages have one-to-one, polynomial-time invertible, length-increasing reductions between them in both directions, then the languages are p-isomorphic. (Here a one-to-one function $f$ is poly-time invertible if there is a poly-time function $g$ such that $g(f(x)) = x$ for all $x$, and $g(y)=\bot$ if $y$ is not in the image of $f$.) Two languages being p-isomorphic basically just means that one is a re-encoding of the other, and thus preserves the "structure" of the other in some sense, that I think is similar to what you're talking about. All known natural $\mathsf{NP}$-complete problems are p-isomorphic. The idea of the proof is a ping-pong-type argument. Finally, as another pointer to the literature: Although the notion of $\mathsf{NP}$-complete is not sensitive to the size of the reduction (so long as it's bounded by a polynomial), the Exponential Time Hypothesis (ETH) and its variants are sensitive to super-linear blow-ups in size. So there may be some work on ETH that addresses parts of your question. 

Hilbert's Tenth Problem over the rationals is neither known to be decidable nor undecidable: given a set of polynomial equations with rational coefficients, does it have a rational solution? (The same problem with rationals replaced by integers was famously proved undecidable by Matiyasevich, building on M. Davis, H. Putnam, and J. Robinson. See this nice, brief survey by Bjorn Poonen.) 

I think this is not known. (I apologize - I think I was also one of the people that said I had remembered reading this somewhere.) For example, I believe that Sapir-Birget-Rips, Annals of Math 2002 were the first to show the existence of a group with $\mathsf{NP}$-complete word problem (which would be a trivial consequence of the result asked for in this question). Their Corollary 1.1 states: 

The computational problem associated to Noether's Normalization Lemma for explicit varieties ("explicit" in the sense of this paper [freely available full version]). Best known upper bound is $\mathsf{EXPSPACE}$ (note, SPACE, not TIME!) but it is conjectured to be in $\mathsf{P}$ (and indeed, its being in $\mathsf{P}$ is essentially equivalent to derandomizing PIT).