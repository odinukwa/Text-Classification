We have just implemented table partition on a very large table in SQL Server 2014 , we used have filtered stats on the same table before partition not after the table partition we enabled Incremental Statistics but we are thinking to create filtered stats which would allow for a much more granular level of statistics.... At this point, i'm not sure if a partitioned table can have both Filtered stats and Incremental Stats and if we implement would it confuse the optimizer ? Also , can anyone help me on how to implement filtered stats on a partitioned table ? Thanks in advance... 

We have migrated SQL standard edition from 2008R2 to SQL 2014. After the migration we are seeing huge amount of blocking and overall SQL instance is very slow. Major wait stats we are seeing is Resource_Semaphore_Query_Compile and some of the queries are requesting more amount of memory and waiting on compile time. Also, this new server is a beast, Memory : 1TB and CPU : 2 physical cores with 30 logic processors each (60 total ), since this is a standard edition, max memory is set to 128GB and i believe there is some issues with Maxdop setting and how SQL 2014 is utilizing the processors. Maxdop is set to 4 and we changed it to 2, still no luck. Regarding the resource semaphore wait types , i did updated stats on all databases with full scan and we cannot tune the queries as they are encrypted and vendor code which used to perform fine in SQL 2008 R2. I'm thinking this might be my issues, configuring the soft NUManode. Please let me know if it has any impact. $URL$ Any one faced this issue ? Please help me we are in production now and our overall system is very slow. 

how to avoid this log file growing? 1) Convert the Recovery Model to Simple Recovery 2) Start Taking Transaction Log Backup 

Make sure there is no error message and listener is up and running by execute the following command: 

based on the log file there is a transaction run that consume all of the memory, if you want to stop the crash you need either: 

To drop it you need to make sure the user has owner privileges on the database, you can use the command 

in-order to change default value you need to edit you file and look for if the parameter exist then you need to edit the current value to 600 and restart the service, otherwise you need to add the parameter and restart the service. Demo: my.ini content (I am using windows here, but MySQL) configuration is the same 

I have oracle 11G R2 under 6.3 test is the name of the database, the database contain 12 custom schema, sch1,sch2,...,sch12. is it possible to create database backup using method that contain all of the schema with no data except the first three one, the data is needed. 

To show the log use the following command: select * from mysql.general_log; if you want the slow query: 

Make sure the MySQL server owner is MySQL:MySQL using and the permission level is 755 for everything except 644. then execute the following commands after changing the information inside to the correct one. 

This will show you the needed info, and you can check Activity Monitor too some useful links: $URL$ $URL$ 

ODBC user is the default username under windows even if you didn't create that user at setup time then it will show you this error message. 

Generated the both plans from plan cache (plan from SSMS and Application) Cleared the plan for application procedure Ran the procedure from application again but still it is slow and generating the plan with ARITHABORT as False. Cleared both plans ( SSMS and Application ) and ran the procedure from application, still slow. Altered the procedure , recompiled and created/dropped the procedure. Stats were up to date. 

stored procedure is running slow in application but fast in SSMS... i have enabled SET ARITHABORT ON in stored procedure and it ran very fast from application in QA but still slowness in production ...we are running the stored proc from application in Read only database ( always on AG group )... Things we have done so far: 

we have an SSIS package that starts around mid night and does bunch of things. one of the insert statement in that package is causing slowness sometimes, runs for 90 minutes and sometimes runs in 42 or 20 minutes and during weekends it runs in 7 minutes. I have checked for any resource contention, there is nothing going on except the database maintenance that runs in parallel and with the maintenance running in parallel the insert statement sometimes runs fast. Environment : virtual Windows 2012 R2 SQL 2014 Enterprise Memory : 120Gb, max sql memory : 112GB vCPU's : 10 Initially i thought the issue might be with the memory because of the PageIOLATCH_SH and PLE going down at the same time and after increasing the memory the performance is still bad. I'm thinking the amount the records they insert might be different for each days but app team specified that they are almost same ? Do you think is there any issue with the Vmware environment, i'm thinking may be something with VM NIC card limitation ? our infratructre team already checked the disk performance and it looks good. Execution plan for the insert statement looks totally good. Can anyone shed some light on this ? 

Management Node: is the Node that process reading the cluster configuration file and distributes this information to all nodes in the cluster that request it. It also maintains a log of cluster activities. Management clients can connect to the management server and check the cluster's status. Data Node: This type of node stores cluster data. There are as many data nodes as there are replicas, times the number of fragments. For example, with two replicas, each having two fragments, you need four data nodes. One replica is sufficient for data storage, but provides no redundancy; therefore, it is recommended to have 2 (or more) replicas to provide redundancy, and thus high availability. Node: This is a node that accesses the cluster data. In the case of MySQL Cluster, an node is a traditional MySQL server that uses the storage engine. An node is a process started with the and options, which are explained elsewhere in this chapter, possibly with additional MySQL server options as well. Note: Node is the specialized type of API node. Please refer to MySQL webpage for more info: $URL$ 

OEM is a web-based application so the language is determined by the default on web browser like Internet Explorer, make sure to change it to English (note you may see Internet Explorer menu in English but the default language (localization is not)) it can be change from internet option. give it a try 

You will get this error when you enter wrong password. To reset your root password: 1) if you have another Admin user login by using it then execute the following command: 

Lets define the in oracle: it is a small binary file that records the physical structure of the database and its include: 1) The database name. 2) Names and locations of associated datafiles and redo log files. 3) The timestamp of the database creation 4) The current log sequence number 5) Checkpoint information 

You can use clause. It's called in documentation and it works for any (lets say) calculated field. Here is a sample for your case; 

I get current log file by using SQL without getting in server via ssh. So I use a query like the one below; 

Case insensitive comparison is always costly than case sensitive one. The documentation also cites that in Limitations section. As I understood, the main problem is that you have a performance issue and you cannot locate the culprit(s). I suggest you to use pgBadger or pg_stat_statements to detect slow queries. 

You can use either generate_series function or VALUES Lists with a left join. The sample queries are below; 

Referenced sections; Executing a Command With No Result Available Diagnostics Items (special variable named FOUND) 

You can remove part if you don't need jsonb type for your output. For additional json functions you can check documentation sections; 

Moreover, the query below provides you foreign key details. It provides relation types by using primary key definition. Note that it does not check unique constrains. 

You can use PERFORM 1 test with a control statement using FOUND special variable. Your query will get like this; 

The main idea of casting to uuid is favor uuid data type, which is 16 byte, to varchar(36) which is obviously more. Answer of this question Although previous approach is faster you probably want only to use index which matches the ORM query. Just create an index like this; 

Unfortunately the answer is no. is not server parameter. It's JDBC's own client parameter. Check the function here; 

If applicable, you can create a function and use control statement. Once we had an issue like "log any error in particular log table while executing a statement and continue without error" so we used something like this; 

the error messages you got because you don't have privileges to log in to the server so you need to grant the user the necessary access. some tips to solve this issue: 1) Mount the remote disk locally (map network drive). 2) Use rman CATALOG command to make the backups available. 3) user has enough privileges on ORACLE level 

If you get the result 0 thats mean the temp doesn't have enough free space, otherwise you need to check segment (mostly happened for RAC) by executing the following command: 

you need to make sure the correct is edited, you can check it from windows services by opening MySQL properties and make sure it is related to MySQL 5.6. now you need to stop the service then open the file in the service description and edit the port. finally start the service and try to log in from using: 1) 2) 

since you are already logged in into MySQL then you need to inter the following command to read and execute text file 

I have solution to some of your problems Q) Why does this happen? A) because invalid or missing values in data-change statements such as INSERT or UPDATE, ...etc Note disabling one of the main causes of this violation. Q) Preventing or workaround There is some restriction you can add to your database, I'm not sure if this practical (DBA should be able to decide) 

The error above happened when you try to do something that take time higher than the original timeout. you can try option to increase the timeout for the command. example: 

To understand the problem and try to fix it you need to check related logs: listener.log, alert log, trace file, etc possible causes and solutions: