I am using merge replication in SQL 2012. Some of my merge articles use column level tracking. I am trying to understand how to use the 'lineage', and 'colv1' fields in the MSmerge_contents table to work out which columns have changed in a particular row in my database. 

I'm just wondering what happens if you do some kind of bulk insert for instance which inserted 5000 new records into this table. What would happen to the identity column then? 

The answer at this point appears to be quite simple. I was using a different domain account to run the subscription agent. I had to log into my machine with that account and install the security certificate. 

I am running merge replication with SQL 2012. When I first create my publication the MSMerge_contents table is populated with a large number of records with the colv1 being set to 0xFF. When I run the stored procedure like this, 

This works 100%. I have omitted the rest of it because it is just server, user, password settings etc. If I change the query to this, 

The user inserts a record 'Shape' at a client The 'Shape' has a default constraint to set the NumberOfSides field to 4 The client user edits the value of NumberOfSides and sets it to 5 They sync with the server 

There something that I have for a long time, to transfer logins with password: You should first create the procedure, and then run it and just copy and paste ( or for sure you can run sp_BlitzErik's script, so it will do it automatically, just don't forget to create a linked server ): 

I've been changing values but with no success. The same config I have in this server, I have in other servers. 

Funny part is, when the query uses a different index, it does not use parallelism. Whe it uses this index ( IX_tbReps_cod_perito_primeiro_cod_status ), it uses parallelism. For more information, the query: 

inserts into an table that already exists. put data in a table that you will create in the same action ( whitout the need to create column by column. You should use something like this: 

Then, I want to use the inside a loop, to list all indexes of this table ( TB_INF_CLI ) of all these databases, with this query: 

A simple trace with . But, how can I know the query that has the problem listed here? I don't think is appropriated to this. EDIT 1: Well, I'm using: STORED PROCEDURES: 

Edit 1: With James Anderson's query, I got this too ( filtering with ) Again, I don't have backups from 2015-09-15, only 2015-09-14. 

What structure is ideal to use to relationally link street lights together. For instance I have street light 1, 2, 3, 4, 5, 6, and I want to say that street light 6 and 2 are related. They might be on the same street for instance. What are the ways I can do this? 

So it is definitely the case statement. And the issue does not resolve if I use ELSE 0 in the case statement. On my actual query I have a where clause (the where clause on the very first query above) which selects only 3 records as a proof of concept, and they all have 8022 as the value. The ELSE 0 never gets used if I add it and I still get the same error. 

So the thing to be aware of, because I was using parameterised filters the snapshot folder above doesn't contain any data, only schema. Also I was not filtering correct using SUSER_SNAME() so the filtering was not using the snapshot at all causing me performance issues. Once that was sorted I could see in the snapshot folder there subfolders with a snapshot for each user of the system. This data is the data filtered for that particular user. 

I am running SQL2012 merge replication on a netbook using SQL Express as a subscriber. The netbook has 1GB of RAM. The replication process works quite well, but it is when it comes to applying the prc files from the snapshot where the problem begins. As I understand the prc files are the stored procedures for each table. At the start the prc files are applied fast, but further along it seems to slow down more for each one. At the start it seems to take less than 1 second for each, but now it is up to about 10 - 20 seconds for each. If I look back when I subscribed to the same publication on a PC (not a netbook) the prc files each applied in less than a second, and there was no slowdown over time. The SQL server is using about 453 Mb of memory. It has increased since applying the prc files. 

I've been reading about Snapshots, and it says you can send catalogs lets say, in a monthly routine. I liked the Idea and i will start to study about this, but can I use snapshot for large databases? Every week I need to backup development database (2tb) and migrate it to test environment. It will be a good idea to make this via snapshot? Performance will not be testes, since it's development, we can wait a lot. 

How can I make the second column ('0.995014168') To have more decimals? I'm trying to convert to , even using with no success. 

is High Availability something to describe Log Shipping and Always On ( replica )? is Always on something to describe Log Shipping and High Availability? I'm studying to get my certification 40-762 but I need to study a lot about these topics ( since i'm bad in this part on online tests ). But even looking at Microsoft's website I'm confused about these topics. I know something about log shipping and replica, But I would like a point to study, and looking for "always on" and "high availability" not knowing what they are is a bit hard. So, how can I describe them? 

Today I got an error ( DTSER_FAILURE ) but I could fix it by editing the maintenance plan ( this error is due to the maintenance plan searching for a database that was deleted, and I was using "selected databases" in the setup ). But over the internet, I read some posts saying that I should . What effects has this option? I read on the Microsoft page that this option has no effect and it is deprecated. 

I am using SQL server, and I have been looking closely at the concept of key lookups, $URL$ So if you have a key lookup you can create an index with the 'include' columns to cover the non index columns you have in the select statement. For instance, 

Why is it suggested to regenerate the snapshots every 14 days by default? With web sync you are an anonymous subscriber, so how can replication know when to clean up metadata for a user who never syncs 

I am running merge replication with SQL 2012. There seems to be a nasty consequence of the delete triggers added for replication in SQL 2012. Inside the delete triggers are this, 

I am using merge replication in SQL 2012. Why can't you mark default constraints as NOT FOR REPLICATION? You can disable all default constraints for a merge article, but it is all or nothing so it doesn't seem to offer enough control. How about this scenario, 

I am using merge replication in SQL 2012. I am trying out the TableDiff utility to show non convergence. I see a problem with this approach though. This is because I am using parameterised filters to filter the subscriptions. In this instance the TableDiff utility tells me that there are missing rows in the subscription and generates the SQL to insert them. If I swap the source and destination around it generates a whole lot of delete statements to remove the records at the publication. This is not a correct result. It should just check the rows that exist at the subscriber, or understand the filters and know which rows should be at the subscriber. Can I use this utility in this instance? If not is there an alternative? I find it surprising that none of the documentation about this utility mentions this problem. 

I could fix this by running the query pointing to a driver inside the server I'm running. How can I give permissions to a SQL Login/User to a network folder? Should I map the driver first and then run it? Like the tip they have in this site: $URL$ I'm trying it right now. Question: Is my BCP running under SQL Service Account ? or it's using the -U -P account? 

But as you can see, files are named after a number ( ). This number is the ID of another table, so, if the PDF file starts with , I need to insert it into the ID . I just would like a start point. I'm trying to create a cursor, looping throug all files, and using left() or substring () function to get the number, inserting it into a variable, and comparing it , like . I need something like a string like this : 

I'm having problem ( I have problems with cursor since ever and I really need to understand how the hell it works ). I would like to run this command in all databases: 

I'm using 1433 because a long story. but its working. We can use the default port 1433 AND IPAII ( for PHP developers ) with 1433 too. But in production, when I changed, the server lost connection. There's no way to explain this in a easy way. Why I had no problems on one servers, but on another, it lost connection? If the question is to abroad, I can get it better. 

I am using Merge Replication with SQL 2012. I look in the snapshot directory, but the largest file in there is a prc file which is 646 KB. I know for sure that the biggest of my replicated tables is 25 MB in the database after replicating, so I am not sure I understand why there aren't larger files in the snapshot directory? Also is there a place I can look for the snapshot files as they are downloaded to the subscriber? For instance the merge agent outputs messages such as, 

I am running log shipping with SQL server 2008 R2. I have a situation where the secondary database drive ran out of space and was not applying log shipping transaction logs. The way I want to fix this is delete the databases at the secondary and configure log shipping from scratch. The problem I have now is that my secondary databases are in the restoring state, and I cannot delete them. How can I proceed? For instance if I try to take them offline I get the error, 

I am running merge replication in SQL2012 using web sync. Has anybody done any experiments to compare the performance of web sync to connecting to replication using a straight TCP/IP connection? Just wondering if it might work to open up a port for a TCP/IP connection over the web and not to use web sync. If it could work is it faster? 

This is because the owner of the database ( the login ) was deleted. You should remap the owner of the database, to a login that exists. 

But today, it shows me "09/15/2015" for all databases, but we had a problem in the cluster, so the backup job didn't run. Why is this query listing "09/15/2015' if there are no backups for today? 

yes you can. You can create a job with the query or procedure you want to run. On Schedule you can set it to run Whenever the CPU becomes idle. 

We're trying to achieve better reports using native tools from SQL Server 2014. I'm a DBA, and I don't know so much about c#, c++ and etc. I know also, that we have Analysis services, SQL Server Data tools, but, long story short, programmers here where I work don't care about anything. They don't want to learn. Is there a way to help my company, being a DBA ? I love to learn but I have some doubts about what service I can use to achieve reports with graphics, and those reports that bosses love. If this is a bad question I can delete it with no problem. My past job, we had an awesome application that uses views and procedures to ( I helped them with views and procedures and query tunning, but not with Visual Basic code ), in real time, update graphics and etc on a web page ( it was awesome ) but we can make it here, because as i said, they don't know and don't have the motivation to learn.