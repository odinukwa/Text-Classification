If you have full access to the server box, the best thing you can do is to check that traffic from the client arrives from the correct interface. Something like: 

in the below examples is the IPv6 address from the 2002: prefix reserved for legacy addresses, which can be found with "ipv6calc --ipv4_to_6to4addr ". radvd will do router advertisements on LAN side, telling all IPv6-capable hosts how to configure their IPv6 addresses. A typical radvd.conf may look like this: 

iptables in combination with tc should be able to do this if OP is on Linux. Iptables has a module called connbytes that can match on the number of bytes that has passed the stream so far. Use this to "mark" packets in streams that have sent too many bytes. For example, you may have one rule that marks all packets in streams between 1 MByte and 10 MBytes with mark "1" and another one that marks all packets in streams longer than 10MBytes with mark "2". Then you set up traffic shaping classes for default (== below 1 Mbyte), for mark "1" and mark "2". The advantage of this solution is that you need not penalize users unless they collectively consume too much bandwidth. The disadvantage is that these are somewhat complex tools that take som reading to wrap your head around. iptables and tc is included in most distros. You may also want to look at tcng which makes it radically simpler to formulate tc rule sets. 

Many applications can log to syslog, which means you can get the logs to a log server. apache, mysql, tomcat (log4j) can, at least. Then you need a competent syslog server to do the aggregation. I use syslog-ng, but that's because it was the only serious alternative 7 years ago. Debian Lenny switched to rsyslog, which probably has a saner codebase and even more features. In my experience, a good regex engine is the most important part of an aggregating syslog server. There is so much gorp you want to filter out so you can see the relevant parts. You can also point logwatch at the aggregated logs if you want to get started quickly. EDIT: I should be explicit. Our strategy is to log everything from a specific host to one or more files in a folder for that host and simultaneously log to heavily filtered files that logs certain activities across all hosts. For example, there may be a file with failed logins across all hosts. 

You have to use cname for you new domain to the cloudapp domain . You can use an alias too . And there is a faq step by step to do that with azure gui or powershell tools . $URL$ 

Some driver are just not ready for terminal services (remote desktop services now) . There is compatibility list on printer driver support site. Sometime another driver for another printer model work in remote desktop but you can have weird problems like bad character or black images etc. No real solution other then get a 100% remote desktop ready printer and driver :) EDIT : or try this : epson universal printer driver 

Don't understand exactly what you need to know (and where is the question)but if i understand a few: use dhcp relay. How to do that : $URL$ 

Azure disk management is not smooth and easy. To resize your sys disk no other solution than delete the vm with retain disk . Resize with the tool after deleting the disk from "vm" but keep data in the blob. After resize you have to add a vm with an existing disk . Remember to save vm name , disk name , acl in firewall etc . Last resize of an old azure vm i used this blog post : $URL$ There is a new solution with cloud explorer but i never tested (and you have to delete the vm like the first one methods). And i don't explain how to expand ubuntu lvm because there is already many blog about that : ( $URL$ 

Probably a trust problem . Doucle check ntp :) Weird problems sometime are just a stupid clock problems . Set same ntp on the two domain . Double check the trust , and dns name . If you ping the domain name and all ok check for eventslogs on source and target server . Try with Test-computersecurechannel in pshell . 

But to no effect. How do I instruct libsasl to use saslauthd authentication? (I can of course create /var/spool/postfix/etc/sasldb2, but this will still not result in connections to saslauthd.) 

during the failing operation to see what libs it is looking for. I'm shooting from the hip, OP but having waited 15 minutes for an answer from someone who actually know what (s)he is talking about, this is better than nothing (I hope :). For future systems, I recommend the MySQL community builds for CentOS 5 boxen. Install server, client, shared and devel from the beginning, and you should be able to dodge this sort of issue. 

From your description it sounds like the kernel actually believes something explicitly unmounted filesystem from /var. I have not known Linux to "forget" that it had a mount in recent years. My suspicion falls on some cronjob/script unmounting the partition or dbus or someone confusing it for a USB device that has been removed. If this was hardware failure, the kernel will insist that the partition is mounted and generate error messages on access. 

Your immediate problem is that you declare a default gateway on both entries. I suppose that this will result in whichever comes up last to "win" and be default gateway. However, if you remove the one on eth1, you will have the problem that the box will reply on eth0, even if the packet arrived on eth1. In order to tell the box to reply on a particular interface, you need to do what is commonly referred to as source routing. I have the following set of commands on a box: 

With the caveat that I don't know much about kvm, I would guess that the partition is a full disk image. If that is the case, you should get a meaningful partition table if you do: 

In the website world some people use ww2 to load balance and/or do A/B testing with "real user load" on a second cluster . Sometime its just a trick used to load with real user and do some benchmark on new stuff :) 

Don't know a all in one solution but look for this : 1- use a software to read iis log and with some "code" email a result when someting match your monitored file . Look for elk stack with email output in logstash . Don't forget to enable logging first . 2- use a web app you code to generate a mail when someone do a get on this file. 

There is solution for your need : 1- use a hids software agent on client to log event to a server . Need install on client , config server , don't work outside without vpn etc . (Ossec or other siem/hids tools do the job) 2- use windows audit capability to centralize all events. This work without tools on client side . you just have to run script/gpo with configuration to send security log to a centralization server . Look this one : $URL$ After that you need some script to read audit log in centralized server and write to database . There is tools like Nxlog ,Snare that do the job (read event log and format for a syslog ). And logstash can read syslog and write in a database (nosql database , or sql database) . There is commercial software doing that too but its not the place to talk about that (google for commercial product). 

You can do that with url rewrite and binding on you iis site . check for iis rewrite modules rules here : $URL$ 

Solution WARNING: Below solution to issue 1 is DANGEROUS. If RPM upgrade breaks you are likely to end up with a broken system. Solution to issue 2 may result in installation of broken packages! Issue 1 can be circumvented by backporting RPM 4.6 from source RPM. See $URL$ Build dependencies for soure RPM: 

If you have any control over the running applications, why not have them log to syslog and have syslog output to the serial terminal? Having said that, asking screen to start all the applications in separate sessions using e.g. the at or exec commands is an interesting idea. However, there are two concerns: 

First, I must ask: "shutdowns"? Do you mean that the machine reboots or does it actually halt? If it halts, it is either misconfigured (perhaps in BIOS) or something is actively shutting down the machine (i.e. init 0). If not, your primary candidate would be /var/log/syslog and /var/log/kern.log as your problem sounds like a kernel panic or a software-triggered hardware-fault. Of course, if the server runs some service (e.g. apache) may give you a clue too. Often, in situations like this, there are log entries generated, but because the machine is having difficulties, it won't manage to write the entries to disk. If the box is colocated, chances are that it is connected to a serial console by the colo partner. That is where I would look if I did not find anything suspicious in the above logs. If the machine is not connected to a serial console and there is nothing in the log, you may want to consider sending syslog to a different box via network. Perhaps the network interface survives a bit longer, and the log messages can be read on the syslog server. Have a look at rsyslog or syslog-ng. UPDATE: I agree with @Johann below. Most likely cause of halt is processor temperature watchdog. Try checking/plotting temperature in box via lmsensors or smartctl (usually the easiest). I find that collectd is unparalleled at keeping track of large number of variables over time. It can do both IPMI and lm-sensors and hddtemp. Also, some BIOS:es log temperature halt events. 

If you think about ssh when you talk about "logged" you can use syslog and rsyslog . For rsyslog check that : $URL$ With some setup you can send log by mail or with log system stack (elk stack , graylog2 , splunk , etc). 

If i check perf counter for mssql there is no perf counter for vcpu/core . To check perf counter available on your mssql server do that: select * from sys.dm_os_performance_counters But if you do the perfcounter from windows view there is counter for every vcpu/core. 

Termina server (rdp server now) work like that : -user connected on server view printer localy installed on the server or connected by script/group policy. -if remote printer is enabled on tse and client tse , user on the server can view localy installed printer on the server if the driver is installed on the server (for 2003 server). And only the user connecting their printer . To resolve your share problem with connected printer via remote session its better to use printer as local one (with ip with or without vpn) because rdp 2003 is not very good at handling printer job. And this prevent share right delete. And there is near 0 compression on print job with old rdp protocole. 2008 and later are better at handling printer job inside rdp session. 

1- If you want comment to your perf we need to see your logstash filter config . Logstash performance is a mix of filter/output/worker setup . More filter = less event/seconds . A good idea is to scale wide if you have logstash perf problems . More worker more instance could increase event/seconds perf . People work with sender to rabbimq queu and scale logstash node behind . 2- see 1 3- there is IO limits and sometine its better to have more node. Elasticsearch is designed to work with shard/node etc . 4- logstash monitoring is only process monitoring for the moment . There is some clue about doing that with java debugger but you have to find information in logstash user group . For elasticsearch there is marvel to monitor you elasticsearch cluster . 

Your mysql server seems to have only something like 128MB pool. If the LAMP system makes use of a fair-sized database, this seems to be on the low side. That would generate a lot of I/O towards disks. Also, if there are CPU spikes on mysql, turn on slow-query logging for a bit and see what shows up. A new index or two might be in order. For a top replacement that can read most of the per-process conuters in a modern kernel, I recommend atop. Among other things, it can show disk access by process. Note that atop has a running daemon as part of its setup, so you may want to uninstall it after you are done. Be careful what CPU usage numbers you trust. They are generated using somewhat different methods. In my experience, to show overall CPU usage, vmstat gives the "best" (== closest to perceived load) numbers. There are apache processes doing serious work. Perhaps some PHP code optimization is in order? 

Rinse and repeat. Since core won't do any system setup, you may need to do any number of things before next step. I need to provide /mnt/etc/resolv.conf. We now have an environment that can be chrooted into for issue 3: 

I failed to find an answer to this problem and in the end accepted random the semi-random IP assignment that above config resulted in. 

On an "ordinary" CentOS 5 machine, these work splendidly. On my virtual machine which has been built using "yum groupinstall core" and some minor adjustments, I get this when user myself logs in: 

Well, four machines make a cluster, no? See $URL$ in the documentation for an indication on how to create an "OR" check; one that notifies only when several conditions occur.