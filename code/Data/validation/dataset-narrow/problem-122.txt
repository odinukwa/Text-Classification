PfR is indeed one option. Option which I don't personally have experience in, but I know people using them are BGP optimizers, which are vendor independent as they just look at BGP, measure network, and inject routes to change routing. Couple options 

I'd like to add ELAM in the mix. ELAM is supported on PFC3 (6500, 7600). You need to have 'service internal' enabled, but it's quite safe feature to run, I've ran it good deal in production networks and not yet once experienced negative impact. Essentially what ELAM does is it shows you what was send for lookup processing to PFC via DBUS (Data BUS) and what did the PFC give as lookup result in RBUS (Result BUS). 

'sikrit' user is to be used when tacacs is not working (it cannot be used if TACACS answers) there is no need for 'line' password under VTY, as it's never consulted. There is no need for 'enable' password, as it is never consulted. If you want non-enabled backup user just create another with 'privilege 1'. However I did add support for 'enable' if you want to use it for some reason after all. If you are using OOB, and OOB access is already secured/authenticated, you might want to allow OOB user always to use local authentication, just in case TACACS is broken but IOS mistakenly thinks it is not, then you'd add something like this: 

For the triggers there is online help, IP_SA == IP Source Address, IP_DA == IP Destination Address, lot of others are available. IF what you want to check isn't available you can do data + mask match for arbitrary data on the first 64B. The arbitrary trigger is bit awkward but can be lifesafer, you'll use it like this: 

show plat cap elam asic superman slot DFC/PFC_SLOT_YOU_WANT_TO_LOOK show plat cap elam trigger dbus ipv4 if ip_sa=192.0.2.1 show plat cap elam start show plat cap elam data 

I never worked with bridges because they were no longer used when I first got internet at home, and I have some troubles understanding what exactly was the role of the switches. From my search I concluded that a bridge can be viewed as a simple switch with two ports and it does MAC switching between two SETS of MAC addresses instead of two MAC addresses. Is this way to view a bridge correct? 

I know that there are devices that now support agentless SNMP configuration. However I believe that the SNMP agent application has to run somewhere. It has to be some code running somewhere stored on some flash memory or a similar device. 

I am curious to know if in an Ethernet network the techniques used in LTE or other High Speed wireless Network that allow different devices to send data at the same time can still be used. For example would it be possible to use different frequencies for different devices on the same network and still have the devices "understand" each other? I know that when hubs were used and many computers would have access to the same wire there was a system called CSMA/CD that would prevent two devices from talking in the same time. What if the devices would communicate at the same time but at different frequencies? 

What was the protocol usually used on top of X.25 and ATM or even Frame Relay Networks when those were commonly used? Was it also TCP/IP protocol stack or some other protocol stack? From what I know since the beginning of the Internet (ARPANET, NSFNET) TCP/IP protocol stack was widely used at least on the access layer of the networks (host machines). However I know that X.25 and ATM networks were also widely used but I am not sure at what level did those networks work. Were they also carrying TCP/IP traffic? 

Router1 and Router2 are running VRRP, HSRP, GLBP or CARP to produce virtual default-GW IP address to the LAN. This protocol will converse over the Switch core to agree which of the routers is owning the default-GW IP address at any given time. PC2 is redundant linux server, which is using 'bonding' to redundantly connect to the Switches, it should be configured so that if the the virtual default-gw IP address stops responding to ARP WHO HAS, it'll switch to backup connection. IP address itself is not on the physical interfaces, but on the virtual bonding interface. Equivalent solution is available to other OS, but often not included in base OS package. PC1 is non-redundant server. Switches are not running anything special, no spanning tree (as there is no L2 loop) and no LACP. They can be from different vendors and can be taken down for maintenance separately. Routers are not running any switching, IP addresses are configured directly in the L3 interfaces facing the switches. If you choose VRRP as your first-hop-redundancy-protocols, routers can be from different vendor. Each router can be taken down for maintenance separately, by gracefully switching VRRP priority before work on the primary. 

Signal travels roughly same speed in copper and fibre, copper being slightly faster. Fibre is determined by refractive index, typically speed being about 0.65c, i.e 200km per 1ms (single direction, not RTT). Maximum theoretical throughput is hard to determine, maybedivide wavelengths to Planck length difference and light each up, so absurd amount. But in practice about 128 waves by 100G each in optical fibre. For copper we're now doing 40G commercially, 100G will happen and is 400G the table. Obviously distances are very short. 

B will program FIB entry, so that label 300 points to interface towards D (because of IGP metric!), and MPLS label operation 'SWAP 200' B will program FIB entry, so that prefix 192.0.2.5/32 points to interface towards D, and MPLS label operation 'PUSH 200' 

So the question is in the title. If a switch does not support Virtual Local Area Network capabilities can it still be considered a managed switch? What other features should it have to be considered managed switch besides VLAN capabilities? 

I do not understand what was the purpose behind those two cable standards. Cross-over cable and Straight-through cable What was the initial purpose that they were build for and what was the necessity for them? 

Here's my scenario: Redistribute ospf routes into bgp Create a route-map that matches on route-type=local and modifies the nexthop (to 4.4.4.4 for example) Assign this route-map as outbound routemap (route policy out) for a bgp neighbor. Will the routes advertised by BGP (the ones redistributed from ospf) have the nexthop changed to 4.4.4.4? What happens if this route-map was applied with the redistribute command? 

For someone who does not speak English as a native language some acronyms can be really confusing and I would like to make sure that I understand how were this acronyms formed and what was the initial thinking behind them. I am not exactly sure what the term Carrier refers to in terms of computer networking. Is the copper considered carrier? What does sensing the carrier mean? 

I recently found out that lots of different types of devices have a MAC address not just ethernet devices. I was thinking that it is possible for Internet protocol to run over many other types of technologies besides ethernet layer. Are there scenarios where other technologies besides ethernet are more practical or efficient or reccomended to use for communication of INTERNET protocol (like connecting through the internet) ? 

I know that when hubs were used there was the possibility of collisions whenever two devices would transmit data at the same time. However on that time I believe that communication was done in Half-Duplex mode rather than Full Duplex like today. Hypothetical Question: Suppose that Full-Duplex communication would have become really popular before the invention of Ethernet Switches. Would Switches have been so necessary in that case. Would it have been possible that switches would have been delayed because they would not be needed AS MUCH as they were because the communication between Network Interface Cards would have been already Full-Duplex and collision would have been already rarer? 

Preventing change of source IP address requires either access lists (ACL) or unicast reverse path filtering (uRPF). Neither come for free. uRPF typically requires additional lookup or more complex single lookup, so it could even halve your lookup performance in some platforms. ACL will slow down lookup and use memory. uRPF is maintenance free, you just configure it once and forget it. ACL needs system which knows which addresses are behind interface and makes sure the ACL stays up-to-date. ACL more widely supported than uRPF, uRPF is comparatively rare feature in L3 switch level devices. In 'real' routers usually both features are available. Even if both features are available, configuring uRPF in wrong place of the network can break the network, not understanding platform specific ACL limitations can cause outages. Usually you yourself don't benefit in preventing source address spoofing, it's mostly the Internet at large who benefits. You carry non-zero risk trying to do it, as you may end-up breaking stuff. And your customers won't gain any benefit, no one will pay you more to implement them. So reward is low doing it. Responsible service provider do it, because it's the right thing to do, but it's unrealistic to expect that we'll get antispoofing in relevantly large portion of access devices deployed. Much more realistic goal is, if we do ACL in IP transit connections, as there are only about 6000 or so stubby AS numbers there. Why this is even issue is because of UDP reflection attacks, which can be fixed by protocols such as QUIC and MinimaLT which ensure that reflection has no gains, as incoming query is guarantee to be larger than outgoing answer, so spoofing loses its benefit. It's again recently become quite popular to use UDP reflection as DDoS attack. There are lot of wide open DNS servers in consumer CPE devices which the consumers are not aware, so those consumers suffer as their home connection is congested as it's used to reflect attack. And it's also easy way to gain significant amplification small query of tens of bytes can yield large answer of over thousand bytes. There have been reflection DDoS attacks which are several hundred gigabits per second, and smaller are daily, just sunday night we transported 43Gbps attack to one of our customer. 

By coupling these concepts together, should I be able to craft a configuration that achieves my objectives? Is there anything else I should consider? 

What are the advantages and disadvantages of using 10GBase-T vs. SFP+ Direct Attach to interconnect devices where distance is not a determining factor? 

We have 2 Juniper EX 3300 switches operating in a stack. It is running Junos 12.3R3.4. The switches have 4 SFP/SFP+ Ports. On FPC 1, PIC 1, Xcvr 0 you see a description of "SFP-FC8G-SW." However, the transceiver is a Juniper branded 10GE SFP+ SR (see image below). The interface is up/down. On the client side the physical media indicates that it is connected but there seems to be no link layer connectivity. No traffic passes on the interface. Here is the output of "show chassis hardware" 

I am attempting to configure routing on a Catalyst 3650 running LAN Base to meet a particular set of criteria. For context: the switch is being configured as part of a lab environment that will allow for pre-configuration of equipment that will ultimately reside in another facility. The switch has been configured with 4 VLAN's, each with an IP address and corresponding DHCP pool (DHCP running on switch). has been enabled and inter-VLAN routing is working as expected. The final requirement is that the internet be reachable from within each VLAN. I expected that by having a hosts default-gateway set to the VLAN interface IP and a default route in the routing table to the upstream router that this would be achievable, assuming there was at least one interface on the same network as the upstream router. I have attempted the following to no avail: 

I am looking to reproduce a configuration that I have quite easily achieved on the Cisco Small Business Series SG500 family of switches. The configuration is for Auto Voice VLAN, triggered by CDP and/or LLDP, which results in dynamic interface configuration for a compatible device (i.e. Cisco phone) such that said interface sets the appropriate voice VLAN, native VLAN, and DSCP and CoS Values (46 and 5 respectively) are set for traffic on the Voice VLAN. The resulting behavior is a compatible phone can be plugged into a port and will operate in the Voice VLAN while a computer connected to the phones switch port will enter the native VLAN. Again, voice traffic has DSCP/CoS values set as mentioned above. I am comfortable with basic configuration of the Catalyst and have a CCNA in Routing and Switching...which does not cover these topics. From my research I gather that there are at least two separate components to achieving this configuration: 

Change port on the room 3D-Link. Fault may affect one, many or all ports in the device, depending on which exact component is broken and how many ports share this component Rewire (if room 2 and room 4 to room 3 are not sharing any wire, you can skip this) Change room 3 D-link 

For advanced config, you may want to supplement that with 'wrr-queue random-detect' with RED curve per queue+threshold. Be sure to mark your traffic correctly when it enters your network. 

Your problem is as such, that your router sampling and your own polling are not hitting the same moment. That is, even though polling interval is static, polling intervals contain different amount of samples, which your math does not take into account. Consider you've polled t1,t2,t3 but router didn't sample anything at t1,t2 interval, so all of the traffic between t1,t3 ended up at t2,t3 polled value. Causing your rate to be 0 at t1,t2 and over linerate at t2,t3 Now I'm going to suggest one solution, but please verify this with someone who has cursory understanding of math. First figure out interface you're interested in (if ge-1/1/1): 

Rationale here is, that we want to leak over the borders to reduce the effect of inaccurate polling intervals at your switch. You'd then plot the s1, s2, s3 and you should have much more smooth/accurate result than what you are seeing now. However I'm sure this is not novel problem and I'm sure there is formal solution how to recover optimal accuracy, unfortunately producing that solution is out of my skill set. Something math.stackexchange people would be better equipped to tackle. 

What you'd like to know is ifIndex, queue, threshold and drop counter. I'm not aware of populated MIB/OID where these values can be polled from. Like John Jensen explained, outDiscard is only thing you can get, but it aggregates all of this, so you won't know if it's BE, AF, EF, NC or what, which is dropping. You probably wouldn't care about BE drops, but you'd care about EF drops. There are two OIDs where these aggregate egress drops are stored, if your ifIndex is 10001, you'd find them here (symbolic and numeric presentation):